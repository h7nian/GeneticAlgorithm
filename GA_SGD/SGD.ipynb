{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629fa011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from momentumnet import MomentumNet\n",
    "from momentumnet import transform_to_momentumnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2d3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,gene_matrix,cell_type):\n",
    "        \n",
    "        self.gene_matrix = torch.from_numpy(gene_matrix).float()\n",
    "        self.cell_type = torch.from_numpy(cell_type).squeeze(1)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.gene_matrix.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        data = (self.gene_matrix[idx],self.cell_type[idx])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8a5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pbmc1_loader(pbmc_path,cell_type_path,batch_size=128):\n",
    "\n",
    "    pbmc = pd.read_csv(pbmc_path,header=None)\n",
    "    cell_type = pd.read_csv(cell_type_path,index_col = 0)\n",
    "    \n",
    "    full_dataset = MyDataset(pbmc.values,cell_type.values)\n",
    "\n",
    "    #Random split(0.7,0.3)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    # Define DataLoaders\n",
    "    # use 'loky' to work with joblib\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,   batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3240496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.normal(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd94e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.lr1 = nn.Linear(3500,1000)\n",
    "        self.lr2 = nn.Linear(1000,128)\n",
    "        self.lr3 = nn.Linear(128,64)\n",
    "        \n",
    "        self.lr = nn.Linear(64,9)\n",
    "        \n",
    "        self.apply(_weights_init)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.lr1(x))\n",
    "        x = self.lr2(x)\n",
    "        x = F.relu(self.lr3(x))\n",
    "        \n",
    "        output = self.lr(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161f8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_training(network, SGD_steps, lr, momentum, data_loader):\n",
    "\n",
    "    network.to(device)\n",
    "    network.train()\n",
    "\n",
    "    # Create optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr, momentum=momentum, nesterov=True, weight_decay=0.0001)\n",
    "    \n",
    "    total_step = len(data_loader)\n",
    "    \n",
    "    for s in range(0, SGD_steps):\n",
    "        total_loss = 0\n",
    "        for i, (genes, types) in enumerate(data_loader): \n",
    "            \n",
    "            genes = genes.to(device)\n",
    "            types = types.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = network(genes) \n",
    "            \n",
    "            loss = criterion(outputs, types)\n",
    "            total_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            #Gradient Value Clipping\n",
    "            nn.utils.clip_grad_value_(network.parameters(), clip_value=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            del loss, outputs\n",
    "            \n",
    "            #if (i+1) % 100 == 0:\n",
    "        total_loss = total_loss / len(data_loader.sampler)\n",
    "        print (\"Epoch [{}/{}], Loss: {}\".format(s+1, SGD_steps, total_loss))\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    # move network back to cpu and return\n",
    "    network.cpu()\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3085a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "SGD_steps = 100\n",
    "learning_rate = 1e-5\n",
    "pbmc_1 = \"data/pbmc_1_pca.csv\"\n",
    "cell_type_pbmc1 = \"data/cell_type_pbmc1.csv\"\n",
    "pbmc_2 = \"data/pbmc_2_pca.csv\"\n",
    "cell_type_pbmc2 = \"data/cell_type_pbmc2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb432943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_pbmc1_loader(pbmc_1,cell_type_pbmc1,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd94992",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a978c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1969.9704974489796\n",
      "Epoch [2/100], Loss: 1611.7593112244897\n",
      "Epoch [3/100], Loss: 1332.4163105867347\n",
      "Epoch [4/100], Loss: 1022.3392665816326\n",
      "Epoch [5/100], Loss: 820.0230420918367\n",
      "Epoch [6/100], Loss: 671.408977997449\n",
      "Epoch [7/100], Loss: 585.602558992347\n",
      "Epoch [8/100], Loss: 517.3997114158163\n",
      "Epoch [9/100], Loss: 476.0442681760204\n",
      "Epoch [10/100], Loss: 421.7506560905612\n",
      "Epoch [11/100], Loss: 399.5551961096939\n",
      "Epoch [12/100], Loss: 366.1506138392857\n",
      "Epoch [13/100], Loss: 358.73410235969385\n",
      "Epoch [14/100], Loss: 332.04303491709186\n",
      "Epoch [15/100], Loss: 308.64644451530614\n",
      "Epoch [16/100], Loss: 285.6639453125\n",
      "Epoch [17/100], Loss: 269.14242426658166\n",
      "Epoch [18/100], Loss: 259.9831473214286\n",
      "Epoch [19/100], Loss: 260.7489166135204\n",
      "Epoch [20/100], Loss: 244.63893654336735\n",
      "Epoch [21/100], Loss: 223.9440983737245\n",
      "Epoch [22/100], Loss: 212.1482401945153\n",
      "Epoch [23/100], Loss: 199.76894690688775\n",
      "Epoch [24/100], Loss: 190.43463966836734\n",
      "Epoch [25/100], Loss: 183.2241932397959\n",
      "Epoch [26/100], Loss: 170.2391458067602\n",
      "Epoch [27/100], Loss: 166.1455580357143\n",
      "Epoch [28/100], Loss: 153.85176837531887\n",
      "Epoch [29/100], Loss: 150.03995455994897\n",
      "Epoch [30/100], Loss: 142.14617984693876\n",
      "Epoch [31/100], Loss: 139.62986088966838\n",
      "Epoch [32/100], Loss: 126.1451809630102\n",
      "Epoch [33/100], Loss: 120.06566615513393\n",
      "Epoch [34/100], Loss: 116.1196880978954\n",
      "Epoch [35/100], Loss: 113.22048030931123\n",
      "Epoch [36/100], Loss: 104.3895071348852\n",
      "Epoch [37/100], Loss: 99.77917889030613\n",
      "Epoch [38/100], Loss: 95.42131018813775\n",
      "Epoch [39/100], Loss: 91.03618582589286\n",
      "Epoch [40/100], Loss: 85.78369688695791\n",
      "Epoch [41/100], Loss: 83.74758510044643\n",
      "Epoch [42/100], Loss: 83.01329799107143\n",
      "Epoch [43/100], Loss: 74.15917350924745\n",
      "Epoch [44/100], Loss: 77.95170240752552\n",
      "Epoch [45/100], Loss: 68.49523337850765\n",
      "Epoch [46/100], Loss: 68.51014319595025\n",
      "Epoch [47/100], Loss: 59.81145557637117\n",
      "Epoch [48/100], Loss: 56.470269102758294\n",
      "Epoch [49/100], Loss: 56.61070651307398\n",
      "Epoch [50/100], Loss: 51.56467873086735\n",
      "Epoch [51/100], Loss: 47.773506799814655\n",
      "Epoch [52/100], Loss: 51.95951470822704\n",
      "Epoch [53/100], Loss: 44.17909418845663\n",
      "Epoch [54/100], Loss: 41.715836605149875\n",
      "Epoch [55/100], Loss: 38.21759111676897\n",
      "Epoch [56/100], Loss: 36.54852170360331\n",
      "Epoch [57/100], Loss: 33.81836266342474\n",
      "Epoch [58/100], Loss: 34.309607979910716\n",
      "Epoch [59/100], Loss: 30.26634329659598\n",
      "Epoch [60/100], Loss: 29.268914421237245\n",
      "Epoch [61/100], Loss: 29.151657764668368\n",
      "Epoch [62/100], Loss: 24.893880739795918\n",
      "Epoch [63/100], Loss: 26.003920848612882\n",
      "Epoch [64/100], Loss: 22.408761932995855\n",
      "Epoch [65/100], Loss: 22.09894023038903\n",
      "Epoch [66/100], Loss: 20.065740792410715\n",
      "Epoch [67/100], Loss: 17.974654565927935\n",
      "Epoch [68/100], Loss: 17.660077539560746\n",
      "Epoch [69/100], Loss: 16.287967379823023\n",
      "Epoch [70/100], Loss: 17.19405517578125\n",
      "Epoch [71/100], Loss: 14.866259949353276\n",
      "Epoch [72/100], Loss: 12.531565215441645\n",
      "Epoch [73/100], Loss: 11.695676294443558\n",
      "Epoch [74/100], Loss: 10.957267270769393\n",
      "Epoch [75/100], Loss: 10.222805829729353\n",
      "Epoch [76/100], Loss: 9.443679451455875\n",
      "Epoch [77/100], Loss: 8.635186674156968\n",
      "Epoch [78/100], Loss: 8.33424031561076\n",
      "Epoch [79/100], Loss: 7.44177452865912\n",
      "Epoch [80/100], Loss: 6.828650344537229\n",
      "Epoch [81/100], Loss: 6.477085484095982\n",
      "Epoch [82/100], Loss: 5.867329920554647\n",
      "Epoch [83/100], Loss: 13.365471599345305\n",
      "Epoch [84/100], Loss: 4.944914930693957\n",
      "Epoch [85/100], Loss: 4.484463043212891\n",
      "Epoch [86/100], Loss: 5.217064962581713\n",
      "Epoch [87/100], Loss: 3.773394445302535\n",
      "Epoch [88/100], Loss: 3.4532945843132175\n",
      "Epoch [89/100], Loss: 3.414438214983259\n",
      "Epoch [90/100], Loss: 2.9723027287697303\n",
      "Epoch [91/100], Loss: 2.7069569817367864\n",
      "Epoch [92/100], Loss: 2.5162643366443866\n",
      "Epoch [93/100], Loss: 2.3369415089141796\n",
      "Epoch [94/100], Loss: 2.2390066999318647\n",
      "Epoch [95/100], Loss: 1.9992067111268335\n",
      "Epoch [96/100], Loss: 1.8478222476686375\n",
      "Epoch [97/100], Loss: 1.700310538155692\n",
      "Epoch [98/100], Loss: 1.5831413985302254\n",
      "Epoch [99/100], Loss: 1.884654136190609\n",
      "Epoch [100/100], Loss: 1.3013093956149355\n",
      "All Time-20415.6231880188ms\n"
     ]
    }
   ],
   "source": [
    "SGD_start = time.time()\n",
    "network = SGD_training(network, SGD_steps, learning_rate, 0.9, train_loader)\n",
    "SGD_end = time.time()\n",
    "print(f\"All Time{(SGD_start-SGD_end)*1000}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd87229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_function(network, data_loader):\n",
    "    # init accuracy\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for genes, types in data_loader:\n",
    "            genes = genes.to(device)\n",
    "            types = types.to(device)\n",
    "            outputs = network(genes)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += genes.size(0)\n",
    "            \n",
    "            correct += (predicted == types).sum().item()\n",
    "\n",
    "        accuracy =  correct / total\n",
    "        #print('Accuracy of the model on the test images: {} %'.format(accuracy))\n",
    "        \n",
    "    # send network back to cpu\n",
    "    network.cpu()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399afb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6752380952380952"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = test_function(network,test_loader)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961efd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
