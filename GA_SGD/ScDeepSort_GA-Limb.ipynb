{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f045d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from scipy.sparse import csr_matrix, vstack, save_npz\n",
    "from sklearn.decomposition import PCA\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c03f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2d94e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.contrib.sampling import NeighborSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c89f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13f729ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from '/home/chenhuaguan/.conda/envs/py36/lib/python3.6/site-packages/torch/version.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d6de9",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c953db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f889d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"data/Limb_Muscle_facts_processed_3m.h5ad\", dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d7a70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gene = adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7cc5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gene = pd.DataFrame(data_gene.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7094d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2gene = data_gene.index.values.tolist()\n",
    "id2gene.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd66093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cell = pd.DataFrame(adata.obs[\"cell_ontology_class\"]).reset_index()\n",
    "data_cell.columns = ['Cell','Cell_type']\n",
    "data_cell.index = data_cell.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac0b9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = set()\n",
    "cell_type_list = []\n",
    "data_cell['Cell_type'] = data_cell['Cell_type'].map(str.strip)\n",
    "cell_types = set(data_cell.values[:, 1])\n",
    "cell_type_list.extend(data_cell.values[:, 1].tolist())\n",
    "id2label = list(cell_types)\n",
    "label_statistics = dict(collections.Counter(cell_type_list))\n",
    "total_cell = sum(label_statistics.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb65084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, num in label_statistics.items():\n",
    "    if num / total_cell <= 0.005:\n",
    "        id2label.remove(label)  # remove exclusive labels\n",
    "gene2id = {gene: idx for idx, gene in enumerate(id2gene)}\n",
    "num_genes = len(id2gene)\n",
    "# prepare unified labels\n",
    "num_labels = len(id2label)\n",
    "label2id = {label: idx for idx, label in enumerate(id2label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c58d198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.DGLGraph()\n",
    "\n",
    "gene_ids = torch.arange(num_genes, dtype=torch.int32, device=device).unsqueeze(-1)\n",
    "graph.add_nodes(num_genes, {'id': gene_ids})\n",
    "all_labels = []\n",
    "matrices = []\n",
    "num_cells = 0\n",
    "cell2type = pd.DataFrame(adata.obs[\"cell_ontology_class\"]).reset_index()\n",
    "cell2type.index = cell2type.index+1\n",
    "cell2type.columns = ['cell', 'type']\n",
    "cell2type['type'] = cell2type['type'].map(str.strip)\n",
    "cell2type['id'] = cell2type['type'].map(label2id)\n",
    "filter_cell = np.where(pd.isnull(cell2type['id']) == False)[0]\n",
    "cell2type = cell2type.iloc[filter_cell]\n",
    "all_labels += cell2type['id'].tolist()\n",
    "df = pd.DataFrame(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e610966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[filter_cell]\n",
    "df = df.rename(columns=gene2id)\n",
    "col = [c for c in df.columns if c in gene2id.values()]\n",
    "df = df[col]\n",
    "arr = df.to_numpy()\n",
    "row_idx, col_idx = np.nonzero(arr > 0)  # intra-dataset index\n",
    "non_zeros = arr[(row_idx, col_idx)]  # non-zero values\n",
    "cell_idx = row_idx + graph.number_of_nodes()  # cell_index\n",
    "gene_idx = df.columns[col_idx].astype(int).tolist()  # gene_index\n",
    "info_shape = (len(df), num_genes)\n",
    "info = csr_matrix((non_zeros, (row_idx, gene_idx)), shape=info_shape)\n",
    "matrices.append(info)\n",
    "\n",
    "num_cells += len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "697ee87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.tensor([-1] * len(df), dtype=torch.int32, device=device).unsqueeze(-1)\n",
    "graph.add_nodes(len(df), {'id': ids})\n",
    "graph.add_edges(cell_idx, gene_idx,\n",
    "                {'weight': torch.tensor(non_zeros, dtype=torch.float32, device=device).unsqueeze(1)})\n",
    "graph.add_edges(gene_idx, cell_idx,\n",
    "                {'weight': torch.tensor(non_zeros, dtype=torch.float32, device=device).unsqueeze(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cce041d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feat = vstack(matrices).toarray()  # cell-wise  (cell, gene)\n",
    "gene_pca = PCA(400, random_state=10086).fit(sparse_feat.T)\n",
    "gene_feat = gene_pca.transform(sparse_feat.T)\n",
    "gene_evr = sum(gene_pca.explained_variance_ratio_) * 100\n",
    "sparse_feat = sparse_feat / (np.sum(sparse_feat, axis=1, keepdims=True) + 1e-6)\n",
    "# use weighted gene_feat as cell_feat\n",
    "cell_feat = sparse_feat.dot(gene_feat)\n",
    "gene_feat = torch.from_numpy(gene_feat)  # use shared storage\n",
    "cell_feat = torch.from_numpy(cell_feat)\n",
    "\n",
    "graph.ndata['features'] = torch.cat([gene_feat, cell_feat], dim=0).type(torch.float).to(device)\n",
    "labels = torch.tensor([-1] * num_genes + all_labels, dtype=torch.long, device=device)  # [gene_num+train_num]\n",
    "per = np.random.permutation(range(num_genes, num_genes + num_cells))\n",
    "test_ids = torch.tensor(per[:int(num_cells // ((1 - 0.2) / 0.2 + 1))]).to(device)\n",
    "train_ids = torch.tensor(per[int(num_cells // ((1 - 0.2) / 0.2 + 1)):]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fe01998",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degrees = graph.in_degrees()\n",
    "for i in range(graph.number_of_nodes()):\n",
    "    src, dst, in_edge_id = graph.in_edges(i, form='all')\n",
    "    if src.shape[0] == 0:\n",
    "        continue\n",
    "    edge_w = graph.edata['weight'][in_edge_id]\n",
    "    graph.edata['weight'][in_edge_id] = in_degrees[i] * edge_w / torch.sum(edge_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "393ec077",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edges(graph.nodes(), graph.nodes(),\n",
    "                {'weight': torch.ones(graph.number_of_nodes(), dtype=torch.float, device=device).unsqueeze(1)})\n",
    "graph.readonly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19854d3b",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca283aa",
   "metadata": {},
   "source": [
    "## NodeUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14d198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeUpdate(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation=None, norm=None):\n",
    "        super(NodeUpdate, self).__init__()\n",
    "        self.fc_neigh = nn.Linear(in_features=in_feats, out_features=out_feats)\n",
    "        self.activation = activation\n",
    "        self.norm = norm\n",
    "        nn.init.xavier_uniform_(self.fc_neigh.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, node):\n",
    "        h_neigh = node.data['neigh']\n",
    "        h_neigh = self.fc_neigh(h_neigh)\n",
    "        if self.activation is not None:\n",
    "            h_neigh = self.activation(h_neigh)\n",
    "        if self.norm is not None:\n",
    "            h_neigh = self.norm(h_neigh)\n",
    "        return {'activation': h_neigh}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40651976",
   "metadata": {},
   "source": [
    "## GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5d444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers, gene_num, activation=None, norm=None, dropout=0.0):\n",
    "        super(GNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.gene_num = gene_num\n",
    "        if dropout != 0:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(NodeUpdate(in_feats=in_feats, out_feats=n_hidden, activation=activation, norm=norm))\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.layers.append(NodeUpdate(in_feats=n_hidden, out_feats=n_hidden, activation=activation, norm=norm))\n",
    "\n",
    "        # [gene_num] is alpha of gene-gene, [gene_num+1] is alpha of cell-cell self loop\n",
    "        self.alpha = nn.Parameter(torch.tensor([1] * (self.gene_num + 2), dtype=torch.float32).unsqueeze(-1))\n",
    "        self.linear = nn.Linear(n_hidden, n_classes)\n",
    "        nn.init.xavier_uniform_(self.linear.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def message_func(self, edges: dgl.udf.EdgeBatch):\n",
    "        number_of_edges = edges.src['h'].shape[0]\n",
    "        indices = np.expand_dims(np.array([self.gene_num + 1] * number_of_edges, dtype=np.int32), axis=1)\n",
    "        src_id, dst_id = edges.src['id'].cpu().numpy(), edges.dst['id'].cpu().numpy()\n",
    "        indices = np.where((src_id >= 0) & (dst_id < 0), src_id, indices)  # gene->cell\n",
    "        indices = np.where((dst_id >= 0) & (src_id < 0), dst_id, indices)  # cell->gene\n",
    "        indices = np.where((dst_id >= 0) & (src_id >= 0), self.gene_num, indices)  # gene-gene\n",
    "        h = edges.src['h'] * self.alpha[indices.squeeze()]\n",
    "        # return {'m': h}\n",
    "        return {'m': h * edges.data['weight']}\n",
    "\n",
    "    def forward(self, nf: dgl.NodeFlow):\n",
    "        nf.layers[0].data['activation'] = nf.layers[0].data['features']\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = nf.layers[i].data.pop('activation')\n",
    "            if self.dropout:\n",
    "                h = self.dropout(h)\n",
    "            nf.layers[i].data['h'] = h\n",
    "            nf.block_compute(i, self.message_func, fn.mean('m', 'neigh'), layer)\n",
    "        h = nf.layers[-1].data.pop('activation')\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "    def evaluate(self, nf: dgl.NodeFlow):\n",
    "        def message_func(edges: dgl.EdgeBatch):\n",
    "            # edges.src['h']： (number of edges, feature dim)\n",
    "            number_of_edges = edges.src['h'].shape[0]\n",
    "            indices = np.expand_dims(np.array([self.gene_num + 1] * number_of_edges, dtype=np.int32), axis=1)\n",
    "            src_id, dst_id = edges.src['id'].cpu().numpy(), edges.dst['id'].cpu().numpy()\n",
    "            indices = np.where((src_id >= 0) & (dst_id < 0), src_id, indices)  # gene->cell\n",
    "            indices = np.where((dst_id >= 0) & (src_id < 0), dst_id, indices)  # cell->gene\n",
    "            indices = np.where((dst_id >= 0) & (src_id >= 0), self.gene_num, indices)  # gene-gene\n",
    "            h = edges.src['h'].cpu() * self.alpha[indices.squeeze()]\n",
    "            return {'m': h * edges.data['weight'].cpu()}\n",
    "\n",
    "        nf.layers[0].data['activation'] = nf.layers[0].data['features'].cpu()\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = nf.layers[i].data.pop('activation')\n",
    "            if self.dropout:\n",
    "                h = self.dropout(h)\n",
    "            nf.layers[i].data['h'] = h\n",
    "            nf.block_compute(i, message_func, fn.mean('m', 'neigh'), layer)\n",
    "        h = nf.layers[-1].data.pop('activation')\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5518d",
   "metadata": {},
   "source": [
    "# Adam_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c7bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam_Trainer:\n",
    "    def __init__(self, device_train,gnn_model,lr,weight_decay,Adam_epochs,batch_size,\n",
    "                num_cells,\n",
    "                num_genes,\n",
    "                num_labels,\n",
    "                graph,\n",
    "                train_ids,\n",
    "                test_ids,\n",
    "                labels):\n",
    "        \n",
    "        self.device = device_train\n",
    "        \n",
    "        self.num_cells = num_cells\n",
    "        self.num_genes = num_genes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.graph = graph\n",
    "        \n",
    "        self.graph.readonly(True)\n",
    "        \n",
    "        self.train_ids = train_ids\n",
    "        self.test_ids = test_ids\n",
    "        self.labels = labels \n",
    "        \n",
    "        self.labels = self.labels.to(self.device)\n",
    "        \n",
    "        self.model = gnn_model\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.epochs = Adam_epochs\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr,\n",
    "                                          weight_decay=self.weight_decay)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "        \n",
    "        self.num_neighbors = self.num_cells + self.num_genes\n",
    "\n",
    "    def fit(self):\n",
    "        max_test_acc, _train_acc, _epoch = 0, 0, 0\n",
    "        for epoch in range(self.epochs):\n",
    "            loss = self.train()\n",
    "            train_correct, train_unsure = self.evaluate(self.train_ids, 'train')\n",
    "            train_acc = train_correct / len(self.train_ids)\n",
    "            test_correct, test_unsure = self.evaluate(self.test_ids, 'test')\n",
    "            test_acc = test_correct / len(self.test_ids)\n",
    "            if max_test_acc <= test_acc:\n",
    "                final_test_correct_num = test_correct\n",
    "                final_test_unsure_num = test_unsure\n",
    "                _train_acc = train_acc\n",
    "                _epoch = epoch\n",
    "                max_test_acc = test_acc\n",
    "                self.save_model()\n",
    "            print(\n",
    "                f\">>>>Epoch {epoch+1:04d}: Train Acc {train_acc:.4f}, Loss {loss / len(self.train_ids):.4f}, Test correct {test_correct}, \"\n",
    "                f\"Test unsure {test_unsure}, Test Acc {test_acc:.4f}\")\n",
    "            if train_acc == 1:\n",
    "                break\n",
    "\n",
    "        #print(f\"---{self.params.species} {self.params.tissue} Best test result:---\")\n",
    "        print(f\"Epoch {_epoch+1:04d}, Train Acc {_train_acc:.4f}, Test Correct Num {final_test_correct_num}, Test Total Num {len(self.test_ids)}, Test Unsure Num {final_test_unsure_num}, Test Acc {final_test_correct_num / len(self.test_ids):.4f}\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch, nf in enumerate(NeighborSampler(g=self.graph,\n",
    "                                                   batch_size=self.batch_size,\n",
    "                                                   expand_factor=self.num_neighbors,\n",
    "                                                   num_hops=1,\n",
    "                                                   neighbor_type='in',\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=8,\n",
    "                                                   seed_nodes=self.train_ids.long())):\n",
    "            nf.copy_from_parent()  # Copy node/edge features from the parent graph.\n",
    "            logits = self.model(nf)\n",
    "            batch_nids = nf.layer_parent_nid(-1).type(torch.long).to(device=self.device)\n",
    "            loss = self.loss_fn(logits, self.labels[batch_nids])\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def evaluate(self, ids, type='test'):\n",
    "        self.model.eval()\n",
    "        total_correct, total_unsure = 0, 0\n",
    "        for nf in NeighborSampler(g=self.graph,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  expand_factor=self.num_cells + self.num_genes,\n",
    "                                  num_hops=1,\n",
    "                                  neighbor_type='in',\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=8,\n",
    "                                  seed_nodes=ids.long()):\n",
    "            nf.copy_from_parent()  # Copy node/edge features from the parent graph.\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(nf).cpu()\n",
    "            batch_nids = nf.layer_parent_nid(-1).type(torch.long)\n",
    "            logits = nn.functional.softmax(logits, dim=1).numpy()\n",
    "            label_list = self.labels.cpu()[batch_nids]\n",
    "            for pred, label in zip(logits, label_list):\n",
    "                max_prob = pred.max().item()\n",
    "                if max_prob < 2 / num_labels:\n",
    "                    total_unsure += 1\n",
    "                elif pred.argmax().item() == label:\n",
    "                    total_correct += 1\n",
    "\n",
    "        return total_correct, total_unsure\n",
    "\n",
    "    def save_model(self):\n",
    "        state = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(state, \"GA_Model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cbc05",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36e06989",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crossover_and_mutation(parents, sigma=0.01):\n",
    "\n",
    "    \n",
    "    base_sd = parents[0].state_dict()\n",
    "    keys = base_sd                    # use all layers to be affected\n",
    "    \n",
    "    # Sum of the weights of the parent\n",
    "    for i in range(1, len(parents)):\n",
    "        parent_sd = parents[i].state_dict()\n",
    "        for key in keys:\n",
    "            base_sd[key] = base_sd[key] + parent_sd[key]\n",
    "            \n",
    "    \n",
    "    # Average and add mutation\n",
    "    num_parents = len(parents)\n",
    "    \n",
    "    for key in keys:\n",
    "        \n",
    "        tensor_size = base_sd[key].size()\n",
    "        random_tensor = torch.normal(mean=0.0, std=sigma, size=tensor_size)\n",
    "        \n",
    "        base_sd[key] = (base_sd[key] / num_parents) + random_tensor\n",
    "    \n",
    "    # create offspring\n",
    "    offspring = GNN(in_feats=in_feats,\n",
    "                         n_hidden=n_hidden,\n",
    "                         n_classes=num_labels,\n",
    "                         n_layers=1,\n",
    "                         gene_num=num_genes,\n",
    "                         activation=F.relu,\n",
    "                         dropout=0.1).to(device_train)\n",
    "    \n",
    "    offspring.load_state_dict(base_sd)\n",
    "    \n",
    "    return offspring\n",
    "    \n",
    "\n",
    "def create_offspring(population, fitness, rho, sigma):\n",
    "\n",
    "    \n",
    "    # Perform selection\n",
    "    parents = random.choices(population,weights=fitness, k=rho) \n",
    "    \n",
    "    # Perform crossover and mutation\n",
    "    offspring = crossover_and_mutation(parents, sigma)\n",
    "    \n",
    "    \n",
    "    return offspring\n",
    "\n",
    "\n",
    "def GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, train_ids,\n",
    "                test_ids,\n",
    "                graph,\n",
    "                batch_size,\n",
    "                num_cells,\n",
    "                num_genes,\n",
    "                labels):\n",
    "    \n",
    "    #Calculate fitness of trained population\n",
    "\n",
    "    fitness = [calc_loss(population[i],train_ids,graph,batch_size,num_cells,num_genes,labels) for i in range(pop_size)]\n",
    "    \n",
    "    print(f\"--- -- Finished fitness evaluation, length: {len(fitness)}\")\n",
    "    \n",
    "    #Create offspring population\n",
    "    \n",
    "    fitness_weighted = fitness\n",
    "    offspring_population = [create_offspring(population, fitness_weighted, rho, sigma) for i in range(offspring_size)]\n",
    "    \n",
    "    print(\"--- -- Finished creating offspring population\")\n",
    "    \n",
    "    #Evaluate fitness of offsprings \n",
    "    \n",
    "    offspring_fitness = [calc_loss(offspring_population[i],test_ids,graph,batch_size,num_cells,num_genes,labels) for i in range(offspring_size)]\n",
    "    \n",
    "    print(\"--- -- Finished evaluating fitness of offspring population\")\n",
    "    \n",
    "    # Combine fitness and population lists\n",
    "    \n",
    "    combined_fitness = fitness + offspring_fitness\n",
    "    combined_population = population + offspring_population\n",
    "    \n",
    "    # sort and select population by their fitness values\n",
    "    \n",
    "    sorted_population = [pop for _, pop in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    sorted_fitness = [loss for loss, _ in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    \n",
    "    m = int(pop_size * elitist_level)\n",
    "    new_population = sorted_population[0:m]\n",
    "    \n",
    "    # Fill up rest of population\n",
    "    difference = pop_size - m\n",
    "    remaining_population = list(set(sorted_population) - set(new_population))\n",
    "    filler_population = random.sample(remaining_population, difference)\n",
    "    \n",
    "    # assemble new population and return\n",
    "    new_population = new_population + filler_population\n",
    "    \n",
    "    return new_population, sorted_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d538178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(model, train_ids,graph,batch_size,num_cells,num_genes,labels):\n",
    "    model.eval()\n",
    "    total_correct, total_unsure = 0, 0\n",
    "    for nf in NeighborSampler(g=graph,\n",
    "                              batch_size=batch_size,\n",
    "                              expand_factor=num_cells + num_genes,\n",
    "                              num_hops=1,\n",
    "                              neighbor_type='in',\n",
    "                              shuffle=True,\n",
    "                              num_workers=8,\n",
    "                              seed_nodes=train_ids.long()):\n",
    "        nf.copy_from_parent()  # Copy node/edge features from the parent graph.\n",
    "        with torch.no_grad():\n",
    "            logits = model(nf).cpu()\n",
    "        batch_nids = nf.layer_parent_nid(-1).type(torch.long)\n",
    "        logits = nn.functional.softmax(logits, dim=1).numpy()\n",
    "        label_list = labels.cpu()[batch_nids]\n",
    "        for pred, label in zip(logits, label_list):\n",
    "            max_prob = pred.max().item()\n",
    "            if max_prob < 2 / num_labels:\n",
    "                total_unsure += 1\n",
    "            elif pred.argmax().item() == label:\n",
    "                total_correct += 1\n",
    "\n",
    "    return total_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657950d",
   "metadata": {},
   "source": [
    "# GA_Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f14faa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_Neural_train(population,\n",
    "                    pop_size,\n",
    "                    max_generations, \n",
    "                    Adam_epochs, GA_steps, \n",
    "                    offspring_size, elitist_level, rho,\n",
    "                    learning_rate,\n",
    "                   weight_decay,\n",
    "                   batch_size,\n",
    "                   num_cells,num_genes,graph,train_ids,test_ids,labels):\n",
    "    \n",
    "    print(f\"Starting with population of size: {pop_size}\")\n",
    "    \n",
    "    \n",
    "    for k in range(max_generations):\n",
    "        print(f\"Currently in generation {k+1}\")\n",
    "        \n",
    "        #SGD\n",
    "        print(f\"--- Starting Adam\")\n",
    "        \n",
    "        # Sequential version\n",
    "        #population = [SGD_training(population[i], SGD_steps, learning_rate, 0.9, train_loader) for i in range(pop_size)]\n",
    "        for i in range(pop_size):\n",
    "            train = Adam_Trainer(device_train = device_train,gnn_model = population[i],\n",
    "                                 lr = learning_rate,weight_decay = weight_decay,Adam_epochs = Adam_epochs,\n",
    "                                 batch_size = batch_size,num_cells = num_cells,\n",
    "                                                        num_genes = num_genes,\n",
    "                                                        num_labels = num_labels,\n",
    "                                                        graph = graph,\n",
    "                                                        train_ids = train_ids,\n",
    "                                                        test_ids = test_ids,\n",
    "                                                        labels = labels)\n",
    "            train.fit()\n",
    "        \n",
    "        print(f\"--- Finished Adam\")\n",
    "         \n",
    "        # GA\n",
    "        print(f\"--- Starting GA\")\n",
    "        GA_start = time.time()\n",
    "        sorted_fitness = []          # store the sorted fitness values to maybe use in data collection\n",
    "        for i in range(0, GA_steps):\n",
    "            \n",
    "            sigma = 0.01 / (k+1)\n",
    "            population, sorted_fitness = GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, train_ids,\n",
    "                                                    test_ids,\n",
    "                                                    graph,\n",
    "                                                    batch_size,\n",
    "                                                    num_cells,\n",
    "                                                    num_genes,\n",
    "                                                    labels)\n",
    "        \n",
    "        GA_end = time.time()\n",
    "        print(f\"--- Finished GA,Time:{(GA_end-GA_start)*1000}ms\")\n",
    "        \n",
    "        \n",
    "    print(f\"Finished training process\")\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab74ac",
   "metadata": {},
   "source": [
    "# Start training process\n",
    "We have now defined the whole training algorithm. The next step is to actually perform training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e61e033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#device_train = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device_train = torch.device('cpu')\n",
    "batch_size = 500\n",
    "pop_size = 10\n",
    "max_generations = 10\n",
    "Adam_epochs = 10\n",
    "GA_steps = 1\n",
    "offspring_size = 80\n",
    "elitist_level = 0.6\n",
    "rho = 3\n",
    "learning_rate = 1e-3\n",
    "in_feats = 400\n",
    "n_hidden = 200\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67dcc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population and start training process\n",
    "population = [GNN(in_feats=in_feats,\n",
    "                         n_hidden=n_hidden,\n",
    "                         n_classes=num_labels,\n",
    "                         n_layers=1,\n",
    "                         gene_num=num_genes,\n",
    "                         activation=F.relu,\n",
    "                         dropout=0.1).to(device_train) for i in range(pop_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbe831",
   "metadata": {},
   "source": [
    "# Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e0c8c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with population of size: 10\n",
      "Currently in generation 1\n",
      "--- Starting Adam\n",
      ">>>>Epoch 0001: Train Acc 0.4932, Loss 1.4025, Test correct 112, Test unsure 27, Test Acc 0.5091\n",
      ">>>>Epoch 0002: Train Acc 0.5283, Loss 1.1339, Test correct 118, Test unsure 27, Test Acc 0.5364\n",
      ">>>>Epoch 0003: Train Acc 0.6712, Loss 0.9384, Test correct 133, Test unsure 33, Test Acc 0.6045\n",
      ">>>>Epoch 0004: Train Acc 0.7755, Loss 0.7745, Test correct 157, Test unsure 29, Test Acc 0.7136\n",
      ">>>>Epoch 0005: Train Acc 0.8209, Loss 0.6549, Test correct 167, Test unsure 31, Test Acc 0.7591\n",
      ">>>>Epoch 0006: Train Acc 0.8435, Loss 0.5622, Test correct 174, Test unsure 28, Test Acc 0.7909\n",
      ">>>>Epoch 0007: Train Acc 0.8594, Loss 0.4854, Test correct 178, Test unsure 28, Test Acc 0.8091\n",
      ">>>>Epoch 0008: Train Acc 0.8934, Loss 0.4117, Test correct 184, Test unsure 23, Test Acc 0.8364\n",
      ">>>>Epoch 0009: Train Acc 0.9184, Loss 0.3596, Test correct 189, Test unsure 22, Test Acc 0.8591\n",
      ">>>>Epoch 0010: Train Acc 0.9376, Loss 0.3047, Test correct 193, Test unsure 20, Test Acc 0.8773\n",
      "Epoch 0010, Train Acc 0.9376, Test Correct Num 193, Test Total Num 220, Test Unsure Num 20, Test Acc 0.8773\n",
      ">>>>Epoch 0001: Train Acc 0.4637, Loss 2.0748, Test correct 107, Test unsure 28, Test Acc 0.4864\n",
      ">>>>Epoch 0002: Train Acc 0.4898, Loss 1.7586, Test correct 110, Test unsure 27, Test Acc 0.5000\n",
      ">>>>Epoch 0003: Train Acc 0.5000, Loss 1.4865, Test correct 111, Test unsure 27, Test Acc 0.5045\n",
      ">>>>Epoch 0004: Train Acc 0.5136, Loss 1.2403, Test correct 113, Test unsure 26, Test Acc 0.5136\n",
      ">>>>Epoch 0005: Train Acc 0.5420, Loss 1.0185, Test correct 119, Test unsure 23, Test Acc 0.5409\n",
      ">>>>Epoch 0006: Train Acc 0.6565, Loss 0.8286, Test correct 129, Test unsure 26, Test Acc 0.5864\n",
      ">>>>Epoch 0007: Train Acc 0.8288, Loss 0.6714, Test correct 153, Test unsure 25, Test Acc 0.6955\n",
      ">>>>Epoch 0008: Train Acc 0.9014, Loss 0.5470, Test correct 173, Test unsure 24, Test Acc 0.7864\n",
      ">>>>Epoch 0009: Train Acc 0.9218, Loss 0.4376, Test correct 181, Test unsure 23, Test Acc 0.8227\n",
      ">>>>Epoch 0010: Train Acc 0.9410, Loss 0.3726, Test correct 187, Test unsure 19, Test Acc 0.8500\n",
      "Epoch 0010, Train Acc 0.9410, Test Correct Num 187, Test Total Num 220, Test Unsure Num 19, Test Acc 0.8500\n",
      ">>>>Epoch 0001: Train Acc 0.2029, Loss 2.5399, Test correct 40, Test unsure 41, Test Acc 0.1818\n",
      ">>>>Epoch 0002: Train Acc 0.2971, Loss 2.0918, Test correct 59, Test unsure 38, Test Acc 0.2682\n",
      ">>>>Epoch 0003: Train Acc 0.3435, Loss 1.7073, Test correct 64, Test unsure 50, Test Acc 0.2909\n",
      ">>>>Epoch 0004: Train Acc 0.5091, Loss 1.3375, Test correct 83, Test unsure 74, Test Acc 0.3773\n",
      ">>>>Epoch 0005: Train Acc 0.7698, Loss 1.0477, Test correct 143, Test unsure 51, Test Acc 0.6500\n",
      ">>>>Epoch 0006: Train Acc 0.8469, Loss 0.8333, Test correct 170, Test unsure 35, Test Acc 0.7727\n",
      ">>>>Epoch 0007: Train Acc 0.8651, Loss 0.6720, Test correct 171, Test unsure 32, Test Acc 0.7773\n",
      ">>>>Epoch 0008: Train Acc 0.8764, Loss 0.5670, Test correct 172, Test unsure 25, Test Acc 0.7818\n",
      ">>>>Epoch 0009: Train Acc 0.8878, Loss 0.4917, Test correct 175, Test unsure 22, Test Acc 0.7955\n",
      ">>>>Epoch 0010: Train Acc 0.9104, Loss 0.4380, Test correct 178, Test unsure 22, Test Acc 0.8091\n",
      "Epoch 0010, Train Acc 0.9104, Test Correct Num 178, Test Total Num 220, Test Unsure Num 22, Test Acc 0.8091\n",
      ">>>>Epoch 0001: Train Acc 0.0941, Loss 3.3231, Test correct 18, Test unsure 75, Test Acc 0.0818\n",
      ">>>>Epoch 0002: Train Acc 0.2222, Loss 2.7233, Test correct 33, Test unsure 69, Test Acc 0.1500\n",
      ">>>>Epoch 0003: Train Acc 0.3345, Loss 2.1637, Test correct 61, Test unsure 47, Test Acc 0.2773\n",
      ">>>>Epoch 0004: Train Acc 0.3798, Loss 1.6666, Test correct 68, Test unsure 57, Test Acc 0.3091\n",
      ">>>>Epoch 0005: Train Acc 0.6179, Loss 1.2218, Test correct 114, Test unsure 55, Test Acc 0.5182\n",
      ">>>>Epoch 0006: Train Acc 0.8152, Loss 0.8910, Test correct 163, Test unsure 33, Test Acc 0.7409\n",
      ">>>>Epoch 0007: Train Acc 0.8662, Loss 0.6733, Test correct 182, Test unsure 22, Test Acc 0.8273\n",
      ">>>>Epoch 0008: Train Acc 0.8878, Loss 0.5070, Test correct 185, Test unsure 18, Test Acc 0.8409\n",
      ">>>>Epoch 0009: Train Acc 0.8980, Loss 0.4181, Test correct 189, Test unsure 14, Test Acc 0.8591\n",
      ">>>>Epoch 0010: Train Acc 0.9116, Loss 0.3686, Test correct 191, Test unsure 11, Test Acc 0.8682\n",
      "Epoch 0010, Train Acc 0.9116, Test Correct Num 191, Test Total Num 220, Test Unsure Num 11, Test Acc 0.8682\n",
      ">>>>Epoch 0001: Train Acc 0.0839, Loss 2.2463, Test correct 22, Test unsure 29, Test Acc 0.1000\n",
      ">>>>Epoch 0002: Train Acc 0.2268, Loss 1.7753, Test correct 51, Test unsure 48, Test Acc 0.2318\n",
      ">>>>Epoch 0003: Train Acc 0.4717, Loss 1.3800, Test correct 100, Test unsure 49, Test Acc 0.4545\n",
      ">>>>Epoch 0004: Train Acc 0.5522, Loss 1.0861, Test correct 114, Test unsure 43, Test Acc 0.5182\n",
      ">>>>Epoch 0005: Train Acc 0.6122, Loss 0.8944, Test correct 125, Test unsure 34, Test Acc 0.5682\n",
      ">>>>Epoch 0006: Train Acc 0.7063, Loss 0.7499, Test correct 141, Test unsure 36, Test Acc 0.6409\n",
      ">>>>Epoch 0007: Train Acc 0.8118, Loss 0.6247, Test correct 161, Test unsure 35, Test Acc 0.7318\n",
      ">>>>Epoch 0008: Train Acc 0.8571, Loss 0.5396, Test correct 170, Test unsure 36, Test Acc 0.7727\n",
      ">>>>Epoch 0009: Train Acc 0.8719, Loss 0.4620, Test correct 181, Test unsure 31, Test Acc 0.8227\n",
      ">>>>Epoch 0010: Train Acc 0.8889, Loss 0.4037, Test correct 187, Test unsure 25, Test Acc 0.8500\n",
      "Epoch 0010, Train Acc 0.8889, Test Correct Num 187, Test Total Num 220, Test Unsure Num 25, Test Acc 0.8500\n",
      ">>>>Epoch 0001: Train Acc 0.0159, Loss 2.7602, Test correct 3, Test unsure 45, Test Acc 0.0136\n",
      ">>>>Epoch 0002: Train Acc 0.0238, Loss 2.2066, Test correct 3, Test unsure 63, Test Acc 0.0136\n",
      ">>>>Epoch 0003: Train Acc 0.1497, Loss 1.7217, Test correct 31, Test unsure 72, Test Acc 0.1409\n",
      ">>>>Epoch 0004: Train Acc 0.5011, Loss 1.3643, Test correct 106, Test unsure 56, Test Acc 0.4818\n",
      ">>>>Epoch 0005: Train Acc 0.5771, Loss 1.0869, Test correct 113, Test unsure 54, Test Acc 0.5136\n",
      ">>>>Epoch 0006: Train Acc 0.6349, Loss 0.8909, Test correct 119, Test unsure 50, Test Acc 0.5409\n",
      ">>>>Epoch 0007: Train Acc 0.7052, Loss 0.7623, Test correct 134, Test unsure 43, Test Acc 0.6091\n",
      ">>>>Epoch 0008: Train Acc 0.7721, Loss 0.6599, Test correct 142, Test unsure 42, Test Acc 0.6455\n",
      ">>>>Epoch 0009: Train Acc 0.8345, Loss 0.5717, Test correct 154, Test unsure 38, Test Acc 0.7000\n",
      ">>>>Epoch 0010: Train Acc 0.8696, Loss 0.5101, Test correct 165, Test unsure 35, Test Acc 0.7500\n",
      "Epoch 0010, Train Acc 0.8696, Test Correct Num 165, Test Total Num 220, Test Unsure Num 35, Test Acc 0.7500\n",
      ">>>>Epoch 0001: Train Acc 0.1009, Loss 2.0153, Test correct 22, Test unsure 139, Test Acc 0.1000\n",
      ">>>>Epoch 0002: Train Acc 0.3231, Loss 1.6169, Test correct 55, Test unsure 131, Test Acc 0.2500\n",
      ">>>>Epoch 0003: Train Acc 0.6984, Loss 1.2479, Test correct 135, Test unsure 57, Test Acc 0.6136\n",
      ">>>>Epoch 0004: Train Acc 0.7880, Loss 0.9821, Test correct 163, Test unsure 32, Test Acc 0.7409\n",
      ">>>>Epoch 0005: Train Acc 0.8118, Loss 0.7948, Test correct 166, Test unsure 24, Test Acc 0.7545\n",
      ">>>>Epoch 0006: Train Acc 0.8322, Loss 0.6554, Test correct 171, Test unsure 17, Test Acc 0.7773\n",
      ">>>>Epoch 0007: Train Acc 0.8458, Loss 0.5587, Test correct 173, Test unsure 16, Test Acc 0.7864\n",
      ">>>>Epoch 0008: Train Acc 0.8549, Loss 0.4851, Test correct 175, Test unsure 15, Test Acc 0.7955\n",
      ">>>>Epoch 0009: Train Acc 0.8651, Loss 0.4244, Test correct 183, Test unsure 11, Test Acc 0.8318\n",
      ">>>>Epoch 0010: Train Acc 0.8855, Loss 0.3720, Test correct 189, Test unsure 7, Test Acc 0.8591\n",
      "Epoch 0010, Train Acc 0.8855, Test Correct Num 189, Test Total Num 220, Test Unsure Num 7, Test Acc 0.8591\n",
      ">>>>Epoch 0001: Train Acc 0.0998, Loss 2.5537, Test correct 32, Test unsure 35, Test Acc 0.1455\n",
      ">>>>Epoch 0002: Train Acc 0.1837, Loss 2.0083, Test correct 42, Test unsure 48, Test Acc 0.1909\n",
      ">>>>Epoch 0003: Train Acc 0.4354, Loss 1.5464, Test correct 79, Test unsure 59, Test Acc 0.3591\n",
      ">>>>Epoch 0004: Train Acc 0.7540, Loss 1.1748, Test correct 152, Test unsure 42, Test Acc 0.6909\n",
      ">>>>Epoch 0005: Train Acc 0.8061, Loss 0.9002, Test correct 167, Test unsure 36, Test Acc 0.7591\n",
      ">>>>Epoch 0006: Train Acc 0.8356, Loss 0.7283, Test correct 170, Test unsure 37, Test Acc 0.7727\n",
      ">>>>Epoch 0007: Train Acc 0.8605, Loss 0.6103, Test correct 175, Test unsure 26, Test Acc 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>Epoch 0008: Train Acc 0.8787, Loss 0.5309, Test correct 181, Test unsure 21, Test Acc 0.8227\n",
      ">>>>Epoch 0009: Train Acc 0.8946, Loss 0.4631, Test correct 186, Test unsure 20, Test Acc 0.8455\n",
      ">>>>Epoch 0010: Train Acc 0.9116, Loss 0.4000, Test correct 190, Test unsure 17, Test Acc 0.8636\n",
      "Epoch 0010, Train Acc 0.9116, Test Correct Num 190, Test Total Num 220, Test Unsure Num 17, Test Acc 0.8636\n",
      ">>>>Epoch 0001: Train Acc 0.0964, Loss 1.8826, Test correct 19, Test unsure 47, Test Acc 0.0864\n",
      ">>>>Epoch 0002: Train Acc 0.4422, Loss 1.5424, Test correct 93, Test unsure 34, Test Acc 0.4227\n",
      ">>>>Epoch 0003: Train Acc 0.4887, Loss 1.2912, Test correct 110, Test unsure 30, Test Acc 0.5000\n",
      ">>>>Epoch 0004: Train Acc 0.4977, Loss 1.1105, Test correct 111, Test unsure 28, Test Acc 0.5045\n",
      ">>>>Epoch 0005: Train Acc 0.5431, Loss 0.9755, Test correct 117, Test unsure 22, Test Acc 0.5318\n",
      ">>>>Epoch 0006: Train Acc 0.5998, Loss 0.8472, Test correct 125, Test unsure 21, Test Acc 0.5682\n",
      ">>>>Epoch 0007: Train Acc 0.7052, Loss 0.7300, Test correct 143, Test unsure 17, Test Acc 0.6500\n",
      ">>>>Epoch 0008: Train Acc 0.8197, Loss 0.6255, Test correct 165, Test unsure 15, Test Acc 0.7500\n",
      ">>>>Epoch 0009: Train Acc 0.8719, Loss 0.5332, Test correct 182, Test unsure 17, Test Acc 0.8273\n",
      ">>>>Epoch 0010: Train Acc 0.9048, Loss 0.4627, Test correct 185, Test unsure 17, Test Acc 0.8409\n",
      "Epoch 0010, Train Acc 0.9048, Test Correct Num 185, Test Total Num 220, Test Unsure Num 17, Test Acc 0.8409\n",
      ">>>>Epoch 0001: Train Acc 0.1485, Loss 2.5599, Test correct 21, Test unsure 32, Test Acc 0.0955\n",
      ">>>>Epoch 0002: Train Acc 0.2336, Loss 2.0555, Test correct 39, Test unsure 35, Test Acc 0.1773\n",
      ">>>>Epoch 0003: Train Acc 0.3163, Loss 1.5830, Test correct 53, Test unsure 44, Test Acc 0.2409\n",
      ">>>>Epoch 0004: Train Acc 0.6791, Loss 1.1938, Test correct 123, Test unsure 50, Test Acc 0.5591\n",
      ">>>>Epoch 0005: Train Acc 0.7982, Loss 0.9121, Test correct 159, Test unsure 36, Test Acc 0.7227\n",
      ">>>>Epoch 0006: Train Acc 0.8175, Loss 0.7161, Test correct 162, Test unsure 28, Test Acc 0.7364\n",
      ">>>>Epoch 0007: Train Acc 0.8322, Loss 0.5723, Test correct 163, Test unsure 23, Test Acc 0.7409\n",
      ">>>>Epoch 0008: Train Acc 0.8503, Loss 0.4791, Test correct 164, Test unsure 21, Test Acc 0.7455\n",
      ">>>>Epoch 0009: Train Acc 0.8866, Loss 0.4114, Test correct 172, Test unsure 18, Test Acc 0.7818\n",
      ">>>>Epoch 0010: Train Acc 0.9138, Loss 0.3531, Test correct 175, Test unsure 18, Test Acc 0.7955\n",
      "Epoch 0010, Train Acc 0.9138, Test Correct Num 175, Test Total Num 220, Test Unsure Num 18, Test Acc 0.7955\n",
      "--- Finished Adam\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:60814.282178878784ms\n",
      "Currently in generation 2\n",
      "--- Starting Adam\n",
      ">>>>Epoch 0001: Train Acc 0.4887, Loss 1.3289, Test correct 82, Test unsure 138, Test Acc 0.3727\n",
      ">>>>Epoch 0002: Train Acc 0.7460, Loss 1.1178, Test correct 147, Test unsure 72, Test Acc 0.6682\n",
      ">>>>Epoch 0003: Train Acc 0.7914, Loss 0.9398, Test correct 159, Test unsure 58, Test Acc 0.7227\n",
      ">>>>Epoch 0004: Train Acc 0.8050, Loss 0.8067, Test correct 163, Test unsure 53, Test Acc 0.7409\n",
      ">>>>Epoch 0005: Train Acc 0.8265, Loss 0.6871, Test correct 167, Test unsure 46, Test Acc 0.7591\n",
      ">>>>Epoch 0006: Train Acc 0.8401, Loss 0.6002, Test correct 170, Test unsure 40, Test Acc 0.7727\n",
      ">>>>Epoch 0007: Train Acc 0.8617, Loss 0.5350, Test correct 172, Test unsure 37, Test Acc 0.7818\n",
      ">>>>Epoch 0008: Train Acc 0.8832, Loss 0.4652, Test correct 179, Test unsure 28, Test Acc 0.8136\n",
      ">>>>Epoch 0009: Train Acc 0.9002, Loss 0.4157, Test correct 181, Test unsure 26, Test Acc 0.8227\n",
      ">>>>Epoch 0010: Train Acc 0.9161, Loss 0.3688, Test correct 184, Test unsure 24, Test Acc 0.8364\n",
      "Epoch 0010, Train Acc 0.9161, Test Correct Num 184, Test Total Num 220, Test Unsure Num 24, Test Acc 0.8364\n",
      ">>>>Epoch 0001: Train Acc 0.3889, Loss 1.3672, Test correct 54, Test unsure 160, Test Acc 0.2455\n",
      ">>>>Epoch 0002: Train Acc 0.7676, Loss 1.1402, Test correct 144, Test unsure 75, Test Acc 0.6545\n",
      ">>>>Epoch 0003: Train Acc 0.8481, Loss 0.9569, Test correct 170, Test unsure 48, Test Acc 0.7727\n",
      ">>>>Epoch 0004: Train Acc 0.8617, Loss 0.8095, Test correct 171, Test unsure 46, Test Acc 0.7773\n",
      ">>>>Epoch 0005: Train Acc 0.8696, Loss 0.6861, Test correct 174, Test unsure 41, Test Acc 0.7909\n",
      ">>>>Epoch 0006: Train Acc 0.8821, Loss 0.5909, Test correct 176, Test unsure 37, Test Acc 0.8000\n",
      ">>>>Epoch 0007: Train Acc 0.8912, Loss 0.5261, Test correct 178, Test unsure 35, Test Acc 0.8091\n",
      ">>>>Epoch 0008: Train Acc 0.8957, Loss 0.4571, Test correct 182, Test unsure 30, Test Acc 0.8273\n",
      ">>>>Epoch 0009: Train Acc 0.9036, Loss 0.4034, Test correct 189, Test unsure 23, Test Acc 0.8591\n",
      ">>>>Epoch 0010: Train Acc 0.9206, Loss 0.3545, Test correct 194, Test unsure 19, Test Acc 0.8818\n",
      "Epoch 0010, Train Acc 0.9206, Test Correct Num 194, Test Total Num 220, Test Unsure Num 19, Test Acc 0.8818\n",
      ">>>>Epoch 0001: Train Acc 0.4637, Loss 1.3723, Test correct 69, Test unsure 118, Test Acc 0.3136\n",
      ">>>>Epoch 0002: Train Acc 0.7619, Loss 1.1514, Test correct 147, Test unsure 72, Test Acc 0.6682\n",
      ">>>>Epoch 0003: Train Acc 0.8209, Loss 0.9582, Test correct 164, Test unsure 49, Test Acc 0.7455\n",
      ">>>>Epoch 0004: Train Acc 0.8288, Loss 0.8081, Test correct 165, Test unsure 41, Test Acc 0.7500\n",
      ">>>>Epoch 0005: Train Acc 0.8322, Loss 0.6957, Test correct 165, Test unsure 33, Test Acc 0.7500\n",
      ">>>>Epoch 0006: Train Acc 0.8390, Loss 0.6099, Test correct 166, Test unsure 24, Test Acc 0.7545\n",
      ">>>>Epoch 0007: Train Acc 0.8469, Loss 0.5472, Test correct 167, Test unsure 23, Test Acc 0.7591\n",
      ">>>>Epoch 0008: Train Acc 0.8583, Loss 0.4864, Test correct 168, Test unsure 22, Test Acc 0.7636\n",
      ">>>>Epoch 0009: Train Acc 0.8764, Loss 0.4386, Test correct 173, Test unsure 23, Test Acc 0.7864\n",
      ">>>>Epoch 0010: Train Acc 0.8957, Loss 0.3916, Test correct 177, Test unsure 19, Test Acc 0.8045\n",
      "Epoch 0010, Train Acc 0.8957, Test Correct Num 177, Test Total Num 220, Test Unsure Num 19, Test Acc 0.8045\n",
      ">>>>Epoch 0001: Train Acc 0.5351, Loss 1.2668, Test correct 114, Test unsure 103, Test Acc 0.5182\n",
      ">>>>Epoch 0002: Train Acc 0.6939, Loss 1.0887, Test correct 141, Test unsure 71, Test Acc 0.6409\n",
      ">>>>Epoch 0003: Train Acc 0.7676, Loss 0.9362, Test correct 150, Test unsure 56, Test Acc 0.6818\n",
      ">>>>Epoch 0004: Train Acc 0.7902, Loss 0.8211, Test correct 158, Test unsure 39, Test Acc 0.7182\n",
      ">>>>Epoch 0005: Train Acc 0.8061, Loss 0.7167, Test correct 162, Test unsure 34, Test Acc 0.7364\n",
      ">>>>Epoch 0006: Train Acc 0.8197, Loss 0.6341, Test correct 163, Test unsure 32, Test Acc 0.7409\n",
      ">>>>Epoch 0007: Train Acc 0.8265, Loss 0.5733, Test correct 166, Test unsure 32, Test Acc 0.7545\n",
      ">>>>Epoch 0008: Train Acc 0.8469, Loss 0.5117, Test correct 167, Test unsure 32, Test Acc 0.7591\n",
      ">>>>Epoch 0009: Train Acc 0.8696, Loss 0.4523, Test correct 170, Test unsure 28, Test Acc 0.7727\n",
      ">>>>Epoch 0010: Train Acc 0.8900, Loss 0.4087, Test correct 174, Test unsure 27, Test Acc 0.7909\n",
      "Epoch 0010, Train Acc 0.8900, Test Correct Num 174, Test Total Num 220, Test Unsure Num 27, Test Acc 0.7909\n",
      ">>>>Epoch 0001: Train Acc 0.4807, Loss 1.2329, Test correct 110, Test unsure 63, Test Acc 0.5000\n",
      ">>>>Epoch 0002: Train Acc 0.5113, Loss 1.0755, Test correct 114, Test unsure 51, Test Acc 0.5182\n",
      ">>>>Epoch 0003: Train Acc 0.5567, Loss 0.9397, Test correct 115, Test unsure 43, Test Acc 0.5227\n",
      ">>>>Epoch 0004: Train Acc 0.6383, Loss 0.8342, Test correct 118, Test unsure 37, Test Acc 0.5364\n",
      ">>>>Epoch 0005: Train Acc 0.7143, Loss 0.7464, Test correct 132, Test unsure 35, Test Acc 0.6000\n",
      ">>>>Epoch 0006: Train Acc 0.7925, Loss 0.6632, Test correct 144, Test unsure 34, Test Acc 0.6545\n",
      ">>>>Epoch 0007: Train Acc 0.8458, Loss 0.5880, Test correct 157, Test unsure 33, Test Acc 0.7136\n",
      ">>>>Epoch 0008: Train Acc 0.8889, Loss 0.5250, Test correct 166, Test unsure 31, Test Acc 0.7545\n",
      ">>>>Epoch 0009: Train Acc 0.9127, Loss 0.4684, Test correct 178, Test unsure 23, Test Acc 0.8091\n",
      ">>>>Epoch 0010: Train Acc 0.9274, Loss 0.4090, Test correct 188, Test unsure 21, Test Acc 0.8545\n",
      "Epoch 0010, Train Acc 0.9274, Test Correct Num 188, Test Total Num 220, Test Unsure Num 21, Test Acc 0.8545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>Epoch 0001: Train Acc 0.7234, Loss 1.1887, Test correct 145, Test unsure 75, Test Acc 0.6591\n",
      ">>>>Epoch 0002: Train Acc 0.7823, Loss 0.9907, Test correct 159, Test unsure 60, Test Acc 0.7227\n",
      ">>>>Epoch 0003: Train Acc 0.8095, Loss 0.8348, Test correct 161, Test unsure 56, Test Acc 0.7318\n",
      ">>>>Epoch 0004: Train Acc 0.8322, Loss 0.7123, Test correct 164, Test unsure 50, Test Acc 0.7455\n",
      ">>>>Epoch 0005: Train Acc 0.8469, Loss 0.6174, Test correct 171, Test unsure 40, Test Acc 0.7773\n",
      ">>>>Epoch 0006: Train Acc 0.8673, Loss 0.5241, Test correct 177, Test unsure 33, Test Acc 0.8045\n",
      ">>>>Epoch 0007: Train Acc 0.8878, Loss 0.4704, Test correct 181, Test unsure 29, Test Acc 0.8227\n",
      ">>>>Epoch 0008: Train Acc 0.9025, Loss 0.4114, Test correct 185, Test unsure 24, Test Acc 0.8409\n",
      ">>>>Epoch 0009: Train Acc 0.9218, Loss 0.3590, Test correct 193, Test unsure 18, Test Acc 0.8773\n",
      ">>>>Epoch 0010: Train Acc 0.9410, Loss 0.3214, Test correct 199, Test unsure 15, Test Acc 0.9045\n",
      "Epoch 0010, Train Acc 0.9410, Test Correct Num 199, Test Total Num 220, Test Unsure Num 15, Test Acc 0.9045\n",
      ">>>>Epoch 0001: Train Acc 0.7188, Loss 1.0522, Test correct 155, Test unsure 62, Test Acc 0.7045\n",
      ">>>>Epoch 0002: Train Acc 0.7517, Loss 0.8972, Test correct 156, Test unsure 61, Test Acc 0.7091\n",
      ">>>>Epoch 0003: Train Acc 0.7993, Loss 0.7731, Test correct 161, Test unsure 54, Test Acc 0.7318\n",
      ">>>>Epoch 0004: Train Acc 0.8288, Loss 0.6693, Test correct 168, Test unsure 45, Test Acc 0.7636\n",
      ">>>>Epoch 0005: Train Acc 0.8537, Loss 0.5917, Test correct 173, Test unsure 39, Test Acc 0.7864\n",
      ">>>>Epoch 0006: Train Acc 0.8753, Loss 0.5262, Test correct 177, Test unsure 35, Test Acc 0.8045\n",
      ">>>>Epoch 0007: Train Acc 0.8957, Loss 0.4596, Test correct 184, Test unsure 28, Test Acc 0.8364\n",
      ">>>>Epoch 0008: Train Acc 0.9184, Loss 0.4039, Test correct 189, Test unsure 24, Test Acc 0.8591\n",
      ">>>>Epoch 0009: Train Acc 0.9342, Loss 0.3584, Test correct 194, Test unsure 21, Test Acc 0.8818\n",
      ">>>>Epoch 0010: Train Acc 0.9467, Loss 0.3184, Test correct 200, Test unsure 13, Test Acc 0.9091\n",
      "Epoch 0010, Train Acc 0.9467, Test Correct Num 200, Test Total Num 220, Test Unsure Num 13, Test Acc 0.9091\n",
      ">>>>Epoch 0001: Train Acc 0.7143, Loss 1.0096, Test correct 146, Test unsure 64, Test Acc 0.6636\n",
      ">>>>Epoch 0002: Train Acc 0.7778, Loss 0.8596, Test correct 150, Test unsure 59, Test Acc 0.6818\n",
      ">>>>Epoch 0003: Train Acc 0.8163, Loss 0.7391, Test correct 159, Test unsure 50, Test Acc 0.7227\n",
      ">>>>Epoch 0004: Train Acc 0.8379, Loss 0.6382, Test correct 167, Test unsure 43, Test Acc 0.7591\n",
      ">>>>Epoch 0005: Train Acc 0.8662, Loss 0.5621, Test correct 172, Test unsure 40, Test Acc 0.7818\n",
      ">>>>Epoch 0006: Train Acc 0.8878, Loss 0.4952, Test correct 180, Test unsure 34, Test Acc 0.8182\n",
      ">>>>Epoch 0007: Train Acc 0.9002, Loss 0.4357, Test correct 187, Test unsure 27, Test Acc 0.8500\n",
      ">>>>Epoch 0008: Train Acc 0.9252, Loss 0.3798, Test correct 193, Test unsure 22, Test Acc 0.8773\n",
      ">>>>Epoch 0009: Train Acc 0.9388, Loss 0.3369, Test correct 200, Test unsure 15, Test Acc 0.9091\n",
      ">>>>Epoch 0010: Train Acc 0.9467, Loss 0.2948, Test correct 203, Test unsure 13, Test Acc 0.9227\n",
      "Epoch 0010, Train Acc 0.9467, Test Correct Num 203, Test Total Num 220, Test Unsure Num 13, Test Acc 0.9227\n",
      ">>>>Epoch 0001: Train Acc 0.8923, Loss 0.6541, Test correct 171, Test unsure 38, Test Acc 0.7773\n",
      ">>>>Epoch 0002: Train Acc 0.9172, Loss 0.5278, Test correct 183, Test unsure 32, Test Acc 0.8318\n",
      ">>>>Epoch 0003: Train Acc 0.9240, Loss 0.4486, Test correct 189, Test unsure 26, Test Acc 0.8591\n",
      ">>>>Epoch 0004: Train Acc 0.9342, Loss 0.3713, Test correct 201, Test unsure 15, Test Acc 0.9136\n",
      ">>>>Epoch 0005: Train Acc 0.9422, Loss 0.3204, Test correct 203, Test unsure 13, Test Acc 0.9227\n",
      ">>>>Epoch 0006: Train Acc 0.9535, Loss 0.2680, Test correct 204, Test unsure 12, Test Acc 0.9273\n",
      ">>>>Epoch 0007: Train Acc 0.9671, Loss 0.2346, Test correct 206, Test unsure 10, Test Acc 0.9364\n",
      ">>>>Epoch 0008: Train Acc 0.9751, Loss 0.2002, Test correct 209, Test unsure 7, Test Acc 0.9500\n",
      ">>>>Epoch 0009: Train Acc 0.9841, Loss 0.1717, Test correct 211, Test unsure 6, Test Acc 0.9591\n",
      ">>>>Epoch 0010: Train Acc 0.9875, Loss 0.1464, Test correct 212, Test unsure 5, Test Acc 0.9636\n",
      "Epoch 0010, Train Acc 0.9875, Test Correct Num 212, Test Total Num 220, Test Unsure Num 5, Test Acc 0.9636\n",
      ">>>>Epoch 0001: Train Acc 0.7721, Loss 0.9149, Test correct 157, Test unsure 58, Test Acc 0.7136\n",
      ">>>>Epoch 0002: Train Acc 0.8027, Loss 0.7808, Test correct 162, Test unsure 45, Test Acc 0.7364\n",
      ">>>>Epoch 0003: Train Acc 0.8220, Loss 0.6797, Test correct 164, Test unsure 40, Test Acc 0.7455\n",
      ">>>>Epoch 0004: Train Acc 0.8345, Loss 0.6048, Test correct 167, Test unsure 37, Test Acc 0.7591\n",
      ">>>>Epoch 0005: Train Acc 0.8537, Loss 0.5369, Test correct 172, Test unsure 32, Test Acc 0.7818\n",
      ">>>>Epoch 0006: Train Acc 0.8696, Loss 0.4738, Test correct 176, Test unsure 31, Test Acc 0.8000\n",
      ">>>>Epoch 0007: Train Acc 0.8900, Loss 0.4190, Test correct 181, Test unsure 28, Test Acc 0.8227\n",
      ">>>>Epoch 0008: Train Acc 0.9082, Loss 0.3737, Test correct 189, Test unsure 24, Test Acc 0.8591\n",
      ">>>>Epoch 0009: Train Acc 0.9365, Loss 0.3296, Test correct 198, Test unsure 17, Test Acc 0.9000\n",
      ">>>>Epoch 0010: Train Acc 0.9456, Loss 0.2890, Test correct 202, Test unsure 13, Test Acc 0.9182\n",
      "Epoch 0010, Train Acc 0.9456, Test Correct Num 202, Test Total Num 220, Test Unsure Num 13, Test Acc 0.9182\n",
      "--- Finished Adam\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:78550.53496360779ms\n",
      "Currently in generation 3\n",
      "--- Starting Adam\n",
      ">>>>Epoch 0001: Train Acc 0.8197, Loss 0.7597, Test correct 156, Test unsure 49, Test Acc 0.7091\n",
      ">>>>Epoch 0002: Train Acc 0.8537, Loss 0.6689, Test correct 161, Test unsure 46, Test Acc 0.7318\n",
      ">>>>Epoch 0003: Train Acc 0.8730, Loss 0.6007, Test correct 164, Test unsure 46, Test Acc 0.7455\n",
      ">>>>Epoch 0004: Train Acc 0.8821, Loss 0.5307, Test correct 170, Test unsure 42, Test Acc 0.7727\n",
      ">>>>Epoch 0005: Train Acc 0.9002, Loss 0.4725, Test correct 179, Test unsure 34, Test Acc 0.8136\n",
      ">>>>Epoch 0006: Train Acc 0.9138, Loss 0.4166, Test correct 187, Test unsure 27, Test Acc 0.8500\n",
      ">>>>Epoch 0007: Train Acc 0.9297, Loss 0.3717, Test correct 195, Test unsure 19, Test Acc 0.8864\n",
      ">>>>Epoch 0008: Train Acc 0.9524, Loss 0.3241, Test correct 201, Test unsure 14, Test Acc 0.9136\n",
      ">>>>Epoch 0009: Train Acc 0.9626, Loss 0.2846, Test correct 203, Test unsure 12, Test Acc 0.9227\n",
      ">>>>Epoch 0010: Train Acc 0.9751, Loss 0.2497, Test correct 207, Test unsure 10, Test Acc 0.9409\n",
      "Epoch 0010, Train Acc 0.9751, Test Correct Num 207, Test Total Num 220, Test Unsure Num 10, Test Acc 0.9409\n",
      ">>>>Epoch 0001: Train Acc 0.8141, Loss 0.8340, Test correct 159, Test unsure 55, Test Acc 0.7227\n",
      ">>>>Epoch 0002: Train Acc 0.8356, Loss 0.7401, Test correct 164, Test unsure 49, Test Acc 0.7455\n",
      ">>>>Epoch 0003: Train Acc 0.8503, Loss 0.6562, Test correct 165, Test unsure 47, Test Acc 0.7500\n",
      ">>>>Epoch 0004: Train Acc 0.8685, Loss 0.5863, Test correct 167, Test unsure 46, Test Acc 0.7591\n",
      ">>>>Epoch 0005: Train Acc 0.8855, Loss 0.5170, Test correct 175, Test unsure 39, Test Acc 0.7955\n",
      ">>>>Epoch 0006: Train Acc 0.9082, Loss 0.4586, Test correct 180, Test unsure 33, Test Acc 0.8182\n",
      ">>>>Epoch 0007: Train Acc 0.9184, Loss 0.4131, Test correct 188, Test unsure 26, Test Acc 0.8545\n",
      ">>>>Epoch 0008: Train Acc 0.9365, Loss 0.3641, Test correct 194, Test unsure 22, Test Acc 0.8818\n",
      ">>>>Epoch 0009: Train Acc 0.9478, Loss 0.3189, Test correct 199, Test unsure 17, Test Acc 0.9045\n",
      ">>>>Epoch 0010: Train Acc 0.9535, Loss 0.2818, Test correct 205, Test unsure 11, Test Acc 0.9318\n",
      "Epoch 0010, Train Acc 0.9535, Test Correct Num 205, Test Total Num 220, Test Unsure Num 11, Test Acc 0.9318\n",
      ">>>>Epoch 0001: Train Acc 0.8254, Loss 0.7611, Test correct 157, Test unsure 48, Test Acc 0.7136\n",
      ">>>>Epoch 0002: Train Acc 0.8469, Loss 0.6714, Test correct 161, Test unsure 45, Test Acc 0.7318\n",
      ">>>>Epoch 0003: Train Acc 0.8628, Loss 0.5974, Test correct 165, Test unsure 41, Test Acc 0.7500\n",
      ">>>>Epoch 0004: Train Acc 0.8821, Loss 0.5337, Test correct 171, Test unsure 35, Test Acc 0.7773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>Epoch 0005: Train Acc 0.8991, Loss 0.4736, Test correct 177, Test unsure 33, Test Acc 0.8045\n",
      ">>>>Epoch 0006: Train Acc 0.9138, Loss 0.4217, Test correct 186, Test unsure 26, Test Acc 0.8455\n",
      ">>>>Epoch 0007: Train Acc 0.9331, Loss 0.3712, Test correct 197, Test unsure 16, Test Acc 0.8955\n",
      ">>>>Epoch 0008: Train Acc 0.9467, Loss 0.3318, Test correct 200, Test unsure 14, Test Acc 0.9091\n",
      ">>>>Epoch 0009: Train Acc 0.9535, Loss 0.2925, Test correct 203, Test unsure 12, Test Acc 0.9227\n",
      ">>>>Epoch 0010: Train Acc 0.9683, Loss 0.2530, Test correct 204, Test unsure 12, Test Acc 0.9273\n",
      "Epoch 0010, Train Acc 0.9683, Test Correct Num 204, Test Total Num 220, Test Unsure Num 12, Test Acc 0.9273\n",
      ">>>>Epoch 0001: Train Acc 0.8073, Loss 0.8575, Test correct 160, Test unsure 57, Test Acc 0.7273\n",
      ">>>>Epoch 0002: Train Acc 0.8118, Loss 0.7602, Test correct 161, Test unsure 49, Test Acc 0.7318\n",
      ">>>>Epoch 0003: Train Acc 0.8254, Loss 0.6794, Test correct 162, Test unsure 45, Test Acc 0.7364\n",
      ">>>>Epoch 0004: Train Acc 0.8447, Loss 0.5998, Test correct 164, Test unsure 44, Test Acc 0.7455\n",
      ">>>>Epoch 0005: Train Acc 0.8673, Loss 0.5449, Test correct 166, Test unsure 41, Test Acc 0.7545\n",
      ">>>>Epoch 0006: Train Acc 0.8855, Loss 0.4807, Test correct 170, Test unsure 38, Test Acc 0.7727\n",
      ">>>>Epoch 0007: Train Acc 0.9048, Loss 0.4312, Test correct 177, Test unsure 34, Test Acc 0.8045\n",
      ">>>>Epoch 0008: Train Acc 0.9286, Loss 0.3785, Test correct 184, Test unsure 28, Test Acc 0.8364\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-dc66c529c011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                \u001b[0mnum_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cells\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_genes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                      \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                      labels = labels)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mTrain_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"All Time:{(Train_start-Train_end)*1000}ms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-18769dddc60c>\u001b[0m in \u001b[0;36mGA_Neural_train\u001b[0;34m(population, pop_size, max_generations, Adam_epochs, GA_steps, offspring_size, elitist_level, rho, learning_rate, weight_decay, batch_size, num_cells, num_genes, graph, train_ids, test_ids, labels)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                         \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                         labels = labels)\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Finished Adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-97c4b4ac5ba7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmax_test_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mtrain_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_unsure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-97c4b4ac5ba7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_nids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Train_start = time.time()\n",
    "trained_population = GA_Neural_train(population=population,\n",
    "                                    pop_size = pop_size,\n",
    "                                    max_generations=max_generations,\n",
    "                                    Adam_epochs=Adam_epochs,GA_steps=GA_steps,\n",
    "                                    offspring_size=offspring_size,elitist_level=elitist_level,rho=rho,\n",
    "                                    learning_rate=learning_rate,\n",
    "                               weight_decay = weight_decay,\n",
    "                               batch_size = batch_size,\n",
    "                               num_cells = num_cells,num_genes = num_genes,graph = graph,\n",
    "                                     train_ids = train_ids,test_ids = test_ids,\n",
    "                                     labels = labels)\n",
    "Train_end = time.time()\n",
    "print(f\"All Time:{(Train_start-Train_end)*1000}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8583e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
