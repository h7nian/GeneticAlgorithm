{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f045d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from momentumnet import MomentumNet\n",
    "from momentumnet import transform_to_momentumnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import time\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74d3bb",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c36e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,gene_matrix,cell_type):\n",
    "        \n",
    "        self.gene_matrix = torch.from_numpy(gene_matrix).float()\n",
    "        self.cell_type = torch.from_numpy(cell_type).squeeze(1)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.gene_matrix.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        data = (self.gene_matrix[idx],self.cell_type[idx])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d6de9",
   "metadata": {},
   "source": [
    "# Create PBMC DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8ab9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pbmc1_loader(pbmc_path,cell_type_path,batch_size=128):\n",
    "\n",
    "    pbmc = pd.read_csv(pbmc_path,header=None)\n",
    "    cell_type = pd.read_csv(cell_type_path,index_col = 0)\n",
    "    \n",
    "    full_dataset = MyDataset(pbmc.values,cell_type.values)\n",
    "\n",
    "    #Random split(0.7,0.3)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    # Define DataLoaders\n",
    "    # use 'loky' to work with joblib\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,   batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19854d3b",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca283aa",
   "metadata": {},
   "source": [
    "## Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.normal(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40651976",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.lr1 = nn.Linear(3500,1000)\n",
    "        self.lr2 = nn.Linear(1000,128)\n",
    "        self.lr3 = nn.Linear(128,64)\n",
    "        \n",
    "        self.lr = nn.Linear(64,9)\n",
    "        \n",
    "        self.apply(_weights_init)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.lr1(x))\n",
    "        x = self.lr2(x)\n",
    "        x = F.relu(self.lr3(x))\n",
    "        \n",
    "        output = self.lr(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5518d",
   "metadata": {},
   "source": [
    "# SGD_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_training(network, SGD_steps, lr, momentum, data_loader):\n",
    "\n",
    "    network.to(device)\n",
    "    network.train()\n",
    "\n",
    "    # Create optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr, momentum=momentum, nesterov=True, weight_decay=0.0001)\n",
    "    \n",
    "    total_step = len(data_loader)\n",
    "    \n",
    "    for s in range(0, SGD_steps):\n",
    "        total_loss = 0\n",
    "        for i, (genes, types) in enumerate(data_loader): \n",
    "            \n",
    "            genes = genes.to(device)\n",
    "            types = types.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = network(genes) \n",
    "            \n",
    "            loss = criterion(outputs, types)\n",
    "            total_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            #Gradient Value Clipping\n",
    "            nn.utils.clip_grad_value_(network.parameters(), clip_value=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            del loss, outputs\n",
    "            \n",
    "            #if (i+1) % 100 == 0:\n",
    "        total_loss = total_loss / len(data_loader.sampler)\n",
    "        print (\"Epoch [{}/{}], Loss: {}\".format(s+1, SGD_steps, total_loss))\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    # move network back to cpu and return\n",
    "    network.cpu()\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cbc05",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e06989",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crossover_and_mutation(parents, sigma=0.01):\n",
    "\n",
    "    \n",
    "    base_sd = parents[0].state_dict()\n",
    "    keys = base_sd                    # use all layers to be affected\n",
    "    \n",
    "    # Sum of the weights of the parent\n",
    "    for i in range(1, len(parents)):\n",
    "        parent_sd = parents[i].state_dict()\n",
    "        for key in keys:\n",
    "            base_sd[key] = base_sd[key] + parent_sd[key]\n",
    "            \n",
    "    \n",
    "    # Average and add mutation\n",
    "    num_parents = len(parents)\n",
    "    \n",
    "    for key in keys:\n",
    "        \n",
    "        tensor_size = base_sd[key].size()\n",
    "        random_tensor = torch.normal(mean=0.0, std=sigma, size=tensor_size)\n",
    "        \n",
    "        base_sd[key] = (base_sd[key] / num_parents) + random_tensor\n",
    "    \n",
    "    # create offspring\n",
    "    offspring = MLP()\n",
    "    \n",
    "    offspring.load_state_dict(base_sd)\n",
    "    \n",
    "    return offspring\n",
    "    \n",
    "\n",
    "def create_offspring(population, fitness, rho, sigma):\n",
    "\n",
    "    \n",
    "    # Perform selection\n",
    "    parents = random.choices(population, weights=fitness, k=rho) \n",
    "    \n",
    "    # Perform crossover and mutation\n",
    "    offspring = crossover_and_mutation(parents, sigma)\n",
    "    \n",
    "    \n",
    "    return offspring\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, data_loader):\n",
    "    \n",
    "    #Calculate fitness of trained population\n",
    "\n",
    "    fitness = [calc_loss(population[i], data_loader) for i in range(pop_size)]\n",
    "    \n",
    "    print(f\"--- -- Finished fitness evaluation, length: {len(fitness)}\")\n",
    "    \n",
    "    #Create offspring population\n",
    "    fitness_weighted = [sigmoid(-f) for f in fitness]   # take inverse of loss so lower losses get higher fitness-values\n",
    "    offspring_population = [create_offspring(population, fitness_weighted, rho, sigma) for i in range(offspring_size)]\n",
    "    print(\"--- -- Finished creating offspring population\")\n",
    "    \n",
    "    #Evaluate fitness of offsprings \n",
    "    \n",
    "    offspring_fitness = [calc_loss(offspring_population[i], data_loader) for i in range(offspring_size)]\n",
    "    print(\"--- -- Finished evaluating fitness of offspring population\")\n",
    "    \n",
    "    # Combine fitness and population lists\n",
    "    \n",
    "    combined_fitness = fitness + offspring_fitness\n",
    "    combined_population = population + offspring_population\n",
    "    \n",
    "    # sort and select population by their fitness values\n",
    "    \n",
    "    sorted_population = [pop for _, pop in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    sorted_fitness = [loss for loss, _ in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    \n",
    "    m = int(pop_size * elitist_level)\n",
    "    new_population = sorted_population[0:m]\n",
    "    \n",
    "    # Fill up rest of population\n",
    "    difference = pop_size - m\n",
    "    remaining_population = list(set(sorted_population) - set(new_population))\n",
    "    filler_population = random.sample(remaining_population, difference)\n",
    "    \n",
    "    # assemble new population and return\n",
    "    new_population = new_population + filler_population\n",
    "    \n",
    "    return new_population, sorted_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d538178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(network, data_loader):\n",
    "    \n",
    "    network.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, (genes, types) in enumerate(data_loader):\n",
    "        \n",
    "        genes = genes.to(device)\n",
    "        types = types.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = network(genes)\n",
    "        loss = criterion(outputs, types)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "        del loss, outputs\n",
    "        \n",
    "    network.cpu()\n",
    "    \n",
    "    return float(total_loss/len(data_loader.sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657950d",
   "metadata": {},
   "source": [
    "# GA_Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14faa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_Neural_train(population,\n",
    "                    pop_size,\n",
    "                    max_generations, \n",
    "                    SGD_steps, GA_steps, \n",
    "                    offspring_size, elitist_level, rho,\n",
    "                    learning_rate,\n",
    "                    train_loader):\n",
    "    \n",
    "    print(f\"Starting with population of size: {pop_size}\")\n",
    "    \n",
    "    \n",
    "    for k in range(max_generations):\n",
    "        print(f\"Currently in generation {k+1}\")\n",
    "        \n",
    "        #SGD\n",
    "        print(f\"--- Starting SGD\")\n",
    "        \n",
    "        # Sequential version\n",
    "        population = [SGD_training(population[i], SGD_steps, learning_rate, 0.9, train_loader) for i in range(pop_size)]\n",
    "        \n",
    "        print(f\"--- Finished SGD\")\n",
    "         \n",
    "        # GA\n",
    "        print(f\"--- Starting GA\")\n",
    "        GA_start = time.time()\n",
    "        sorted_fitness = []          # store the sorted fitness values to maybe use in data collection\n",
    "        for i in range(0, GA_steps):\n",
    "            \n",
    "            sigma = 0.01 / (k+1)\n",
    "            population, sorted_fitness = GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, train_loader)\n",
    "        \n",
    "        GA_end = time.time()\n",
    "        print(f\"--- Finished GA,Time:{(GA_start-GA_end)*1000}ms\")\n",
    "        \n",
    "        \n",
    "    print(f\"Finished training process\")\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab74ac",
   "metadata": {},
   "source": [
    "# Start training process\n",
    "We have now defined the whole training algorithm. The next step is to actually perform training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61e033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "pop_size = 2\n",
    "max_generations = 10\n",
    "SGD_steps = 10\n",
    "GA_steps = 1\n",
    "offspring_size = 2\n",
    "elitist_level = 0.6\n",
    "rho = 2\n",
    "learning_rate = 1e-5\n",
    "pbmc_1 = \"data/pbmc_1_pca.csv\"\n",
    "cell_type_pbmc1 = \"data/cell_type_pbmc1.csv\"\n",
    "pbmc_2 = \"data/pbmc_2_pca.csv\"\n",
    "cell_type_pbmc2 = \"data/cell_type_pbmc2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc6c219",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_pbmc1_loader(pbmc_1,cell_type_pbmc1,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67dcc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population and start training process\n",
    "population = [MLP() for i in range(pop_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbe831",
   "metadata": {},
   "source": [
    "# Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0c8c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with population of size: 2\n",
      "Currently in generation 1\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 2035.1902551020407\n",
      "Epoch [2/10], Loss: 1677.2460331632653\n",
      "Epoch [3/10], Loss: 1352.1584725765306\n",
      "Epoch [4/10], Loss: 1175.195306122449\n",
      "Epoch [5/10], Loss: 976.052512755102\n",
      "Epoch [6/10], Loss: 882.4413488520408\n",
      "Epoch [7/10], Loss: 798.506556122449\n",
      "Epoch [8/10], Loss: 717.8942155612245\n",
      "Epoch [9/10], Loss: 640.0279145408164\n",
      "Epoch [10/10], Loss: 553.5887069515306\n",
      "Epoch [1/10], Loss: 2518.559955357143\n",
      "Epoch [2/10], Loss: 2153.368125\n",
      "Epoch [3/10], Loss: 1720.134980867347\n",
      "Epoch [4/10], Loss: 1357.277844387755\n",
      "Epoch [5/10], Loss: 1103.2917346938775\n",
      "Epoch [6/10], Loss: 905.0523820153061\n",
      "Epoch [7/10], Loss: 771.0109518494897\n",
      "Epoch [8/10], Loss: 678.1053730867347\n",
      "Epoch [9/10], Loss: 598.4911862244898\n",
      "Epoch [10/10], Loss: 541.2546667729592\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-972.8894233703613ms\n",
      "Currently in generation 2\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 497.06274234693876\n",
      "Epoch [2/10], Loss: 449.89146603954083\n",
      "Epoch [3/10], Loss: 420.9526387117347\n",
      "Epoch [4/10], Loss: 377.8869172512755\n",
      "Epoch [5/10], Loss: 350.7831568877551\n",
      "Epoch [6/10], Loss: 327.34843510841836\n",
      "Epoch [7/10], Loss: 300.6852000956633\n",
      "Epoch [8/10], Loss: 280.3781664540816\n",
      "Epoch [9/10], Loss: 267.9679081632653\n",
      "Epoch [10/10], Loss: 248.00075573979592\n",
      "Epoch [1/10], Loss: 527.4487611607143\n",
      "Epoch [2/10], Loss: 481.412409119898\n",
      "Epoch [3/10], Loss: 427.028671875\n",
      "Epoch [4/10], Loss: 379.99373724489794\n",
      "Epoch [5/10], Loss: 341.6873445471939\n",
      "Epoch [6/10], Loss: 302.3655476721939\n",
      "Epoch [7/10], Loss: 283.71000159438773\n",
      "Epoch [8/10], Loss: 274.321165497449\n",
      "Epoch [9/10], Loss: 248.32884805484693\n",
      "Epoch [10/10], Loss: 228.78369180484694\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-1020.4658508300781ms\n",
      "Currently in generation 3\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 224.68835379464286\n",
      "Epoch [2/10], Loss: 209.81861447704082\n",
      "Epoch [3/10], Loss: 200.7874720982143\n",
      "Epoch [4/10], Loss: 205.55553212691328\n",
      "Epoch [5/10], Loss: 183.3088775510204\n",
      "Epoch [6/10], Loss: 176.0226737882653\n",
      "Epoch [7/10], Loss: 162.83879544005103\n",
      "Epoch [8/10], Loss: 160.1481373565051\n",
      "Epoch [9/10], Loss: 150.67704719387754\n",
      "Epoch [10/10], Loss: 144.36432238520408\n",
      "Epoch [1/10], Loss: 221.97562101403062\n",
      "Epoch [2/10], Loss: 205.80929807079082\n",
      "Epoch [3/10], Loss: 197.55852718431123\n",
      "Epoch [4/10], Loss: 196.38682637117347\n",
      "Epoch [5/10], Loss: 178.48127590880102\n",
      "Epoch [6/10], Loss: 167.8644583067602\n",
      "Epoch [7/10], Loss: 179.15169682716837\n",
      "Epoch [8/10], Loss: 161.8168152104592\n",
      "Epoch [9/10], Loss: 146.5222337372449\n",
      "Epoch [10/10], Loss: 141.85776805644133\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-745.8658218383789ms\n",
      "Currently in generation 4\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 144.54363440688775\n",
      "Epoch [2/10], Loss: 134.439114716199\n",
      "Epoch [3/10], Loss: 127.19568199936225\n",
      "Epoch [4/10], Loss: 118.1826542570153\n",
      "Epoch [5/10], Loss: 113.84765047034439\n",
      "Epoch [6/10], Loss: 108.24158063616072\n",
      "Epoch [7/10], Loss: 103.48806162308674\n",
      "Epoch [8/10], Loss: 98.87437739158163\n",
      "Epoch [9/10], Loss: 90.73193219866072\n",
      "Epoch [10/10], Loss: 88.76775271045918\n",
      "Epoch [1/10], Loss: 133.24978435905612\n",
      "Epoch [2/10], Loss: 143.1043215880102\n",
      "Epoch [3/10], Loss: 129.9371197385204\n",
      "Epoch [4/10], Loss: 116.87808753188776\n",
      "Epoch [5/10], Loss: 109.69840471540178\n",
      "Epoch [6/10], Loss: 114.78359813456633\n",
      "Epoch [7/10], Loss: 102.60279257015306\n",
      "Epoch [8/10], Loss: 96.75749242665816\n",
      "Epoch [9/10], Loss: 91.0135423309949\n",
      "Epoch [10/10], Loss: 85.19762261838329\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-936.3424777984619ms\n",
      "Currently in generation 5\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 87.60856086575255\n",
      "Epoch [2/10], Loss: 83.49915876116071\n",
      "Epoch [3/10], Loss: 78.05845304528061\n",
      "Epoch [4/10], Loss: 70.57521688655932\n",
      "Epoch [5/10], Loss: 72.16456393494897\n",
      "Epoch [6/10], Loss: 65.65366868622449\n",
      "Epoch [7/10], Loss: 63.80917610012755\n",
      "Epoch [8/10], Loss: 60.69312968351403\n",
      "Epoch [9/10], Loss: 53.839381477200256\n",
      "Epoch [10/10], Loss: 53.13204908721301\n",
      "Epoch [1/10], Loss: 82.1271780333227\n",
      "Epoch [2/10], Loss: 79.60720563616071\n",
      "Epoch [3/10], Loss: 79.67104472257653\n",
      "Epoch [4/10], Loss: 81.51010243941326\n",
      "Epoch [5/10], Loss: 75.59530951052295\n",
      "Epoch [6/10], Loss: 63.884305046237245\n",
      "Epoch [7/10], Loss: 61.82536092952806\n",
      "Epoch [8/10], Loss: 57.52159388950893\n",
      "Epoch [9/10], Loss: 56.05713682836416\n",
      "Epoch [10/10], Loss: 52.75672124123087\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-866.3508892059326ms\n",
      "Currently in generation 6\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 47.93550691565689\n",
      "Epoch [2/10], Loss: 47.86827258051658\n",
      "Epoch [3/10], Loss: 46.42576530612245\n",
      "Epoch [4/10], Loss: 44.89756527024873\n",
      "Epoch [5/10], Loss: 48.05696398676658\n",
      "Epoch [6/10], Loss: 38.78156489158163\n",
      "Epoch [7/10], Loss: 36.336883569834185\n",
      "Epoch [8/10], Loss: 33.85083128637197\n",
      "Epoch [9/10], Loss: 30.605807407924107\n",
      "Epoch [10/10], Loss: 28.225557288345026\n",
      "Epoch [1/10], Loss: 48.28664474798708\n",
      "Epoch [2/10], Loss: 46.39656379544005\n",
      "Epoch [3/10], Loss: 43.544276671117665\n",
      "Epoch [4/10], Loss: 43.77430584343112\n",
      "Epoch [5/10], Loss: 38.42654087611607\n",
      "Epoch [6/10], Loss: 37.42703892299107\n",
      "Epoch [7/10], Loss: 34.62497150031888\n",
      "Epoch [8/10], Loss: 35.65998560068559\n",
      "Epoch [9/10], Loss: 30.090752750318877\n",
      "Epoch [10/10], Loss: 29.89461353535555\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-989.0284538269043ms\n",
      "Currently in generation 7\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 26.868742875079718\n",
      "Epoch [2/10], Loss: 25.560673828125\n",
      "Epoch [3/10], Loss: 25.133204968510842\n",
      "Epoch [4/10], Loss: 23.551546282087052\n",
      "Epoch [5/10], Loss: 21.253774600904816\n",
      "Epoch [6/10], Loss: 20.023519461495535\n",
      "Epoch [7/10], Loss: 19.688520408163264\n",
      "Epoch [8/10], Loss: 17.59311233209104\n",
      "Epoch [9/10], Loss: 16.346390953842473\n",
      "Epoch [10/10], Loss: 15.31982212334263\n",
      "Epoch [1/10], Loss: 27.937190240353953\n",
      "Epoch [2/10], Loss: 25.9350792709662\n",
      "Epoch [3/10], Loss: 25.335686533402423\n",
      "Epoch [4/10], Loss: 25.404347048389667\n",
      "Epoch [5/10], Loss: 21.2538080207669\n",
      "Epoch [6/10], Loss: 21.52041895029496\n",
      "Epoch [7/10], Loss: 18.649388060277822\n",
      "Epoch [8/10], Loss: 18.06071799764828\n",
      "Epoch [9/10], Loss: 19.031143948301978\n",
      "Epoch [10/10], Loss: 15.20817776426977\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-1172.1696853637695ms\n",
      "Currently in generation 8\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 14.54631319007095\n",
      "Epoch [2/10], Loss: 13.514853291414221\n",
      "Epoch [3/10], Loss: 12.518615495331433\n",
      "Epoch [4/10], Loss: 11.863425255600287\n",
      "Epoch [5/10], Loss: 10.800012144750479\n",
      "Epoch [6/10], Loss: 10.364485268106266\n",
      "Epoch [7/10], Loss: 10.410326911770568\n",
      "Epoch [8/10], Loss: 8.537877393450056\n",
      "Epoch [9/10], Loss: 7.782055892944336\n",
      "Epoch [10/10], Loss: 7.175253731863839\n",
      "Epoch [1/10], Loss: 14.322640555245536\n",
      "Epoch [2/10], Loss: 13.739033651546556\n",
      "Epoch [3/10], Loss: 13.198517306580836\n",
      "Epoch [4/10], Loss: 12.477791474011479\n",
      "Epoch [5/10], Loss: 10.916065075932718\n",
      "Epoch [6/10], Loss: 10.040005462023677\n",
      "Epoch [7/10], Loss: 9.911373577507176\n",
      "Epoch [8/10], Loss: 8.577959112050582\n",
      "Epoch [9/10], Loss: 7.855298187878667\n",
      "Epoch [10/10], Loss: 7.953395493176519\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-1025.9149074554443ms\n",
      "Currently in generation 9\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 7.570862638512436\n",
      "Epoch [2/10], Loss: 6.210951345015546\n",
      "Epoch [3/10], Loss: 5.713553230129943\n",
      "Epoch [4/10], Loss: 5.2728635453204715\n",
      "Epoch [5/10], Loss: 4.750395769391741\n",
      "Epoch [6/10], Loss: 4.253474756357621\n",
      "Epoch [7/10], Loss: 3.9579871165995697\n",
      "Epoch [8/10], Loss: 3.544544461697948\n",
      "Epoch [9/10], Loss: 3.1382706373565052\n",
      "Epoch [10/10], Loss: 3.3715347476881377\n",
      "Epoch [1/10], Loss: 6.68926397206832\n",
      "Epoch [2/10], Loss: 6.350241562201052\n",
      "Epoch [3/10], Loss: 5.6303149164939414\n",
      "Epoch [4/10], Loss: 5.465822757020288\n",
      "Epoch [5/10], Loss: 4.790492180026307\n",
      "Epoch [6/10], Loss: 4.261333854830995\n",
      "Epoch [7/10], Loss: 3.87468158332669\n",
      "Epoch [8/10], Loss: 3.5695894140126754\n",
      "Epoch [9/10], Loss: 3.5101175860969387\n",
      "Epoch [10/10], Loss: 2.8641651636240435\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-791.2368774414062ms\n",
      "Currently in generation 10\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 2.8503160030987797\n",
      "Epoch [2/10], Loss: 2.3996128502670597\n",
      "Epoch [3/10], Loss: 2.0561892038097187\n",
      "Epoch [4/10], Loss: 2.399404116260762\n",
      "Epoch [5/10], Loss: 1.6250599203304368\n",
      "Epoch [6/10], Loss: 1.5372944594402702\n",
      "Epoch [7/10], Loss: 1.3126760739696268\n",
      "Epoch [8/10], Loss: 1.1198082997847576\n",
      "Epoch [9/10], Loss: 0.9763906824345492\n",
      "Epoch [10/10], Loss: 0.920366024095185\n",
      "Epoch [1/10], Loss: 2.516805345184949\n",
      "Epoch [2/10], Loss: 2.32331509959941\n",
      "Epoch [3/10], Loss: 2.128458999322385\n",
      "Epoch [4/10], Loss: 1.8358615610550861\n",
      "Epoch [5/10], Loss: 1.5923596359906766\n",
      "Epoch [6/10], Loss: 1.357850566007653\n",
      "Epoch [7/10], Loss: 1.2049553014794174\n",
      "Epoch [8/10], Loss: 1.1244791459064094\n",
      "Epoch [9/10], Loss: 1.0112397719402701\n",
      "Epoch [10/10], Loss: 0.8749206651960101\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 2\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-980.3774356842041ms\n",
      "Finished training process\n",
      "All Time:-43949.246644973755ms\n"
     ]
    }
   ],
   "source": [
    "Train_start = time.time()\n",
    "trained_population = GA_Neural_train(population=population,\n",
    "                                    pop_size = pop_size,\n",
    "                                    max_generations=max_generations,\n",
    "                                    SGD_steps=SGD_steps,GA_steps=GA_steps,\n",
    "                                    offspring_size=offspring_size,elitist_level=elitist_level,rho=rho,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    train_loader=train_loader)\n",
    "Train_end = time.time()\n",
    "print(f\"All Time:{(Train_start-Train_end)*1000}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c10858",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "676ced0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_function(network, data_loader):\n",
    "    # init accuracy\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for genes, types in data_loader:\n",
    "            genes = genes.to(device)\n",
    "            types = types.to(device)\n",
    "            outputs = network(genes)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += genes.size(0)\n",
    "            \n",
    "            correct += (predicted == types).sum().item()\n",
    "\n",
    "        accuracy =  correct / total\n",
    "        #print('Accuracy of the model on the test images: {} %'.format(accuracy))\n",
    "        \n",
    "    # send network back to cpu\n",
    "    network.cpu()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedcf55a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b784ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = [test_function(trained_population[i],test_loader) for i in range(pop_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c028748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6971428571428572, 0.6971428571428572]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04916cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6971428571428572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_accuracy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b3285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
