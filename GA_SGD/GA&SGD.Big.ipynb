{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f045d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from momentumnet import MomentumNet\n",
    "from momentumnet import transform_to_momentumnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74d3bb",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c36e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,gene_matrix,cell_type):\n",
    "        \n",
    "        self.gene_matrix = torch.from_numpy(gene_matrix).float()\n",
    "        self.cell_type = torch.from_numpy(cell_type).squeeze(1)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.gene_matrix.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        data = (self.gene_matrix[idx],self.cell_type[idx])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d6de9",
   "metadata": {},
   "source": [
    "# Create PBMC DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8ab9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pbmc1_loader(pbmc_path,cell_type_path,batch_size=128):\n",
    "\n",
    "    pbmc = pd.read_csv(pbmc_path,header=None)\n",
    "    cell_type = pd.read_csv(cell_type_path,index_col = 0)\n",
    "    \n",
    "    full_dataset = MyDataset(pbmc.values,cell_type.values)\n",
    "\n",
    "    #Random split(0.7,0.3)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    # Define DataLoaders\n",
    "    # use 'loky' to work with joblib\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,   batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19854d3b",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca283aa",
   "metadata": {},
   "source": [
    "## Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.normal(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40651976",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.lr1 = nn.Linear(3500,1000)\n",
    "        self.lr2 = nn.Linear(1000,128)\n",
    "        self.lr3 = nn.Linear(128,64)\n",
    "        \n",
    "        self.lr = nn.Linear(64,9)\n",
    "        \n",
    "        self.apply(_weights_init)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.lr1(x))\n",
    "        x = self.lr2(x)\n",
    "        x = F.relu(self.lr3(x))\n",
    "        \n",
    "        output = self.lr(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5518d",
   "metadata": {},
   "source": [
    "# SGD_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_training(network, SGD_steps, lr, momentum, data_loader):\n",
    "\n",
    "    network.to(device)\n",
    "    network.train()\n",
    "\n",
    "    # Create optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr, momentum=momentum, nesterov=True, weight_decay=0.0001)\n",
    "    \n",
    "    total_step = len(data_loader)\n",
    "    \n",
    "    for s in range(0, SGD_steps):\n",
    "        total_loss = 0\n",
    "        for i, (genes, types) in enumerate(data_loader): \n",
    "            \n",
    "            genes = genes.to(device)\n",
    "            types = types.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = network(genes) \n",
    "            \n",
    "            loss = criterion(outputs, types)\n",
    "            total_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            #Gradient Value Clipping\n",
    "            nn.utils.clip_grad_value_(network.parameters(), clip_value=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            del loss, outputs\n",
    "            \n",
    "            #if (i+1) % 100 == 0:\n",
    "        total_loss = total_loss / len(data_loader.sampler)\n",
    "        print (\"Epoch [{}/{}], Loss: {}\".format(s+1, SGD_steps, total_loss))\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    # move network back to cpu and return\n",
    "    network.cpu()\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cbc05",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e06989",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crossover_and_mutation(parents, sigma=0.01):\n",
    "\n",
    "    \n",
    "    base_sd = parents[0].state_dict()\n",
    "    keys = base_sd                    # use all layers to be affected\n",
    "    \n",
    "    # Sum of the weights of the parent\n",
    "    for i in range(1, len(parents)):\n",
    "        parent_sd = parents[i].state_dict()\n",
    "        for key in keys:\n",
    "            base_sd[key] = base_sd[key] + parent_sd[key]\n",
    "            \n",
    "    \n",
    "    # Average and add mutation\n",
    "    num_parents = len(parents)\n",
    "    \n",
    "    for key in keys:\n",
    "        \n",
    "        tensor_size = base_sd[key].size()\n",
    "        random_tensor = torch.normal(mean=0.0, std=sigma, size=tensor_size)\n",
    "        \n",
    "        base_sd[key] = (base_sd[key] / num_parents) + random_tensor\n",
    "    \n",
    "    # create offspring\n",
    "    offspring = MLP()\n",
    "    \n",
    "    offspring.load_state_dict(base_sd)\n",
    "    \n",
    "    return offspring\n",
    "    \n",
    "\n",
    "def create_offspring(population, fitness, rho, sigma):\n",
    "\n",
    "    \n",
    "    # Perform selection\n",
    "    parents = random.choices(population, weights=fitness, k=rho) \n",
    "    \n",
    "    # Perform crossover and mutation\n",
    "    offspring = crossover_and_mutation(parents, sigma)\n",
    "    \n",
    "    \n",
    "    return offspring\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, data_loader):\n",
    "    \n",
    "    #Calculate fitness of trained population\n",
    "\n",
    "    fitness = [calc_loss(population[i], data_loader) for i in range(pop_size)]\n",
    "    \n",
    "    print(f\"--- -- Finished fitness evaluation, length: {len(fitness)}\")\n",
    "    \n",
    "    #Create offspring population\n",
    "    fitness_weighted = [sigmoid(-f) for f in fitness]   # take inverse of loss so lower losses get higher fitness-values\n",
    "    offspring_population = [create_offspring(population, fitness_weighted, rho, sigma) for i in range(offspring_size)]\n",
    "    print(\"--- -- Finished creating offspring population\")\n",
    "    \n",
    "    #Evaluate fitness of offsprings \n",
    "    \n",
    "    offspring_fitness = [calc_loss(offspring_population[i], data_loader) for i in range(offspring_size)]\n",
    "    print(\"--- -- Finished evaluating fitness of offspring population\")\n",
    "    \n",
    "    # Combine fitness and population lists\n",
    "    \n",
    "    combined_fitness = fitness + offspring_fitness\n",
    "    combined_population = population + offspring_population\n",
    "    \n",
    "    # sort and select population by their fitness values\n",
    "    \n",
    "    sorted_population = [pop for _, pop in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    sorted_fitness = [loss for loss, _ in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    \n",
    "    m = int(pop_size * elitist_level)\n",
    "    new_population = sorted_population[0:m]\n",
    "    \n",
    "    # Fill up rest of population\n",
    "    difference = pop_size - m\n",
    "    remaining_population = list(set(sorted_population) - set(new_population))\n",
    "    filler_population = random.sample(remaining_population, difference)\n",
    "    \n",
    "    # assemble new population and return\n",
    "    new_population = new_population + filler_population\n",
    "    \n",
    "    return new_population, sorted_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d538178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(network, data_loader):\n",
    "    \n",
    "    network.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, (genes, types) in enumerate(data_loader):\n",
    "        \n",
    "        genes = genes.to(device)\n",
    "        types = types.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = network(genes)\n",
    "        loss = criterion(outputs, types)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "        del loss, outputs\n",
    "        \n",
    "    network.cpu()\n",
    "    \n",
    "    return float(total_loss/len(data_loader.sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657950d",
   "metadata": {},
   "source": [
    "# GA_Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14faa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_Neural_train(population,\n",
    "                    pop_size,\n",
    "                    max_generations, \n",
    "                    SGD_steps, GA_steps, \n",
    "                    offspring_size, elitist_level, rho,\n",
    "                    learning_rate,\n",
    "                    train_loader):\n",
    "    \n",
    "    print(f\"Starting with population of size: {pop_size}\")\n",
    "    \n",
    "    \n",
    "    for k in range(max_generations):\n",
    "        print(f\"Currently in generation {k+1}\")\n",
    "        \n",
    "        #SGD\n",
    "        print(f\"--- Starting SGD\")\n",
    "        \n",
    "        # Sequential version\n",
    "        population = [SGD_training(population[i], SGD_steps, learning_rate, 0.9, train_loader) for i in range(pop_size)]\n",
    "        \n",
    "        print(f\"--- Finished SGD\")\n",
    "         \n",
    "        # GA\n",
    "        print(f\"--- Starting GA\")\n",
    "        GA_start = time.time()\n",
    "        sorted_fitness = []          # store the sorted fitness values to maybe use in data collection\n",
    "        for i in range(0, GA_steps):\n",
    "            \n",
    "            sigma = 0.01 / (k+1)\n",
    "            population, sorted_fitness = GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, train_loader)\n",
    "        \n",
    "        GA_end = time.time()\n",
    "        print(f\"--- Finished GA,Time:{(GA_start-GA_end)*1000}ms\")\n",
    "        \n",
    "        \n",
    "    print(f\"Finished training process\")\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab74ac",
   "metadata": {},
   "source": [
    "# Prepare training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61e033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "pop_size = 10\n",
    "max_generations = 10\n",
    "SGD_steps = 10\n",
    "GA_steps = 1\n",
    "offspring_size = 10\n",
    "elitist_level = 0.6\n",
    "rho = 2\n",
    "learning_rate = 1e-5\n",
    "pbmc_1 = \"data/pbmc_1_pca.csv\"\n",
    "cell_type_pbmc1 = \"data/cell_type_pbmc1.csv\"\n",
    "pbmc_2 = \"data/pbmc_2_pca.csv\"\n",
    "cell_type_pbmc2 = \"data/cell_type_pbmc2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc6c219",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_pbmc1_loader(pbmc_1,cell_type_pbmc1,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67dcc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population and start training process\n",
    "population = [MLP() for i in range(pop_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbe831",
   "metadata": {},
   "source": [
    "# Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0c8c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with population of size: 10\n",
      "Currently in generation 1\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 2352.5521173469388\n",
      "Epoch [2/10], Loss: 1912.7696237244897\n",
      "Epoch [3/10], Loss: 1507.373801020408\n",
      "Epoch [4/10], Loss: 1160.9634375\n",
      "Epoch [5/10], Loss: 889.5119419642857\n",
      "Epoch [6/10], Loss: 726.309706632653\n",
      "Epoch [7/10], Loss: 556.8213727678572\n",
      "Epoch [8/10], Loss: 472.5841772959184\n",
      "Epoch [9/10], Loss: 425.2756393494898\n",
      "Epoch [10/10], Loss: 365.99777981505105\n",
      "Epoch [1/10], Loss: 3578.156173469388\n",
      "Epoch [2/10], Loss: 3026.742704081633\n",
      "Epoch [3/10], Loss: 2408.5448788265307\n",
      "Epoch [4/10], Loss: 1938.471855867347\n",
      "Epoch [5/10], Loss: 1554.6905739795918\n",
      "Epoch [6/10], Loss: 1283.8523883928572\n",
      "Epoch [7/10], Loss: 1057.9760427295919\n",
      "Epoch [8/10], Loss: 922.7232079081633\n",
      "Epoch [9/10], Loss: 807.4747672193878\n",
      "Epoch [10/10], Loss: 709.5285395408164\n",
      "Epoch [1/10], Loss: 1554.323488520408\n",
      "Epoch [2/10], Loss: 1157.216517857143\n",
      "Epoch [3/10], Loss: 882.9627232142857\n",
      "Epoch [4/10], Loss: 719.1156648596939\n",
      "Epoch [5/10], Loss: 590.3358561862245\n",
      "Epoch [6/10], Loss: 501.06985969387756\n",
      "Epoch [7/10], Loss: 449.72033641581635\n",
      "Epoch [8/10], Loss: 398.9653738839286\n",
      "Epoch [9/10], Loss: 378.39389668367346\n",
      "Epoch [10/10], Loss: 340.7269244260204\n",
      "Epoch [1/10], Loss: 2003.367831632653\n",
      "Epoch [2/10], Loss: 1801.9461096938776\n",
      "Epoch [3/10], Loss: 1516.2629910714286\n",
      "Epoch [4/10], Loss: 1288.5661734693876\n",
      "Epoch [5/10], Loss: 1119.1566039540817\n",
      "Epoch [6/10], Loss: 911.9884630102041\n",
      "Epoch [7/10], Loss: 776.3539381377551\n",
      "Epoch [8/10], Loss: 647.2816517857143\n",
      "Epoch [9/10], Loss: 566.5363456632653\n",
      "Epoch [10/10], Loss: 527.5037515943877\n",
      "Epoch [1/10], Loss: 3364.832487244898\n",
      "Epoch [2/10], Loss: 2823.0330357142857\n",
      "Epoch [3/10], Loss: 2278.729457908163\n",
      "Epoch [4/10], Loss: 1835.9447895408164\n",
      "Epoch [5/10], Loss: 1424.8088265306124\n",
      "Epoch [6/10], Loss: 1116.9814764030612\n",
      "Epoch [7/10], Loss: 898.1470184948979\n",
      "Epoch [8/10], Loss: 764.8937149234694\n",
      "Epoch [9/10], Loss: 653.6033051658163\n",
      "Epoch [10/10], Loss: 569.9688711734694\n",
      "Epoch [1/10], Loss: 4273.2982270408165\n",
      "Epoch [2/10], Loss: 3728.35193877551\n",
      "Epoch [3/10], Loss: 3292.5349107142856\n",
      "Epoch [4/10], Loss: 2826.1242857142856\n",
      "Epoch [5/10], Loss: 2428.208966836735\n",
      "Epoch [6/10], Loss: 2059.3676403061227\n",
      "Epoch [7/10], Loss: 1791.9001594387755\n",
      "Epoch [8/10], Loss: 1464.8409693877552\n",
      "Epoch [9/10], Loss: 1161.7329591836735\n",
      "Epoch [10/10], Loss: 934.71765625\n",
      "Epoch [1/10], Loss: 2478.752512755102\n",
      "Epoch [2/10], Loss: 2061.6405229591837\n",
      "Epoch [3/10], Loss: 1683.702869897959\n",
      "Epoch [4/10], Loss: 1353.7072512755103\n",
      "Epoch [5/10], Loss: 1117.5896332908164\n",
      "Epoch [6/10], Loss: 927.6902630739796\n",
      "Epoch [7/10], Loss: 808.5879145408163\n",
      "Epoch [8/10], Loss: 734.7936288265306\n",
      "Epoch [9/10], Loss: 635.564375\n",
      "Epoch [10/10], Loss: 577.2029304846939\n",
      "Epoch [1/10], Loss: 4197.678443877551\n",
      "Epoch [2/10], Loss: 3677.5008163265306\n",
      "Epoch [3/10], Loss: 3042.267219387755\n",
      "Epoch [4/10], Loss: 2521.81100127551\n",
      "Epoch [5/10], Loss: 2046.416243622449\n",
      "Epoch [6/10], Loss: 1689.6334757653062\n",
      "Epoch [7/10], Loss: 1316.5772895408163\n",
      "Epoch [8/10], Loss: 1068.2766964285715\n",
      "Epoch [9/10], Loss: 891.8835969387756\n",
      "Epoch [10/10], Loss: 736.5070153061224\n",
      "Epoch [1/10], Loss: 1792.281243622449\n",
      "Epoch [2/10], Loss: 1519.2357525510204\n",
      "Epoch [3/10], Loss: 1255.9090911989797\n",
      "Epoch [4/10], Loss: 1079.4092506377551\n",
      "Epoch [5/10], Loss: 934.6535267857142\n",
      "Epoch [6/10], Loss: 818.1707174744898\n",
      "Epoch [7/10], Loss: 716.2858227040816\n",
      "Epoch [8/10], Loss: 643.2856680484693\n",
      "Epoch [9/10], Loss: 583.1419228316327\n",
      "Epoch [10/10], Loss: 517.2556074617347\n",
      "Epoch [1/10], Loss: 2979.2760076530612\n",
      "Epoch [2/10], Loss: 2585.875318877551\n",
      "Epoch [3/10], Loss: 2135.083386479592\n",
      "Epoch [4/10], Loss: 1745.9144132653062\n",
      "Epoch [5/10], Loss: 1372.1103539540816\n",
      "Epoch [6/10], Loss: 1107.6048501275511\n",
      "Epoch [7/10], Loss: 880.2076116071429\n",
      "Epoch [8/10], Loss: 707.4593144132654\n",
      "Epoch [9/10], Loss: 591.9962484056123\n",
      "Epoch [10/10], Loss: 537.1303156887755\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4340.273380279541ms\n",
      "Currently in generation 2\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 332.63676977040814\n",
      "Epoch [2/10], Loss: 309.8545567602041\n",
      "Epoch [3/10], Loss: 288.87721301020406\n",
      "Epoch [4/10], Loss: 271.83917410714287\n",
      "Epoch [5/10], Loss: 260.390735809949\n",
      "Epoch [6/10], Loss: 237.75415975765307\n",
      "Epoch [7/10], Loss: 222.02269770408162\n",
      "Epoch [8/10], Loss: 210.31358298788265\n",
      "Epoch [9/10], Loss: 212.1330994897959\n",
      "Epoch [10/10], Loss: 197.48484853316327\n",
      "Epoch [1/10], Loss: 321.27646444515307\n",
      "Epoch [2/10], Loss: 312.3713600127551\n",
      "Epoch [3/10], Loss: 291.24880580357143\n",
      "Epoch [4/10], Loss: 271.1473126594388\n",
      "Epoch [5/10], Loss: 254.14381935586735\n",
      "Epoch [6/10], Loss: 240.99337133290817\n",
      "Epoch [7/10], Loss: 219.9168594547194\n",
      "Epoch [8/10], Loss: 211.66549266581632\n",
      "Epoch [9/10], Loss: 199.48214285714286\n",
      "Epoch [10/10], Loss: 188.9926686065051\n",
      "Epoch [1/10], Loss: 323.1212922512755\n",
      "Epoch [2/10], Loss: 308.58439094387757\n",
      "Epoch [3/10], Loss: 285.03280931122447\n",
      "Epoch [4/10], Loss: 269.1843670280612\n",
      "Epoch [5/10], Loss: 249.9672058354592\n",
      "Epoch [6/10], Loss: 240.13150829081633\n",
      "Epoch [7/10], Loss: 224.78916294642858\n",
      "Epoch [8/10], Loss: 217.6677056760204\n",
      "Epoch [9/10], Loss: 209.2531138392857\n",
      "Epoch [10/10], Loss: 191.17881696428572\n",
      "Epoch [1/10], Loss: 321.9482110969388\n",
      "Epoch [2/10], Loss: 309.6003483737245\n",
      "Epoch [3/10], Loss: 291.7657182716837\n",
      "Epoch [4/10], Loss: 272.3121388711735\n",
      "Epoch [5/10], Loss: 256.3446133609694\n",
      "Epoch [6/10], Loss: 234.15064014668368\n",
      "Epoch [7/10], Loss: 232.72362683354592\n",
      "Epoch [8/10], Loss: 209.91865353954083\n",
      "Epoch [9/10], Loss: 200.26939772002552\n",
      "Epoch [10/10], Loss: 190.33416972257652\n",
      "Epoch [1/10], Loss: 316.0346978635204\n",
      "Epoch [2/10], Loss: 314.4058378507653\n",
      "Epoch [3/10], Loss: 291.89871014030615\n",
      "Epoch [4/10], Loss: 264.9211726721939\n",
      "Epoch [5/10], Loss: 247.0767167570153\n",
      "Epoch [6/10], Loss: 248.08938695790818\n",
      "Epoch [7/10], Loss: 224.52597815688776\n",
      "Epoch [8/10], Loss: 225.46689572704082\n",
      "Epoch [9/10], Loss: 205.11084103954082\n",
      "Epoch [10/10], Loss: 188.0472733976403\n",
      "Epoch [1/10], Loss: 322.4815864158163\n",
      "Epoch [2/10], Loss: 304.9839341517857\n",
      "Epoch [3/10], Loss: 288.8329352678571\n",
      "Epoch [4/10], Loss: 276.8505851403061\n",
      "Epoch [5/10], Loss: 255.9721022002551\n",
      "Epoch [6/10], Loss: 236.28579121492348\n",
      "Epoch [7/10], Loss: 233.11932637117346\n",
      "Epoch [8/10], Loss: 215.31512675382652\n",
      "Epoch [9/10], Loss: 203.72703762755103\n",
      "Epoch [10/10], Loss: 199.77040736607142\n",
      "Epoch [1/10], Loss: 476.36711415816325\n",
      "Epoch [2/10], Loss: 444.5800302933674\n",
      "Epoch [3/10], Loss: 396.26866709183673\n",
      "Epoch [4/10], Loss: 371.11406090561223\n",
      "Epoch [5/10], Loss: 339.79278140943876\n",
      "Epoch [6/10], Loss: 312.6423477359694\n",
      "Epoch [7/10], Loss: 284.90967633928574\n",
      "Epoch [8/10], Loss: 272.1938823341837\n",
      "Epoch [9/10], Loss: 267.48876434948977\n",
      "Epoch [10/10], Loss: 234.00661750637755\n",
      "Epoch [1/10], Loss: 512.9801642219388\n",
      "Epoch [2/10], Loss: 474.76770089285714\n",
      "Epoch [3/10], Loss: 442.9277455357143\n",
      "Epoch [4/10], Loss: 411.8780612244898\n",
      "Epoch [5/10], Loss: 376.2374258609694\n",
      "Epoch [6/10], Loss: 347.1226092155612\n",
      "Epoch [7/10], Loss: 329.4412882653061\n",
      "Epoch [8/10], Loss: 324.5763241390306\n",
      "Epoch [9/10], Loss: 287.85543925382655\n",
      "Epoch [10/10], Loss: 276.8565138711735\n",
      "Epoch [1/10], Loss: 339.12006058673467\n",
      "Epoch [2/10], Loss: 300.36640784438777\n",
      "Epoch [3/10], Loss: 294.84456632653064\n",
      "Epoch [4/10], Loss: 266.4704185267857\n",
      "Epoch [5/10], Loss: 252.7360475127551\n",
      "Epoch [6/10], Loss: 247.05043207908165\n",
      "Epoch [7/10], Loss: 231.15064612563776\n",
      "Epoch [8/10], Loss: 208.31775868941327\n",
      "Epoch [9/10], Loss: 197.52670998086734\n",
      "Epoch [10/10], Loss: 191.3351953125\n",
      "Epoch [1/10], Loss: 486.5202662627551\n",
      "Epoch [2/10], Loss: 445.7897648278061\n",
      "Epoch [3/10], Loss: 412.0331457270408\n",
      "Epoch [4/10], Loss: 394.4516326530612\n",
      "Epoch [5/10], Loss: 360.0592602040816\n",
      "Epoch [6/10], Loss: 324.67479193239797\n",
      "Epoch [7/10], Loss: 306.5709207589286\n",
      "Epoch [8/10], Loss: 282.0971189413265\n",
      "Epoch [9/10], Loss: 272.61861926020407\n",
      "Epoch [10/10], Loss: 249.5094407684949\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4824.719429016113ms\n",
      "Currently in generation 3\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 186.0205213647959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 175.2808171237245\n",
      "Epoch [3/10], Loss: 172.28901586415816\n",
      "Epoch [4/10], Loss: 160.01234135841835\n",
      "Epoch [5/10], Loss: 154.73566764987245\n",
      "Epoch [6/10], Loss: 169.7193757971939\n",
      "Epoch [7/10], Loss: 134.01684829400511\n",
      "Epoch [8/10], Loss: 129.78714564732144\n",
      "Epoch [9/10], Loss: 123.84270169005102\n",
      "Epoch [10/10], Loss: 114.73400091677296\n",
      "Epoch [1/10], Loss: 188.71060467155613\n",
      "Epoch [2/10], Loss: 174.10698022959184\n",
      "Epoch [3/10], Loss: 164.28180564413265\n",
      "Epoch [4/10], Loss: 154.49636599170918\n",
      "Epoch [5/10], Loss: 148.76082071109693\n",
      "Epoch [6/10], Loss: 146.39143973214286\n",
      "Epoch [7/10], Loss: 135.1673457429847\n",
      "Epoch [8/10], Loss: 125.8467483458227\n",
      "Epoch [9/10], Loss: 120.04146404655613\n",
      "Epoch [10/10], Loss: 126.36954918686224\n",
      "Epoch [1/10], Loss: 183.64194116709183\n",
      "Epoch [2/10], Loss: 181.44494539221938\n",
      "Epoch [3/10], Loss: 175.60741948341837\n",
      "Epoch [4/10], Loss: 157.8919511320153\n",
      "Epoch [5/10], Loss: 154.2981536989796\n",
      "Epoch [6/10], Loss: 147.38128228635205\n",
      "Epoch [7/10], Loss: 136.12434151785715\n",
      "Epoch [8/10], Loss: 126.52331792091837\n",
      "Epoch [9/10], Loss: 132.01228555484693\n",
      "Epoch [10/10], Loss: 118.57578483737245\n",
      "Epoch [1/10], Loss: 189.24900868941327\n",
      "Epoch [2/10], Loss: 177.05528180803572\n",
      "Epoch [3/10], Loss: 164.44353675063775\n",
      "Epoch [4/10], Loss: 159.00216677295919\n",
      "Epoch [5/10], Loss: 149.87667689732143\n",
      "Epoch [6/10], Loss: 139.4681463249362\n",
      "Epoch [7/10], Loss: 145.49645408163266\n",
      "Epoch [8/10], Loss: 129.26359534438777\n",
      "Epoch [9/10], Loss: 123.0236764588648\n",
      "Epoch [10/10], Loss: 116.33590481505102\n",
      "Epoch [1/10], Loss: 191.01815808354593\n",
      "Epoch [2/10], Loss: 184.34655771683674\n",
      "Epoch [3/10], Loss: 163.49210578762754\n",
      "Epoch [4/10], Loss: 160.15509287308674\n",
      "Epoch [5/10], Loss: 149.7585208067602\n",
      "Epoch [6/10], Loss: 140.21110311702807\n",
      "Epoch [7/10], Loss: 140.31508370535715\n",
      "Epoch [8/10], Loss: 134.56565569196428\n",
      "Epoch [9/10], Loss: 121.6209909119898\n",
      "Epoch [10/10], Loss: 114.58803053252551\n",
      "Epoch [1/10], Loss: 178.66109594228317\n",
      "Epoch [2/10], Loss: 172.8270918367347\n",
      "Epoch [3/10], Loss: 170.64804129464287\n",
      "Epoch [4/10], Loss: 156.05969029017857\n",
      "Epoch [5/10], Loss: 149.81256656568877\n",
      "Epoch [6/10], Loss: 149.9053977997449\n",
      "Epoch [7/10], Loss: 132.37676518654337\n",
      "Epoch [8/10], Loss: 125.06471948740433\n",
      "Epoch [9/10], Loss: 119.65635762117347\n",
      "Epoch [10/10], Loss: 116.45299645248724\n",
      "Epoch [1/10], Loss: 178.33263113839286\n",
      "Epoch [2/10], Loss: 176.47781489158163\n",
      "Epoch [3/10], Loss: 169.88201331313775\n",
      "Epoch [4/10], Loss: 155.40625119579082\n",
      "Epoch [5/10], Loss: 148.92452686543368\n",
      "Epoch [6/10], Loss: 149.5227064732143\n",
      "Epoch [7/10], Loss: 134.2314660395408\n",
      "Epoch [8/10], Loss: 126.69691067442602\n",
      "Epoch [9/10], Loss: 120.28451311383928\n",
      "Epoch [10/10], Loss: 118.46515405771683\n",
      "Epoch [1/10], Loss: 189.9893698182398\n",
      "Epoch [2/10], Loss: 175.6096444515306\n",
      "Epoch [3/10], Loss: 170.134791533801\n",
      "Epoch [4/10], Loss: 154.7643698182398\n",
      "Epoch [5/10], Loss: 149.9497429049745\n",
      "Epoch [6/10], Loss: 143.8688620057398\n",
      "Epoch [7/10], Loss: 133.91581273915816\n",
      "Epoch [8/10], Loss: 126.48955297353316\n",
      "Epoch [9/10], Loss: 128.46694316007654\n",
      "Epoch [10/10], Loss: 115.55299107142856\n",
      "Epoch [1/10], Loss: 176.92871402662627\n",
      "Epoch [2/10], Loss: 176.31273636798468\n",
      "Epoch [3/10], Loss: 171.74718829719387\n",
      "Epoch [4/10], Loss: 161.15763911033164\n",
      "Epoch [5/10], Loss: 146.16608059630101\n",
      "Epoch [6/10], Loss: 140.48437260841837\n",
      "Epoch [7/10], Loss: 131.81362663424744\n",
      "Epoch [8/10], Loss: 133.7849681122449\n",
      "Epoch [9/10], Loss: 138.9196105707908\n",
      "Epoch [10/10], Loss: 127.05496432557398\n",
      "Epoch [1/10], Loss: 256.78748724489793\n",
      "Epoch [2/10], Loss: 247.3873979591837\n",
      "Epoch [3/10], Loss: 234.4779225127551\n",
      "Epoch [4/10], Loss: 221.78982900191326\n",
      "Epoch [5/10], Loss: 218.01269411670918\n",
      "Epoch [6/10], Loss: 204.3583860809949\n",
      "Epoch [7/10], Loss: 192.46429807079082\n",
      "Epoch [8/10], Loss: 178.5216529815051\n",
      "Epoch [9/10], Loss: 176.42050701530613\n",
      "Epoch [10/10], Loss: 163.33883808992346\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4622.802257537842ms\n",
      "Currently in generation 4\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 114.4029348692602\n",
      "Epoch [2/10], Loss: 106.54973054846938\n",
      "Epoch [3/10], Loss: 104.99210100446429\n",
      "Epoch [4/10], Loss: 95.70616569674745\n",
      "Epoch [5/10], Loss: 93.04725924744898\n",
      "Epoch [6/10], Loss: 86.96631218112245\n",
      "Epoch [7/10], Loss: 81.01672642299107\n",
      "Epoch [8/10], Loss: 84.4432981903699\n",
      "Epoch [9/10], Loss: 75.16984424824618\n",
      "Epoch [10/10], Loss: 70.33564976283482\n",
      "Epoch [1/10], Loss: 113.66568757971939\n",
      "Epoch [2/10], Loss: 123.53934151785714\n",
      "Epoch [3/10], Loss: 99.77862902582908\n",
      "Epoch [4/10], Loss: 94.31752699248645\n",
      "Epoch [5/10], Loss: 91.24547811702806\n",
      "Epoch [6/10], Loss: 87.12481345663265\n",
      "Epoch [7/10], Loss: 85.87268415178572\n",
      "Epoch [8/10], Loss: 81.27575613839285\n",
      "Epoch [9/10], Loss: 73.89002817582112\n",
      "Epoch [10/10], Loss: 71.80756218112245\n",
      "Epoch [1/10], Loss: 109.64039311623087\n",
      "Epoch [2/10], Loss: 108.57740792410715\n",
      "Epoch [3/10], Loss: 106.35752431441327\n",
      "Epoch [4/10], Loss: 115.84213827327807\n",
      "Epoch [5/10], Loss: 97.84607242506378\n",
      "Epoch [6/10], Loss: 88.02573042889031\n",
      "Epoch [7/10], Loss: 86.66983876753827\n",
      "Epoch [8/10], Loss: 80.32163942920918\n",
      "Epoch [9/10], Loss: 74.8172590481505\n",
      "Epoch [10/10], Loss: 70.76887017697705\n",
      "Epoch [1/10], Loss: 113.68122010522958\n",
      "Epoch [2/10], Loss: 107.03342693718112\n",
      "Epoch [3/10], Loss: 107.88351602359694\n",
      "Epoch [4/10], Loss: 94.24856368084343\n",
      "Epoch [5/10], Loss: 90.75469935825893\n",
      "Epoch [6/10], Loss: 94.25543207908163\n",
      "Epoch [7/10], Loss: 82.37967424665179\n",
      "Epoch [8/10], Loss: 78.12795888472577\n",
      "Epoch [9/10], Loss: 74.12165158641582\n",
      "Epoch [10/10], Loss: 69.9504611392897\n",
      "Epoch [1/10], Loss: 109.01924734933036\n",
      "Epoch [2/10], Loss: 109.64754743303571\n",
      "Epoch [3/10], Loss: 106.3391509885204\n",
      "Epoch [4/10], Loss: 103.14658083545919\n",
      "Epoch [5/10], Loss: 93.11306959502551\n",
      "Epoch [6/10], Loss: 86.31730568399234\n",
      "Epoch [7/10], Loss: 84.62725805165816\n",
      "Epoch [8/10], Loss: 82.82732700892858\n",
      "Epoch [9/10], Loss: 73.65796057876275\n",
      "Epoch [10/10], Loss: 73.60441695232781\n",
      "Epoch [1/10], Loss: 110.96634765625\n",
      "Epoch [2/10], Loss: 105.1740826291454\n",
      "Epoch [3/10], Loss: 101.87817103794643\n",
      "Epoch [4/10], Loss: 95.57410574776786\n",
      "Epoch [5/10], Loss: 94.49680803571428\n",
      "Epoch [6/10], Loss: 86.5538548309949\n",
      "Epoch [7/10], Loss: 81.94666488958865\n",
      "Epoch [8/10], Loss: 78.87106126434949\n",
      "Epoch [9/10], Loss: 76.71690868144132\n",
      "Epoch [10/10], Loss: 72.36447385204082\n",
      "Epoch [1/10], Loss: 111.27702188297194\n",
      "Epoch [2/10], Loss: 110.17593969228317\n",
      "Epoch [3/10], Loss: 99.8589297672194\n",
      "Epoch [4/10], Loss: 97.46971301020409\n",
      "Epoch [5/10], Loss: 93.22875378667092\n",
      "Epoch [6/10], Loss: 87.41809909119898\n",
      "Epoch [7/10], Loss: 81.04008534334143\n",
      "Epoch [8/10], Loss: 81.45509147799744\n",
      "Epoch [9/10], Loss: 73.69692661830358\n",
      "Epoch [10/10], Loss: 70.30844258211097\n",
      "Epoch [1/10], Loss: 155.4759315210459\n",
      "Epoch [2/10], Loss: 155.56308952487245\n",
      "Epoch [3/10], Loss: 141.63257593271683\n",
      "Epoch [4/10], Loss: 140.52101243622448\n",
      "Epoch [5/10], Loss: 132.74256935586735\n",
      "Epoch [6/10], Loss: 123.29404157366072\n",
      "Epoch [7/10], Loss: 116.41577048788265\n",
      "Epoch [8/10], Loss: 118.84455875318878\n",
      "Epoch [9/10], Loss: 113.04105090082908\n",
      "Epoch [10/10], Loss: 100.45984076052297\n",
      "Epoch [1/10], Loss: 119.27632055165816\n",
      "Epoch [2/10], Loss: 106.34662507971939\n",
      "Epoch [3/10], Loss: 103.34968929368623\n",
      "Epoch [4/10], Loss: 97.31726343271684\n",
      "Epoch [5/10], Loss: 93.04025370695153\n",
      "Epoch [6/10], Loss: 86.82026466836734\n",
      "Epoch [7/10], Loss: 82.82144750478317\n",
      "Epoch [8/10], Loss: 79.06968969228316\n",
      "Epoch [9/10], Loss: 75.96717414700255\n",
      "Epoch [10/10], Loss: 71.31227080676021\n",
      "Epoch [1/10], Loss: 114.46920280612245\n",
      "Epoch [2/10], Loss: 107.36701112085458\n",
      "Epoch [3/10], Loss: 102.5228977997449\n",
      "Epoch [4/10], Loss: 98.8830026307398\n",
      "Epoch [5/10], Loss: 90.71375558035714\n",
      "Epoch [6/10], Loss: 93.36962990274235\n",
      "Epoch [7/10], Loss: 82.98155811543367\n",
      "Epoch [8/10], Loss: 77.86365520866549\n",
      "Epoch [9/10], Loss: 76.2934966916454\n",
      "Epoch [10/10], Loss: 71.48858338647959\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4850.845813751221ms\n",
      "Currently in generation 5\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 68.75388891103316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 67.51668267697704\n",
      "Epoch [3/10], Loss: 63.146435048628824\n",
      "Epoch [4/10], Loss: 61.050667948820156\n",
      "Epoch [5/10], Loss: 57.30264219945791\n",
      "Epoch [6/10], Loss: 56.95464823820153\n",
      "Epoch [7/10], Loss: 52.57516232860332\n",
      "Epoch [8/10], Loss: 54.41299615353954\n",
      "Epoch [9/10], Loss: 46.23752967055963\n",
      "Epoch [10/10], Loss: 44.15678137954401\n",
      "Epoch [1/10], Loss: 69.29210259885204\n",
      "Epoch [2/10], Loss: 66.34381566884566\n",
      "Epoch [3/10], Loss: 68.31248485331632\n",
      "Epoch [4/10], Loss: 60.12675841039541\n",
      "Epoch [5/10], Loss: 57.94799176897322\n",
      "Epoch [6/10], Loss: 58.51577108577806\n",
      "Epoch [7/10], Loss: 52.59778180803571\n",
      "Epoch [8/10], Loss: 48.141126335299745\n",
      "Epoch [9/10], Loss: 49.51461485570791\n",
      "Epoch [10/10], Loss: 43.37898804022341\n",
      "Epoch [1/10], Loss: 71.7807057158801\n",
      "Epoch [2/10], Loss: 64.98152812101404\n",
      "Epoch [3/10], Loss: 64.95622349330357\n",
      "Epoch [4/10], Loss: 60.12137057557398\n",
      "Epoch [5/10], Loss: 59.15645438058036\n",
      "Epoch [6/10], Loss: 53.49172029456314\n",
      "Epoch [7/10], Loss: 54.33925562021684\n",
      "Epoch [8/10], Loss: 50.680457589285716\n",
      "Epoch [9/10], Loss: 47.511827965561224\n",
      "Epoch [10/10], Loss: 44.39657605229592\n",
      "Epoch [1/10], Loss: 70.67879225127551\n",
      "Epoch [2/10], Loss: 65.87297253667091\n",
      "Epoch [3/10], Loss: 62.744720483896685\n",
      "Epoch [4/10], Loss: 59.19651546556123\n",
      "Epoch [5/10], Loss: 57.80536112882653\n",
      "Epoch [6/10], Loss: 53.711717753507656\n",
      "Epoch [7/10], Loss: 53.3926806640625\n",
      "Epoch [8/10], Loss: 51.82322773836097\n",
      "Epoch [9/10], Loss: 47.30177913743623\n",
      "Epoch [10/10], Loss: 43.94745913135762\n",
      "Epoch [1/10], Loss: 70.73951251594387\n",
      "Epoch [2/10], Loss: 69.4625318877551\n",
      "Epoch [3/10], Loss: 63.96501584422832\n",
      "Epoch [4/10], Loss: 60.35991240832271\n",
      "Epoch [5/10], Loss: 59.39045699139031\n",
      "Epoch [6/10], Loss: 54.21196079799107\n",
      "Epoch [7/10], Loss: 51.048225247130105\n",
      "Epoch [8/10], Loss: 48.47296239424725\n",
      "Epoch [9/10], Loss: 46.80051438934949\n",
      "Epoch [10/10], Loss: 43.94452220683195\n",
      "Epoch [1/10], Loss: 89.33069176498725\n",
      "Epoch [2/10], Loss: 66.69822883450256\n",
      "Epoch [3/10], Loss: 62.49671037946428\n",
      "Epoch [4/10], Loss: 65.40825185347576\n",
      "Epoch [5/10], Loss: 57.10716413225446\n",
      "Epoch [6/10], Loss: 55.649037388392856\n",
      "Epoch [7/10], Loss: 55.60414989237883\n",
      "Epoch [8/10], Loss: 52.91449896364796\n",
      "Epoch [9/10], Loss: 48.04868751992985\n",
      "Epoch [10/10], Loss: 44.415032037228954\n",
      "Epoch [1/10], Loss: 69.36495416135205\n",
      "Epoch [2/10], Loss: 65.67906170280612\n",
      "Epoch [3/10], Loss: 62.46328722895408\n",
      "Epoch [4/10], Loss: 58.90265644929847\n",
      "Epoch [5/10], Loss: 56.20211956413425\n",
      "Epoch [6/10], Loss: 54.42402224170918\n",
      "Epoch [7/10], Loss: 65.5509228515625\n",
      "Epoch [8/10], Loss: 51.81768086336097\n",
      "Epoch [9/10], Loss: 46.66920091278699\n",
      "Epoch [10/10], Loss: 43.99280709402902\n",
      "Epoch [1/10], Loss: 71.75310706313776\n",
      "Epoch [2/10], Loss: 65.2386677271006\n",
      "Epoch [3/10], Loss: 62.52821802256059\n",
      "Epoch [4/10], Loss: 61.155249820631376\n",
      "Epoch [5/10], Loss: 59.45846291055485\n",
      "Epoch [6/10], Loss: 53.545685686383926\n",
      "Epoch [7/10], Loss: 52.57459552375638\n",
      "Epoch [8/10], Loss: 48.48389685027453\n",
      "Epoch [9/10], Loss: 50.51310377471301\n",
      "Epoch [10/10], Loss: 48.86090541294643\n",
      "Epoch [1/10], Loss: 69.56105947066327\n",
      "Epoch [2/10], Loss: 69.26639234893176\n",
      "Epoch [3/10], Loss: 64.27732202646683\n",
      "Epoch [4/10], Loss: 60.95158571827169\n",
      "Epoch [5/10], Loss: 56.43457609215561\n",
      "Epoch [6/10], Loss: 57.153215381855865\n",
      "Epoch [7/10], Loss: 51.542199557557396\n",
      "Epoch [8/10], Loss: 53.438469786352044\n",
      "Epoch [9/10], Loss: 47.85948740433673\n",
      "Epoch [10/10], Loss: 46.547974180883294\n",
      "Epoch [1/10], Loss: 67.48364417251275\n",
      "Epoch [2/10], Loss: 65.97207370057399\n",
      "Epoch [3/10], Loss: 67.58844950773278\n",
      "Epoch [4/10], Loss: 59.77402214205995\n",
      "Epoch [5/10], Loss: 57.26758171237245\n",
      "Epoch [6/10], Loss: 54.01064144212373\n",
      "Epoch [7/10], Loss: 53.32167580117985\n",
      "Epoch [8/10], Loss: 50.84580078125\n",
      "Epoch [9/10], Loss: 47.889536631058675\n",
      "Epoch [10/10], Loss: 44.13252680564413\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4811.993360519409ms\n",
      "Currently in generation 6\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 41.964439921476405\n",
      "Epoch [2/10], Loss: 39.792242904974486\n",
      "Epoch [3/10], Loss: 39.19322763871173\n",
      "Epoch [4/10], Loss: 35.930784961933995\n",
      "Epoch [5/10], Loss: 35.49565509406888\n",
      "Epoch [6/10], Loss: 32.121857760682396\n",
      "Epoch [7/10], Loss: 32.009701849489794\n",
      "Epoch [8/10], Loss: 29.71421481385523\n",
      "Epoch [9/10], Loss: 27.21198244678731\n",
      "Epoch [10/10], Loss: 25.874552026865434\n",
      "Epoch [1/10], Loss: 41.65310875717474\n",
      "Epoch [2/10], Loss: 42.77988829320791\n",
      "Epoch [3/10], Loss: 37.740132035235966\n",
      "Epoch [4/10], Loss: 35.99358346121652\n",
      "Epoch [5/10], Loss: 34.38721151546556\n",
      "Epoch [6/10], Loss: 32.07006004489198\n",
      "Epoch [7/10], Loss: 39.308628976004464\n",
      "Epoch [8/10], Loss: 28.628141741071428\n",
      "Epoch [9/10], Loss: 26.960676381636638\n",
      "Epoch [10/10], Loss: 25.4939381377551\n",
      "Epoch [1/10], Loss: 43.07287647480867\n",
      "Epoch [2/10], Loss: 53.78029501155931\n",
      "Epoch [3/10], Loss: 40.517903629225124\n",
      "Epoch [4/10], Loss: 36.63356340680804\n",
      "Epoch [5/10], Loss: 35.51938068000638\n",
      "Epoch [6/10], Loss: 34.366930554448345\n",
      "Epoch [7/10], Loss: 33.58495560626594\n",
      "Epoch [8/10], Loss: 29.176072474888393\n",
      "Epoch [9/10], Loss: 28.02610590720663\n",
      "Epoch [10/10], Loss: 28.435986589704243\n",
      "Epoch [1/10], Loss: 44.05304767219388\n",
      "Epoch [2/10], Loss: 40.12232989875638\n",
      "Epoch [3/10], Loss: 38.03383274623326\n",
      "Epoch [4/10], Loss: 37.4289231903699\n",
      "Epoch [5/10], Loss: 34.173056279396526\n",
      "Epoch [6/10], Loss: 33.5518046476403\n",
      "Epoch [7/10], Loss: 31.27126873405612\n",
      "Epoch [8/10], Loss: 29.96593167051977\n",
      "Epoch [9/10], Loss: 28.462502192283164\n",
      "Epoch [10/10], Loss: 37.87217761604153\n",
      "Epoch [1/10], Loss: 41.830955785634565\n",
      "Epoch [2/10], Loss: 42.85714300661671\n",
      "Epoch [3/10], Loss: 44.11761850785236\n",
      "Epoch [4/10], Loss: 35.96737773038903\n",
      "Epoch [5/10], Loss: 34.20627366669324\n",
      "Epoch [6/10], Loss: 44.053655831473215\n",
      "Epoch [7/10], Loss: 30.512929172515868\n",
      "Epoch [8/10], Loss: 28.96123343331473\n",
      "Epoch [9/10], Loss: 27.338148018973214\n",
      "Epoch [10/10], Loss: 27.448489865672833\n",
      "Epoch [1/10], Loss: 45.67971580038265\n",
      "Epoch [2/10], Loss: 42.430035275829084\n",
      "Epoch [3/10], Loss: 38.938304655113996\n",
      "Epoch [4/10], Loss: 38.82220334422831\n",
      "Epoch [5/10], Loss: 35.82218391262755\n",
      "Epoch [6/10], Loss: 32.34970738002232\n",
      "Epoch [7/10], Loss: 32.35390605070153\n",
      "Epoch [8/10], Loss: 29.48430419921875\n",
      "Epoch [9/10], Loss: 27.722252813845266\n",
      "Epoch [10/10], Loss: 27.436955068160078\n",
      "Epoch [1/10], Loss: 42.513685327646684\n",
      "Epoch [2/10], Loss: 39.785384347098216\n",
      "Epoch [3/10], Loss: 40.893524394132655\n",
      "Epoch [4/10], Loss: 39.5366886061065\n",
      "Epoch [5/10], Loss: 34.78720852598852\n",
      "Epoch [6/10], Loss: 33.846098333864795\n",
      "Epoch [7/10], Loss: 32.542515096859056\n",
      "Epoch [8/10], Loss: 28.9872716537787\n",
      "Epoch [9/10], Loss: 27.07711899115115\n",
      "Epoch [10/10], Loss: 26.450724948182398\n",
      "Epoch [1/10], Loss: 42.489341617506376\n",
      "Epoch [2/10], Loss: 40.33769586057079\n",
      "Epoch [3/10], Loss: 39.51167879065689\n",
      "Epoch [4/10], Loss: 36.21273045520393\n",
      "Epoch [5/10], Loss: 34.66611744160555\n",
      "Epoch [6/10], Loss: 32.38610087492028\n",
      "Epoch [7/10], Loss: 32.18291369379783\n",
      "Epoch [8/10], Loss: 29.247505729830994\n",
      "Epoch [9/10], Loss: 28.19350588428731\n",
      "Epoch [10/10], Loss: 28.35170748963648\n",
      "Epoch [1/10], Loss: 42.37132344148597\n",
      "Epoch [2/10], Loss: 43.59319834183673\n",
      "Epoch [3/10], Loss: 38.06486869831475\n",
      "Epoch [4/10], Loss: 37.87292874083227\n",
      "Epoch [5/10], Loss: 34.37480139907525\n",
      "Epoch [6/10], Loss: 33.715048728475765\n",
      "Epoch [7/10], Loss: 31.495285794005103\n",
      "Epoch [8/10], Loss: 29.063160297627352\n",
      "Epoch [9/10], Loss: 28.209592534279338\n",
      "Epoch [10/10], Loss: 26.047046620894452\n",
      "Epoch [1/10], Loss: 43.01791603555485\n",
      "Epoch [2/10], Loss: 41.42411655970982\n",
      "Epoch [3/10], Loss: 47.01087183115434\n",
      "Epoch [4/10], Loss: 37.73857150330836\n",
      "Epoch [5/10], Loss: 34.61096127257055\n",
      "Epoch [6/10], Loss: 37.71008370535714\n",
      "Epoch [7/10], Loss: 30.880685686383927\n",
      "Epoch [8/10], Loss: 31.205614885602678\n",
      "Epoch [9/10], Loss: 32.10763181102519\n",
      "Epoch [10/10], Loss: 26.412736367984692\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4665.149211883545ms\n",
      "Currently in generation 7\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 24.991130146882973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 23.28964502762775\n",
      "Epoch [3/10], Loss: 22.186336268210898\n",
      "Epoch [4/10], Loss: 20.824990458585777\n",
      "Epoch [5/10], Loss: 20.63969051438935\n",
      "Epoch [6/10], Loss: 19.703189971301022\n",
      "Epoch [7/10], Loss: 18.036583027742346\n",
      "Epoch [8/10], Loss: 17.866920315489477\n",
      "Epoch [9/10], Loss: 15.310372211689852\n",
      "Epoch [10/10], Loss: 15.320153646663744\n",
      "Epoch [1/10], Loss: 25.123505859375\n",
      "Epoch [2/10], Loss: 23.443641008649553\n",
      "Epoch [3/10], Loss: 23.611203712930486\n",
      "Epoch [4/10], Loss: 23.459549759845345\n",
      "Epoch [5/10], Loss: 20.687004992426658\n",
      "Epoch [6/10], Loss: 18.55307357243129\n",
      "Epoch [7/10], Loss: 29.645156785614635\n",
      "Epoch [8/10], Loss: 16.29171613420759\n",
      "Epoch [9/10], Loss: 16.059227469308034\n",
      "Epoch [10/10], Loss: 14.840071797273596\n",
      "Epoch [1/10], Loss: 25.397003921197385\n",
      "Epoch [2/10], Loss: 24.15816650390625\n",
      "Epoch [3/10], Loss: 22.206704998405613\n",
      "Epoch [4/10], Loss: 21.096788853236607\n",
      "Epoch [5/10], Loss: 19.60678216428173\n",
      "Epoch [6/10], Loss: 18.51608682437819\n",
      "Epoch [7/10], Loss: 18.616925771285075\n",
      "Epoch [8/10], Loss: 17.702636731206155\n",
      "Epoch [9/10], Loss: 15.608270188934949\n",
      "Epoch [10/10], Loss: 15.164655468999124\n",
      "Epoch [1/10], Loss: 25.125402682557397\n",
      "Epoch [2/10], Loss: 23.55566127232143\n",
      "Epoch [3/10], Loss: 22.289298207808514\n",
      "Epoch [4/10], Loss: 21.164879791882573\n",
      "Epoch [5/10], Loss: 20.631338317248286\n",
      "Epoch [6/10], Loss: 19.829541887555802\n",
      "Epoch [7/10], Loss: 17.677906881838428\n",
      "Epoch [8/10], Loss: 16.761652358697386\n",
      "Epoch [9/10], Loss: 16.294822026466836\n",
      "Epoch [10/10], Loss: 14.910010674924267\n",
      "Epoch [1/10], Loss: 24.4891167839206\n",
      "Epoch [2/10], Loss: 23.311417326635816\n",
      "Epoch [3/10], Loss: 23.92585003288425\n",
      "Epoch [4/10], Loss: 20.8400926364198\n",
      "Epoch [5/10], Loss: 19.60204380580357\n",
      "Epoch [6/10], Loss: 18.47096620676469\n",
      "Epoch [7/10], Loss: 18.18278476014429\n",
      "Epoch [8/10], Loss: 16.53372116400271\n",
      "Epoch [9/10], Loss: 15.489969308035715\n",
      "Epoch [10/10], Loss: 14.641727189044563\n",
      "Epoch [1/10], Loss: 26.141857312260843\n",
      "Epoch [2/10], Loss: 23.49292658591757\n",
      "Epoch [3/10], Loss: 22.297420218331474\n",
      "Epoch [4/10], Loss: 20.98152691276706\n",
      "Epoch [5/10], Loss: 23.340097108179208\n",
      "Epoch [6/10], Loss: 18.6980183286083\n",
      "Epoch [7/10], Loss: 28.117010273836097\n",
      "Epoch [8/10], Loss: 16.614444617446587\n",
      "Epoch [9/10], Loss: 16.26748139050542\n",
      "Epoch [10/10], Loss: 15.069774169921875\n",
      "Epoch [1/10], Loss: 25.831498500279018\n",
      "Epoch [2/10], Loss: 25.524703892299108\n",
      "Epoch [3/10], Loss: 23.61370891337492\n",
      "Epoch [4/10], Loss: 20.65520116689254\n",
      "Epoch [5/10], Loss: 21.15141863141741\n",
      "Epoch [6/10], Loss: 18.368908840880103\n",
      "Epoch [7/10], Loss: 18.04060749287508\n",
      "Epoch [8/10], Loss: 16.630130640146685\n",
      "Epoch [9/10], Loss: 16.514084771603954\n",
      "Epoch [10/10], Loss: 15.040362047467912\n",
      "Epoch [1/10], Loss: 25.404447818678253\n",
      "Epoch [2/10], Loss: 23.795238535355548\n",
      "Epoch [3/10], Loss: 22.67580195212851\n",
      "Epoch [4/10], Loss: 21.764773397640305\n",
      "Epoch [5/10], Loss: 22.045740717673787\n",
      "Epoch [6/10], Loss: 20.16941762496014\n",
      "Epoch [7/10], Loss: 18.24509332150829\n",
      "Epoch [8/10], Loss: 16.572628918083346\n",
      "Epoch [9/10], Loss: 17.60220832669005\n",
      "Epoch [10/10], Loss: 14.809226659658004\n",
      "Epoch [1/10], Loss: 24.95150949205671\n",
      "Epoch [2/10], Loss: 25.520378517617985\n",
      "Epoch [3/10], Loss: 22.44077064981266\n",
      "Epoch [4/10], Loss: 21.305724175900828\n",
      "Epoch [5/10], Loss: 21.1501329819037\n",
      "Epoch [6/10], Loss: 18.763868034518495\n",
      "Epoch [7/10], Loss: 19.845626943160077\n",
      "Epoch [8/10], Loss: 16.651927403819805\n",
      "Epoch [9/10], Loss: 15.64836073972741\n",
      "Epoch [10/10], Loss: 14.789684018504863\n",
      "Epoch [1/10], Loss: 27.53491978236607\n",
      "Epoch [2/10], Loss: 23.745562656947545\n",
      "Epoch [3/10], Loss: 22.487510811941963\n",
      "Epoch [4/10], Loss: 21.44593299087213\n",
      "Epoch [5/10], Loss: 20.113344303053253\n",
      "Epoch [6/10], Loss: 18.801932671994578\n",
      "Epoch [7/10], Loss: 17.775621910873724\n",
      "Epoch [8/10], Loss: 19.09425735162229\n",
      "Epoch [9/10], Loss: 17.483512772540656\n",
      "Epoch [10/10], Loss: 16.547633231026786\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4690.836429595947ms\n",
      "Currently in generation 8\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 14.520538940429688\n",
      "Epoch [2/10], Loss: 13.054161852233264\n",
      "Epoch [3/10], Loss: 12.43422099210778\n",
      "Epoch [4/10], Loss: 15.800171515017139\n",
      "Epoch [5/10], Loss: 10.99085071174466\n",
      "Epoch [6/10], Loss: 10.30872954388054\n",
      "Epoch [7/10], Loss: 9.533909935464665\n",
      "Epoch [8/10], Loss: 9.159104022590482\n",
      "Epoch [9/10], Loss: 8.80771449253992\n",
      "Epoch [10/10], Loss: 7.794566451092155\n",
      "Epoch [1/10], Loss: 13.881802604830995\n",
      "Epoch [2/10], Loss: 13.350448695591519\n",
      "Epoch [3/10], Loss: 12.527884449861487\n",
      "Epoch [4/10], Loss: 11.778393761771065\n",
      "Epoch [5/10], Loss: 11.026176982023278\n",
      "Epoch [6/10], Loss: 11.393119687450175\n",
      "Epoch [7/10], Loss: 9.634410244688695\n",
      "Epoch [8/10], Loss: 9.066955694081832\n",
      "Epoch [9/10], Loss: 8.351538372429049\n",
      "Epoch [10/10], Loss: 7.842828300631776\n",
      "Epoch [1/10], Loss: 13.958579822462433\n",
      "Epoch [2/10], Loss: 13.219342169177775\n",
      "Epoch [3/10], Loss: 13.403114686304209\n",
      "Epoch [4/10], Loss: 11.793632289341518\n",
      "Epoch [5/10], Loss: 11.114628295898438\n",
      "Epoch [6/10], Loss: 10.525226667754504\n",
      "Epoch [7/10], Loss: 9.805546551139987\n",
      "Epoch [8/10], Loss: 9.199824760592714\n",
      "Epoch [9/10], Loss: 8.579524722975128\n",
      "Epoch [10/10], Loss: 7.87925073117626\n",
      "Epoch [1/10], Loss: 14.1059929298868\n",
      "Epoch [2/10], Loss: 13.28740742586097\n",
      "Epoch [3/10], Loss: 13.552427069216359\n",
      "Epoch [4/10], Loss: 11.833806949537628\n",
      "Epoch [5/10], Loss: 11.210641286421795\n",
      "Epoch [6/10], Loss: 10.449409055125956\n",
      "Epoch [7/10], Loss: 9.865746017767458\n",
      "Epoch [8/10], Loss: 11.091860139807876\n",
      "Epoch [9/10], Loss: 8.422641197905248\n",
      "Epoch [10/10], Loss: 8.627291409628732\n",
      "Epoch [1/10], Loss: 13.9198499967614\n",
      "Epoch [2/10], Loss: 14.370947664221939\n",
      "Epoch [3/10], Loss: 13.380510789520887\n",
      "Epoch [4/10], Loss: 13.770443946682677\n",
      "Epoch [5/10], Loss: 12.462386499521683\n",
      "Epoch [6/10], Loss: 10.446133796536193\n",
      "Epoch [7/10], Loss: 10.548231154461297\n",
      "Epoch [8/10], Loss: 10.414064053905253\n",
      "Epoch [9/10], Loss: 8.427102312360491\n",
      "Epoch [10/10], Loss: 7.963504224504743\n",
      "Epoch [1/10], Loss: 13.930860397961675\n",
      "Epoch [2/10], Loss: 16.090460267358896\n",
      "Epoch [3/10], Loss: 13.252091961296237\n",
      "Epoch [4/10], Loss: 11.612413333192164\n",
      "Epoch [5/10], Loss: 11.811241834990833\n",
      "Epoch [6/10], Loss: 10.43897627849968\n",
      "Epoch [7/10], Loss: 10.076338345274634\n",
      "Epoch [8/10], Loss: 8.91931778888313\n",
      "Epoch [9/10], Loss: 8.31422468107574\n",
      "Epoch [10/10], Loss: 7.7296361495037464\n",
      "Epoch [1/10], Loss: 13.846342315673828\n",
      "Epoch [2/10], Loss: 13.170454998405612\n",
      "Epoch [3/10], Loss: 12.777755824497769\n",
      "Epoch [4/10], Loss: 12.953323367371851\n",
      "Epoch [5/10], Loss: 10.981584481219857\n",
      "Epoch [6/10], Loss: 10.245163027704978\n",
      "Epoch [7/10], Loss: 9.643096961196589\n",
      "Epoch [8/10], Loss: 9.519867813733159\n",
      "Epoch [9/10], Loss: 8.7226742398009\n",
      "Epoch [10/10], Loss: 7.888153470097756\n",
      "Epoch [1/10], Loss: 14.197323869977678\n",
      "Epoch [2/10], Loss: 13.49482338418766\n",
      "Epoch [3/10], Loss: 12.688859122140068\n",
      "Epoch [4/10], Loss: 11.94022601692044\n",
      "Epoch [5/10], Loss: 11.124797375737405\n",
      "Epoch [6/10], Loss: 10.887621659259407\n",
      "Epoch [7/10], Loss: 9.757973396145568\n",
      "Epoch [8/10], Loss: 9.794556174764828\n",
      "Epoch [9/10], Loss: 8.637292661082988\n",
      "Epoch [10/10], Loss: 7.870648149762835\n",
      "Epoch [1/10], Loss: 14.017381292849171\n",
      "Epoch [2/10], Loss: 13.3423234277842\n",
      "Epoch [3/10], Loss: 14.116873558200135\n",
      "Epoch [4/10], Loss: 11.903285392449826\n",
      "Epoch [5/10], Loss: 11.240132754578882\n",
      "Epoch [6/10], Loss: 10.505039844123685\n",
      "Epoch [7/10], Loss: 10.018528828523596\n",
      "Epoch [8/10], Loss: 9.336971444888992\n",
      "Epoch [9/10], Loss: 8.698232294199418\n",
      "Epoch [10/10], Loss: 9.306146504149146\n",
      "Epoch [1/10], Loss: 14.111944457073601\n",
      "Epoch [2/10], Loss: 13.453250495754943\n",
      "Epoch [3/10], Loss: 12.634624870455994\n",
      "Epoch [4/10], Loss: 12.162899948431521\n",
      "Epoch [5/10], Loss: 11.180469593904457\n",
      "Epoch [6/10], Loss: 13.014493227588886\n",
      "Epoch [7/10], Loss: 9.807099777533084\n",
      "Epoch [8/10], Loss: 10.61249668043487\n",
      "Epoch [9/10], Loss: 9.079749703699228\n",
      "Epoch [10/10], Loss: 8.836551619549187\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4331.413984298706ms\n",
      "Currently in generation 9\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 7.679062960877711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 11.155728731739277\n",
      "Epoch [3/10], Loss: 6.410877996950734\n",
      "Epoch [4/10], Loss: 6.194620573082749\n",
      "Epoch [5/10], Loss: 5.514236046148806\n",
      "Epoch [6/10], Loss: 5.133996871636838\n",
      "Epoch [7/10], Loss: 4.838401554652623\n",
      "Epoch [8/10], Loss: 4.5606962585449216\n",
      "Epoch [9/10], Loss: 4.283848599025181\n",
      "Epoch [10/10], Loss: 4.069265485491071\n",
      "Epoch [1/10], Loss: 7.30009840284075\n",
      "Epoch [2/10], Loss: 6.923058023258132\n",
      "Epoch [3/10], Loss: 6.404900995371293\n",
      "Epoch [4/10], Loss: 6.009157492189991\n",
      "Epoch [5/10], Loss: 5.595021362304688\n",
      "Epoch [6/10], Loss: 5.284010721323441\n",
      "Epoch [7/10], Loss: 5.140494967090841\n",
      "Epoch [8/10], Loss: 4.639870138362962\n",
      "Epoch [9/10], Loss: 4.3609044164540816\n",
      "Epoch [10/10], Loss: 4.14811378323302\n",
      "Epoch [1/10], Loss: 7.744237807916135\n",
      "Epoch [2/10], Loss: 7.00525074553733\n",
      "Epoch [3/10], Loss: 6.5736045993104275\n",
      "Epoch [4/10], Loss: 6.239397243577606\n",
      "Epoch [5/10], Loss: 5.656867021443892\n",
      "Epoch [6/10], Loss: 5.3180358388472575\n",
      "Epoch [7/10], Loss: 5.0268803872867505\n",
      "Epoch [8/10], Loss: 4.604709949104153\n",
      "Epoch [9/10], Loss: 4.500663277762277\n",
      "Epoch [10/10], Loss: 4.173546534557731\n",
      "Epoch [1/10], Loss: 7.455743240045042\n",
      "Epoch [2/10], Loss: 6.978281822983099\n",
      "Epoch [3/10], Loss: 7.2396811847297515\n",
      "Epoch [4/10], Loss: 6.00469519634636\n",
      "Epoch [5/10], Loss: 5.770196011601662\n",
      "Epoch [6/10], Loss: 5.252500664847238\n",
      "Epoch [7/10], Loss: 4.89260198787767\n",
      "Epoch [8/10], Loss: 4.641613853610291\n",
      "Epoch [9/10], Loss: 4.3701280913061025\n",
      "Epoch [10/10], Loss: 4.137844914027623\n",
      "Epoch [1/10], Loss: 7.438045386489557\n",
      "Epoch [2/10], Loss: 7.026365741029077\n",
      "Epoch [3/10], Loss: 6.527168062171158\n",
      "Epoch [4/10], Loss: 6.177498062289491\n",
      "Epoch [5/10], Loss: 6.370010631327727\n",
      "Epoch [6/10], Loss: 5.377372698102678\n",
      "Epoch [7/10], Loss: 5.089154909094986\n",
      "Epoch [8/10], Loss: 4.777138676546058\n",
      "Epoch [9/10], Loss: 4.452500084079042\n",
      "Epoch [10/10], Loss: 4.144772058603715\n",
      "Epoch [1/10], Loss: 7.384941150898836\n",
      "Epoch [2/10], Loss: 7.064866897427306\n",
      "Epoch [3/10], Loss: 6.591753621004066\n",
      "Epoch [4/10], Loss: 6.882547364526865\n",
      "Epoch [5/10], Loss: 5.706285584508156\n",
      "Epoch [6/10], Loss: 5.8717309508031725\n",
      "Epoch [7/10], Loss: 5.041436845526404\n",
      "Epoch [8/10], Loss: 4.7804013123804205\n",
      "Epoch [9/10], Loss: 4.547824608551157\n",
      "Epoch [10/10], Loss: 4.187135794503728\n",
      "Epoch [1/10], Loss: 7.344732541454082\n",
      "Epoch [2/10], Loss: 6.957330316037548\n",
      "Epoch [3/10], Loss: 6.530579762361487\n",
      "Epoch [4/10], Loss: 6.181482207629146\n",
      "Epoch [5/10], Loss: 5.741976874215262\n",
      "Epoch [6/10], Loss: 5.360582200653699\n",
      "Epoch [7/10], Loss: 5.021298817225865\n",
      "Epoch [8/10], Loss: 4.639064004080637\n",
      "Epoch [9/10], Loss: 4.581573902052276\n",
      "Epoch [10/10], Loss: 4.155527312609614\n",
      "Epoch [1/10], Loss: 7.4101103677555\n",
      "Epoch [2/10], Loss: 7.452176009197625\n",
      "Epoch [3/10], Loss: 6.589931165344861\n",
      "Epoch [4/10], Loss: 6.691193048516098\n",
      "Epoch [5/10], Loss: 5.796782759063098\n",
      "Epoch [6/10], Loss: 5.391030173788265\n",
      "Epoch [7/10], Loss: 4.972060716590103\n",
      "Epoch [8/10], Loss: 4.76405634043168\n",
      "Epoch [9/10], Loss: 4.408482672243702\n",
      "Epoch [10/10], Loss: 4.165078473772321\n",
      "Epoch [1/10], Loss: 7.544367177535077\n",
      "Epoch [2/10], Loss: 7.176010907231545\n",
      "Epoch [3/10], Loss: 13.158013489392339\n",
      "Epoch [4/10], Loss: 6.837266233794543\n",
      "Epoch [5/10], Loss: 5.8989171179946585\n",
      "Epoch [6/10], Loss: 5.50264151436942\n",
      "Epoch [7/10], Loss: 5.2261722704829\n",
      "Epoch [8/10], Loss: 5.199750572637636\n",
      "Epoch [9/10], Loss: 4.42506418033522\n",
      "Epoch [10/10], Loss: 4.157489284593232\n",
      "Epoch [1/10], Loss: 7.789675954701949\n",
      "Epoch [2/10], Loss: 11.270650503976004\n",
      "Epoch [3/10], Loss: 6.433222363530373\n",
      "Epoch [4/10], Loss: 6.062810108418367\n",
      "Epoch [5/10], Loss: 5.691807461174167\n",
      "Epoch [6/10], Loss: 5.24253820536088\n",
      "Epoch [7/10], Loss: 5.031130315041056\n",
      "Epoch [8/10], Loss: 4.584734086017219\n",
      "Epoch [9/10], Loss: 4.326577861552336\n",
      "Epoch [10/10], Loss: 4.100673892741301\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4404.820919036865ms\n",
      "Currently in generation 10\n",
      "--- Starting SGD\n",
      "Epoch [1/10], Loss: 3.7864371007802533\n",
      "Epoch [2/10], Loss: 3.687506962992935\n",
      "Epoch [3/10], Loss: 3.472268184739716\n",
      "Epoch [4/10], Loss: 3.3495012929488204\n",
      "Epoch [5/10], Loss: 3.1856784742705675\n",
      "Epoch [6/10], Loss: 2.981328573421556\n",
      "Epoch [7/10], Loss: 2.8050719124930246\n",
      "Epoch [8/10], Loss: 2.606070195412149\n",
      "Epoch [9/10], Loss: 2.525169242158228\n",
      "Epoch [10/10], Loss: 3.1753199427468437\n",
      "Epoch [1/10], Loss: 3.8653581712683853\n",
      "Epoch [2/10], Loss: 3.662219188456633\n",
      "Epoch [3/10], Loss: 4.626754829251037\n",
      "Epoch [4/10], Loss: 3.3609477202776743\n",
      "Epoch [5/10], Loss: 3.2051118111123844\n",
      "Epoch [6/10], Loss: 3.0242638163663904\n",
      "Epoch [7/10], Loss: 2.861844104066187\n",
      "Epoch [8/10], Loss: 2.703786988550303\n",
      "Epoch [9/10], Loss: 2.5609681378105433\n",
      "Epoch [10/10], Loss: 2.4945833478655133\n",
      "Epoch [1/10], Loss: 3.8485515547771842\n",
      "Epoch [2/10], Loss: 3.7983090238573447\n",
      "Epoch [3/10], Loss: 4.367628485231983\n",
      "Epoch [4/10], Loss: 7.047792750767299\n",
      "Epoch [5/10], Loss: 3.1550044172637315\n",
      "Epoch [6/10], Loss: 3.0306721198802093\n",
      "Epoch [7/10], Loss: 2.8033993094308034\n",
      "Epoch [8/10], Loss: 2.6783350461843063\n",
      "Epoch [9/10], Loss: 2.544576760123731\n",
      "Epoch [10/10], Loss: 2.437563863092539\n",
      "Epoch [1/10], Loss: 3.8940504113022163\n",
      "Epoch [2/10], Loss: 3.74058283591757\n",
      "Epoch [3/10], Loss: 3.5658815837393\n",
      "Epoch [4/10], Loss: 3.3921041060467156\n",
      "Epoch [5/10], Loss: 3.1929211674904336\n",
      "Epoch [6/10], Loss: 3.0509047745685187\n",
      "Epoch [7/10], Loss: 3.007014453970656\n",
      "Epoch [8/10], Loss: 2.81229439404546\n",
      "Epoch [9/10], Loss: 2.660543956367337\n",
      "Epoch [10/10], Loss: 3.3264409937177386\n",
      "Epoch [1/10], Loss: 3.9038153512137277\n",
      "Epoch [2/10], Loss: 3.781873621259417\n",
      "Epoch [3/10], Loss: 3.5472500213311644\n",
      "Epoch [4/10], Loss: 9.81524194211376\n",
      "Epoch [5/10], Loss: 3.211543747259646\n",
      "Epoch [6/10], Loss: 3.0081719534737723\n",
      "Epoch [7/10], Loss: 2.848518869828205\n",
      "Epoch [8/10], Loss: 2.731951567980708\n",
      "Epoch [9/10], Loss: 2.6339156341552736\n",
      "Epoch [10/10], Loss: 2.466975069424725\n",
      "Epoch [1/10], Loss: 5.9356608924087215\n",
      "Epoch [2/10], Loss: 3.7550185627840005\n",
      "Epoch [3/10], Loss: 3.543744908546915\n",
      "Epoch [4/10], Loss: 3.3839479104338253\n",
      "Epoch [5/10], Loss: 3.2153406384526466\n",
      "Epoch [6/10], Loss: 3.052014645946269\n",
      "Epoch [7/10], Loss: 2.928220949756856\n",
      "Epoch [8/10], Loss: 2.753830448072784\n",
      "Epoch [9/10], Loss: 2.576837025856485\n",
      "Epoch [10/10], Loss: 2.47698974609375\n",
      "Epoch [1/10], Loss: 3.915305916922433\n",
      "Epoch [2/10], Loss: 3.7353544429856904\n",
      "Epoch [3/10], Loss: 3.573695314368423\n",
      "Epoch [4/10], Loss: 3.4489199673399633\n",
      "Epoch [5/10], Loss: 3.2817401228145675\n",
      "Epoch [6/10], Loss: 3.0532352260667452\n",
      "Epoch [7/10], Loss: 2.8822425250617827\n",
      "Epoch [8/10], Loss: 2.766896974213269\n",
      "Epoch [9/10], Loss: 2.6718038343896673\n",
      "Epoch [10/10], Loss: 2.4638210623604913\n",
      "Epoch [1/10], Loss: 3.93813089487504\n",
      "Epoch [2/10], Loss: 4.687582372548629\n",
      "Epoch [3/10], Loss: 3.6102161267338966\n",
      "Epoch [4/10], Loss: 3.423236840695751\n",
      "Epoch [5/10], Loss: 3.2118984549386163\n",
      "Epoch [6/10], Loss: 3.045777678197744\n",
      "Epoch [7/10], Loss: 3.6327750879860656\n",
      "Epoch [8/10], Loss: 2.728433227045515\n",
      "Epoch [9/10], Loss: 2.628613804408482\n",
      "Epoch [10/10], Loss: 2.4743308818583585\n",
      "Epoch [1/10], Loss: 4.832989884979871\n",
      "Epoch [2/10], Loss: 3.8005177836515465\n",
      "Epoch [3/10], Loss: 3.5988908323949698\n",
      "Epoch [4/10], Loss: 3.394829107790577\n",
      "Epoch [5/10], Loss: 3.263506574046855\n",
      "Epoch [6/10], Loss: 3.0925906278649156\n",
      "Epoch [7/10], Loss: 2.905182439064493\n",
      "Epoch [8/10], Loss: 2.8022511493916413\n",
      "Epoch [9/10], Loss: 2.669669136514469\n",
      "Epoch [10/10], Loss: 2.5208966656120455\n",
      "Epoch [1/10], Loss: 3.923591713418766\n",
      "Epoch [2/10], Loss: 3.8370324395627393\n",
      "Epoch [3/10], Loss: 3.547221035860023\n",
      "Epoch [4/10], Loss: 3.3402804503148915\n",
      "Epoch [5/10], Loss: 3.2160052614795918\n",
      "Epoch [6/10], Loss: 3.0447433097995056\n",
      "Epoch [7/10], Loss: 2.8447386187939405\n",
      "Epoch [8/10], Loss: 2.7203099776287467\n",
      "Epoch [9/10], Loss: 2.5801848181899714\n",
      "Epoch [10/10], Loss: 2.414530189669862\n",
      "--- Finished SGD\n",
      "--- Starting GA\n",
      "--- -- Finished fitness evaluation, length: 10\n",
      "--- -- Finished creating offspring population\n",
      "--- -- Finished evaluating fitness of offspring population\n",
      "--- Finished GA,Time:-4595.05033493042ms\n",
      "Finished training process\n",
      "All Time:-176023.0438709259ms\n"
     ]
    }
   ],
   "source": [
    "Train_start = time.time()\n",
    "trained_population = GA_Neural_train(population=population,\n",
    "                                    pop_size = pop_size,\n",
    "                                    max_generations=max_generations,\n",
    "                                    SGD_steps=SGD_steps,GA_steps=GA_steps,\n",
    "                                    offspring_size=offspring_size,elitist_level=elitist_level,rho=rho,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    train_loader=train_loader)\n",
    "Train_end = time.time()\n",
    "print(f\"All Time:{(Train_start-Train_end)*1000}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c10858",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "676ced0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_function(network, data_loader):\n",
    "    # init accuracy\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for genes, types in data_loader:\n",
    "            genes = genes.to(device)\n",
    "            types = types.to(device)\n",
    "            outputs = network(genes)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += genes.size(0)\n",
    "            \n",
    "            correct += (predicted == types).sum().item()\n",
    "\n",
    "        accuracy =  correct / total\n",
    "        #print('Accuracy of the model on the test images: {} %'.format(accuracy))\n",
    "        \n",
    "    # send network back to cpu\n",
    "    network.cpu()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedcf55a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b784ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = [test_function(trained_population[i],test_loader) for i in range(pop_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a9a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6895238095238095,\n",
       " 0.6895238095238095,\n",
       " 0.6876190476190476,\n",
       " 0.6885714285714286,\n",
       " 0.6866666666666666,\n",
       " 0.6847619047619048,\n",
       " 0.6914285714285714,\n",
       " 0.6866666666666666,\n",
       " 0.6876190476190476,\n",
       " 0.6876190476190476]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04916cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880000000000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_accuracy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde91428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
