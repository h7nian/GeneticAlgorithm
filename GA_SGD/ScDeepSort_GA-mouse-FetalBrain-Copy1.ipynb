{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f045d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from scipy.sparse import csr_matrix, vstack, save_npz\n",
    "from sklearn.decomposition import PCA\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d94e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.contrib.sampling import NeighborSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c89f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f729ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from '/home/chenhuaguan/.conda/envs/python3.6/lib/python3.6/site-packages/torch/version.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d6de9",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c953db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20968a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gene = pd.read_csv(\"data/mouse_Fetal_brain4369_data.csv\",index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c622ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_1</th>\n",
       "      <th>C_2</th>\n",
       "      <th>C_3</th>\n",
       "      <th>C_4</th>\n",
       "      <th>C_5</th>\n",
       "      <th>C_6</th>\n",
       "      <th>C_7</th>\n",
       "      <th>C_8</th>\n",
       "      <th>C_9</th>\n",
       "      <th>C_10</th>\n",
       "      <th>...</th>\n",
       "      <th>C_4360</th>\n",
       "      <th>C_4361</th>\n",
       "      <th>C_4362</th>\n",
       "      <th>C_4363</th>\n",
       "      <th>C_4364</th>\n",
       "      <th>C_4365</th>\n",
       "      <th>C_4366</th>\n",
       "      <th>C_4367</th>\n",
       "      <th>C_4368</th>\n",
       "      <th>C_4369</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0610009B22Rik</th>\n",
       "      <td>2.516851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.691593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.623779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.82721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009E02Rik</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009L18Rik</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.673823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.012705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610010F05Rik</th>\n",
       "      <td>2.516851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.623779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.815324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610010K14Rik</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.964363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tut4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.623779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtl4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtl3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tut7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zup1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.590051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18226 rows × 4369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    C_1       C_2  C_3  C_4       C_5  C_6  C_7  C_8  C_9  \\\n",
       "0610009B22Rik  2.516851  0.000000  0.0  0.0  2.691593  0.0  0.0  0.0  0.0   \n",
       "0610009E02Rik  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "0610009L18Rik  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "0610010F05Rik  2.516851  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "0610010K14Rik  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "...                 ...       ...  ...  ...       ...  ...  ...  ...  ...   \n",
       "Tut4           0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "Rtl4           0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "Rtl3           0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "Tut7           0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "Zup1           0.000000  2.590051  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "\n",
       "               C_10  ...  C_4360    C_4361  C_4362    C_4363    C_4364  \\\n",
       "0610009B22Rik   0.0  ...     0.0  2.623779     0.0  0.000000  0.000000   \n",
       "0610009E02Rik   0.0  ...     0.0  0.000000     0.0  0.000000  0.000000   \n",
       "0610009L18Rik   0.0  ...     0.0  0.000000     0.0  0.000000  2.673823   \n",
       "0610010F05Rik   0.0  ...     0.0  2.623779     0.0  2.815324  0.000000   \n",
       "0610010K14Rik   0.0  ...     0.0  0.000000     0.0  0.000000  0.000000   \n",
       "...             ...  ...     ...       ...     ...       ...       ...   \n",
       "Tut4            0.0  ...     0.0  2.623779     0.0  0.000000  0.000000   \n",
       "Rtl4            0.0  ...     0.0  0.000000     0.0  0.000000  0.000000   \n",
       "Rtl3            0.0  ...     0.0  0.000000     0.0  0.000000  0.000000   \n",
       "Tut7            0.0  ...     0.0  0.000000     0.0  0.000000  0.000000   \n",
       "Zup1            0.0  ...     0.0  0.000000     0.0  0.000000  0.000000   \n",
       "\n",
       "               C_4365    C_4366   C_4367  C_4368    C_4369  \n",
       "0610009B22Rik     0.0  0.000000  2.82721     0.0  0.000000  \n",
       "0610009E02Rik     0.0  0.000000  0.00000     0.0  0.000000  \n",
       "0610009L18Rik     0.0  3.012705  0.00000     0.0  0.000000  \n",
       "0610010F05Rik     0.0  0.000000  0.00000     0.0  0.000000  \n",
       "0610010K14Rik     0.0  0.000000  0.00000     0.0  2.964363  \n",
       "...               ...       ...      ...     ...       ...  \n",
       "Tut4              0.0  0.000000  0.00000     0.0  0.000000  \n",
       "Rtl4              0.0  0.000000  0.00000     0.0  0.000000  \n",
       "Rtl3              0.0  0.000000  0.00000     0.0  0.000000  \n",
       "Tut7              0.0  0.000000  0.00000     0.0  0.000000  \n",
       "Zup1              0.0  0.000000  0.00000     0.0  0.000000  \n",
       "\n",
       "[18226 rows x 4369 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7094d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2gene = data_gene.index.values.tolist()\n",
    "id2gene.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2cc9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cell = pd.read_csv(\"data/mouse_Fetal_brain4369_celltype.csv\", dtype=np.str, header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0b9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = set()\n",
    "cell_type_list = []\n",
    "data_cell['Cell_type'] = data_cell['Cell_type'].map(str.strip)\n",
    "cell_types = set(data_cell.values[:, 1])\n",
    "cell_type_list.extend(data_cell.values[:, 1].tolist())\n",
    "id2label = list(cell_types)\n",
    "label_statistics = dict(collections.Counter(cell_type_list))\n",
    "total_cell = sum(label_statistics.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb65084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, num in label_statistics.items():\n",
    "    if num / total_cell <= 0.005:\n",
    "        id2label.remove(label)  # remove exclusive labels\n",
    "gene2id = {gene: idx for idx, gene in enumerate(id2gene)}\n",
    "num_genes = len(id2gene)\n",
    "# prepare unified labels\n",
    "num_labels = len(id2label)\n",
    "label2id = {label: idx for idx, label in enumerate(id2label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58d198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.DGLGraph()\n",
    "\n",
    "gene_ids = torch.arange(num_genes, dtype=torch.int32, device=device).unsqueeze(-1)\n",
    "graph.add_nodes(num_genes, {'id': gene_ids})\n",
    "all_labels = []\n",
    "matrices = []\n",
    "num_cells = 0\n",
    "cell2type = pd.read_csv(\"data/mouse_Fetal_brain4369_celltype.csv\",index_col=0)\n",
    "cell2type.columns = ['cell', 'type']\n",
    "cell2type['type'] = cell2type['type'].map(str.strip)\n",
    "cell2type['id'] = cell2type['type'].map(label2id)\n",
    "filter_cell = np.where(pd.isnull(cell2type['id']) == False)[0]\n",
    "cell2type = cell2type.iloc[filter_cell]\n",
    "all_labels += cell2type['id'].tolist()\n",
    "df = pd.read_csv(\"data/mouse_Fetal_brain4369_data.csv\",index_col = 0)\n",
    "df = df.transpose(copy=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e610966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[filter_cell]\n",
    "df = df.rename(columns=gene2id)\n",
    "col = [c for c in df.columns if c in gene2id.values()]\n",
    "df = df[col]\n",
    "arr = df.to_numpy()\n",
    "row_idx, col_idx = np.nonzero(arr > 0)  # intra-dataset index\n",
    "non_zeros = arr[(row_idx, col_idx)]  # non-zero values\n",
    "cell_idx = row_idx + graph.number_of_nodes()  # cell_index\n",
    "gene_idx = df.columns[col_idx].astype(int).tolist()  # gene_index\n",
    "info_shape = (len(df), num_genes)\n",
    "info = csr_matrix((non_zeros, (row_idx, gene_idx)), shape=info_shape)\n",
    "matrices.append(info)\n",
    "\n",
    "num_cells += len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "697ee87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.tensor([-1] * len(df), dtype=torch.int32, device=device).unsqueeze(-1)\n",
    "graph.add_nodes(len(df), {'id': ids})\n",
    "graph.add_edges(cell_idx, gene_idx,\n",
    "                {'weight': torch.tensor(non_zeros, dtype=torch.float32, device=device).unsqueeze(1)})\n",
    "graph.add_edges(gene_idx, cell_idx,\n",
    "                {'weight': torch.tensor(non_zeros, dtype=torch.float32, device=device).unsqueeze(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce041d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feat = vstack(matrices).toarray()  # cell-wise  (cell, gene)\n",
    "gene_pca = PCA(400, random_state=10086).fit(sparse_feat.T)\n",
    "gene_feat = gene_pca.transform(sparse_feat.T)\n",
    "gene_evr = sum(gene_pca.explained_variance_ratio_) * 100\n",
    "sparse_feat = sparse_feat / (np.sum(sparse_feat, axis=1, keepdims=True) + 1e-6)\n",
    "# use weighted gene_feat as cell_feat\n",
    "cell_feat = sparse_feat.dot(gene_feat)\n",
    "gene_feat = torch.from_numpy(gene_feat)  # use shared storage\n",
    "cell_feat = torch.from_numpy(cell_feat)\n",
    "\n",
    "graph.ndata['features'] = torch.cat([gene_feat, cell_feat], dim=0).type(torch.float).to(device)\n",
    "labels = torch.tensor([-1] * num_genes + all_labels, dtype=torch.long, device=device)  # [gene_num+train_num]\n",
    "per = np.random.permutation(range(num_genes, num_genes + num_cells))\n",
    "test_ids = torch.tensor(per[:int(num_cells // ((1 - 0.2) / 0.2 + 1))]).to(device)\n",
    "train_ids = torch.tensor(per[int(num_cells // ((1 - 0.2) / 0.2 + 1)):]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe01998",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degrees = graph.in_degrees()\n",
    "for i in range(graph.number_of_nodes()):\n",
    "    src, dst, in_edge_id = graph.in_edges(i, form='all')\n",
    "    if src.shape[0] == 0:\n",
    "        continue\n",
    "    edge_w = graph.edata['weight'][in_edge_id]\n",
    "    graph.edata['weight'][in_edge_id] = in_degrees[i] * edge_w / torch.sum(edge_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393ec077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add self-loop\n",
    "graph.add_edges(graph.nodes(), graph.nodes(),\n",
    "                {'weight': torch.ones(graph.number_of_nodes(), dtype=torch.float, device=device).unsqueeze(1)})\n",
    "graph.readonly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19854d3b",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca283aa",
   "metadata": {},
   "source": [
    "## NodeUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeUpdate(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation=None, norm=None):\n",
    "        super(NodeUpdate, self).__init__()\n",
    "        self.fc_neigh = nn.Linear(in_features=in_feats, out_features=out_feats)\n",
    "        self.activation = activation\n",
    "        self.norm = norm\n",
    "        nn.init.xavier_uniform_(self.fc_neigh.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, node):\n",
    "        h_neigh = node.data['neigh']\n",
    "        h_neigh = self.fc_neigh(h_neigh)\n",
    "        if self.activation is not None:\n",
    "            h_neigh = self.activation(h_neigh)\n",
    "        if self.norm is not None:\n",
    "            h_neigh = self.norm(h_neigh)\n",
    "        return {'activation': h_neigh}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40651976",
   "metadata": {},
   "source": [
    "## GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5d444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers, gene_num, activation=None, norm=None, dropout=0.0):\n",
    "        super(GNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.gene_num = gene_num\n",
    "        if dropout != 0:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(NodeUpdate(in_feats=in_feats, out_feats=n_hidden, activation=activation, norm=norm))\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.layers.append(NodeUpdate(in_feats=n_hidden, out_feats=n_hidden, activation=activation, norm=norm))\n",
    "\n",
    "        # [gene_num] is alpha of gene-gene, [gene_num+1] is alpha of cell-cell self loop\n",
    "        self.alpha = nn.Parameter(torch.tensor([1] * (self.gene_num + 2), dtype=torch.float32).unsqueeze(-1))\n",
    "        self.linear = nn.Linear(n_hidden, n_classes)\n",
    "        nn.init.xavier_uniform_(self.linear.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def message_func(self, edges: dgl.udf.EdgeBatch):\n",
    "        number_of_edges = edges.src['h'].shape[0]\n",
    "        indices = np.expand_dims(np.array([self.gene_num + 1] * number_of_edges, dtype=np.int32), axis=1)\n",
    "        src_id, dst_id = edges.src['id'].cpu().numpy(), edges.dst['id'].cpu().numpy()\n",
    "        indices = np.where((src_id >= 0) & (dst_id < 0), src_id, indices)  # gene->cell\n",
    "        indices = np.where((dst_id >= 0) & (src_id < 0), dst_id, indices)  # cell->gene\n",
    "        indices = np.where((dst_id >= 0) & (src_id >= 0), self.gene_num, indices)  # gene-gene\n",
    "        \n",
    "        print(type(edges.src['h']))\n",
    "        print(type(self.alpha[indices.squeeze()]))\n",
    "        \n",
    "        h = edges.src['h'].to(torch.device(\"cuda:1\")) * self.alpha[indices.squeeze()].to(torch.device(\"cuda:1\"))\n",
    "        # return {'m': h}\n",
    "        return {'m': h * edges.data['weight']}\n",
    "\n",
    "    def forward(self, nf: dgl.NodeFlow):\n",
    "        nf.layers[0].data['activation'] = nf.layers[0].data['features']\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = nf.layers[i].data.pop('activation')\n",
    "            if self.dropout:\n",
    "                h = self.dropout(h)\n",
    "            nf.layers[i].data['h'] = h\n",
    "            nf.block_compute(i, self.message_func, fn.mean('m', 'neigh'), layer)\n",
    "        h = nf.layers[-1].data.pop('activation')\n",
    "        h = self.linear(h).to(torch.device(\"cuda:1\"))\n",
    "        return h\n",
    "\n",
    "    def evaluate(self, nf: dgl.NodeFlow):\n",
    "        def message_func(edges: dgl.EdgeBatch):\n",
    "            # edges.src['h']： (number of edges, feature dim)\n",
    "            number_of_edges = edges.src['h'].shape[0]\n",
    "            indices = np.expand_dims(np.array([self.gene_num + 1] * number_of_edges, dtype=np.int32), axis=1)\n",
    "            src_id, dst_id = edges.src['id'].cpu().numpy(), edges.dst['id'].cpu().numpy()\n",
    "            indices = np.where((src_id >= 0) & (dst_id < 0), src_id, indices)  # gene->cell\n",
    "            indices = np.where((dst_id >= 0) & (src_id < 0), dst_id, indices)  # cell->gene\n",
    "            indices = np.where((dst_id >= 0) & (src_id >= 0), self.gene_num, indices)  # gene-gene\n",
    "            \n",
    "            h = edges.src['h'] * self.alpha[indices.squeeze()]\n",
    "            return {'m': h * edges.data['weight']}\n",
    "\n",
    "        nf.layers[0].data['activation'] = nf.layers[0].data['features'].cpu()\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = nf.layers[i].data.pop('activation')\n",
    "            if self.dropout:\n",
    "                h = self.dropout(h)\n",
    "            nf.layers[i].data['h'] = h\n",
    "            nf.block_compute(i, message_func, fn.mean('m', 'neigh'), layer)\n",
    "        h = nf.layers[-1].data.pop('activation')\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5518d",
   "metadata": {},
   "source": [
    "# Adam_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam_Trainer:\n",
    "    def __init__(self, device_train,gnn_model,lr,weight_decay,Adam_epochs,batch_size,\n",
    "                num_cells,\n",
    "                num_genes,\n",
    "                num_labels,\n",
    "                graph,\n",
    "                train_ids,\n",
    "                test_ids,\n",
    "                labels):\n",
    "        \n",
    "        self.device = device_train\n",
    "        \n",
    "        self.num_cells = num_cells\n",
    "        self.num_genes = num_genes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.graph = graph\n",
    "        \n",
    "        self.graph.readonly(True)\n",
    "        \n",
    "        self.train_ids = train_ids\n",
    "        self.test_ids = test_ids\n",
    "        self.labels = labels \n",
    "        \n",
    "        self.labels = self.labels.to(self.device)\n",
    "        \n",
    "        self.model = gnn_model\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.epochs = Adam_epochs\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr,\n",
    "                                          weight_decay=self.weight_decay)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "        \n",
    "        self.num_neighbors = self.num_cells + self.num_genes\n",
    "\n",
    "    def fit(self):\n",
    "        max_test_acc, _train_acc, _epoch = 0, 0, 0\n",
    "        for epoch in range(self.epochs):\n",
    "            loss = self.train()\n",
    "            train_correct, train_unsure = self.evaluate(self.train_ids, 'train')\n",
    "            train_acc = train_correct / len(self.train_ids)\n",
    "            test_correct, test_unsure = self.evaluate(self.test_ids, 'test')\n",
    "            test_acc = test_correct / len(self.test_ids)\n",
    "            if max_test_acc <= test_acc:\n",
    "                final_test_correct_num = test_correct\n",
    "                final_test_unsure_num = test_unsure\n",
    "                _train_acc = train_acc\n",
    "                _epoch = epoch\n",
    "                max_test_acc = test_acc\n",
    "                self.save_model()\n",
    "            print(\n",
    "                f\">>>>Epoch {epoch+1:04d}: Train Acc {train_acc:.4f}, Loss {loss / len(self.train_ids):.4f}, Test correct {test_correct}, \"\n",
    "                f\"Test unsure {test_unsure}, Test Acc {test_acc:.4f}\")\n",
    "            if train_acc == 1:\n",
    "                break\n",
    "\n",
    "        #print(f\"---{self.params.species} {self.params.tissue} Best test result:---\")\n",
    "        print(f\"Epoch {_epoch+1:04d}, Train Acc {_train_acc:.4f}, Test Correct Num {final_test_correct_num}, Test Total Num {len(self.test_ids)}, Test Unsure Num {final_test_unsure_num}, Test Acc {final_test_correct_num / len(self.test_ids):.4f}\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch, nf in enumerate(NeighborSampler(g=self.graph,\n",
    "                                                   batch_size=self.batch_size,\n",
    "                                                   expand_factor=self.num_neighbors,\n",
    "                                                   num_hops=1,\n",
    "                                                   neighbor_type='in',\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=8,\n",
    "                                                   seed_nodes=self.train_ids.long())):\n",
    "            nf.copy_from_parent()  # Copy node/edge features from the parent graph.\n",
    "            logits = self.model(nf)\n",
    "            batch_nids = nf.layer_parent_nid(-1).type(torch.long).to(device=self.device)\n",
    "            loss = self.loss_fn(logits, self.labels[batch_nids])\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def evaluate(self, ids, type='test'):\n",
    "        self.model.eval()\n",
    "        total_correct, total_unsure = 0, 0\n",
    "        for nf in NeighborSampler(g=self.graph,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  expand_factor=self.num_cells + self.num_genes,\n",
    "                                  num_hops=1,\n",
    "                                  neighbor_type='in',\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=8,\n",
    "                                  seed_nodes=ids.long()):\n",
    "            nf.copy_from_parent()  # Copy node/edge features from the parent graph.\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(nf).cpu()\n",
    "            batch_nids = nf.layer_parent_nid(-1).type(torch.long)\n",
    "            logits = nn.functional.softmax(logits, dim=1).numpy()\n",
    "            label_list = self.labels.cpu()[batch_nids]\n",
    "            for pred, label in zip(logits, label_list):\n",
    "                max_prob = pred.max().item()\n",
    "                if max_prob < 2 / num_labels:\n",
    "                    total_unsure += 1\n",
    "                elif pred.argmax().item() == label:\n",
    "                    total_correct += 1\n",
    "\n",
    "        return total_correct, total_unsure\n",
    "\n",
    "    def save_model(self):\n",
    "        state = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(state, \"GA_Model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cbc05",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36e06989",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crossover_and_mutation(parents, sigma=0.05):\n",
    "\n",
    "    \n",
    "    base_sd = parents[0].state_dict()\n",
    "    keys = base_sd                    # use all layers to be affected\n",
    "    \n",
    "    # Sum of the weights of the parent\n",
    "    for i in range(1, len(parents)):\n",
    "        parent_sd = parents[i].state_dict()\n",
    "        for key in keys:\n",
    "            base_sd[key] = base_sd[key] + parent_sd[key]\n",
    "            \n",
    "    \n",
    "    # Average and add mutation\n",
    "    num_parents = len(parents)\n",
    "    \n",
    "    for key in keys:\n",
    "        \n",
    "        tensor_size = base_sd[key].size()\n",
    "        random_tensor = torch.normal(mean=0.0, std=sigma, size=tensor_size)\n",
    "        \n",
    "        base_sd[key] = (base_sd[key] / num_parents) + random_tensor\n",
    "    \n",
    "    # create offspring\n",
    "    offspring = GNN(in_feats=in_feats,\n",
    "                         n_hidden=n_hidden,\n",
    "                         n_classes=num_labels,\n",
    "                         n_layers=1,\n",
    "                         gene_num=num_genes,\n",
    "                         activation=F.relu,\n",
    "                         dropout=0.1).to(device_train)\n",
    "    \n",
    "    offspring.load_state_dict(base_sd)\n",
    "    \n",
    "    return offspring\n",
    "    \n",
    "\n",
    "def create_offspring(population, fitness, rho, sigma):\n",
    "\n",
    "    \n",
    "    # Perform selection\n",
    "    parents = random.choices(population,weights=fitness, k=rho) \n",
    "    \n",
    "    # Perform crossover and mutation\n",
    "    offspring = crossover_and_mutation(parents, sigma)\n",
    "    \n",
    "    \n",
    "    return offspring\n",
    "\n",
    "\n",
    "def GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, train_ids,\n",
    "                test_ids,\n",
    "                graph,\n",
    "                batch_size,\n",
    "                num_cells,\n",
    "                num_genes,\n",
    "                labels):\n",
    "    \n",
    "    #Calculate fitness of trained population\n",
    "\n",
    "    fitness = [calc_loss(population[i],train_ids,graph,batch_size,num_cells,num_genes,labels) for i in range(pop_size)]\n",
    "    \n",
    "    print(f\"--- -- Finished fitness evaluation, length: {len(fitness)}\")\n",
    "    \n",
    "    #Create offspring population\n",
    "    \n",
    "    fitness_weighted = fitness\n",
    "    offspring_population = [create_offspring(population, fitness_weighted, rho, sigma) for i in range(offspring_size)]\n",
    "    \n",
    "    print(\"--- -- Finished creating offspring population\")\n",
    "    \n",
    "    #Evaluate fitness of offsprings \n",
    "    \n",
    "    offspring_fitness = [calc_loss(offspring_population[i],test_ids,graph,batch_size,num_cells,num_genes,labels) for i in range(offspring_size)]\n",
    "    \n",
    "    print(\"--- -- Finished evaluating fitness of offspring population\")\n",
    "    \n",
    "    # Combine fitness and population lists\n",
    "    \n",
    "    combined_fitness = fitness + offspring_fitness\n",
    "    combined_population = population + offspring_population\n",
    "    \n",
    "    # sort and select population by their fitness values\n",
    "    \n",
    "    sorted_population = [pop for _, pop in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    sorted_fitness = [loss for loss, _ in sorted(zip(combined_fitness, combined_population), key=lambda pair: pair[0])]\n",
    "    \n",
    "    m = int(pop_size * elitist_level)\n",
    "    new_population = sorted_population[0:m]\n",
    "    \n",
    "    # Fill up rest of population\n",
    "    difference = pop_size - m\n",
    "    remaining_population = list(set(sorted_population) - set(new_population))\n",
    "    filler_population = random.sample(remaining_population, difference)\n",
    "    \n",
    "    # assemble new population and return\n",
    "    new_population = new_population + filler_population\n",
    "    \n",
    "    return new_population, sorted_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d538178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(model, train_ids,graph,batch_size,num_cells,num_genes,labels):\n",
    "    model.eval()\n",
    "    total_correct, total_unsure = 0, 0\n",
    "    for nf in NeighborSampler(g=graph,\n",
    "                              batch_size=batch_size,\n",
    "                              expand_factor=num_cells + num_genes,\n",
    "                              num_hops=1,\n",
    "                              neighbor_type='in',\n",
    "                              shuffle=True,\n",
    "                              num_workers=8,\n",
    "                              seed_nodes=train_ids.long()):\n",
    "        nf.copy_from_parent()  # Copy node/edge features from the parent graph.\n",
    "        with torch.no_grad():\n",
    "            logits = model(nf).cpu()\n",
    "        batch_nids = nf.layer_parent_nid(-1).type(torch.long)\n",
    "        logits = nn.functional.softmax(logits, dim=1).numpy()\n",
    "        label_list = labels.cpu()[batch_nids]\n",
    "        for pred, label in zip(logits, label_list):\n",
    "            max_prob = pred.max().item()\n",
    "            if max_prob < 2 / num_labels:\n",
    "                total_unsure += 1\n",
    "            elif pred.argmax().item() == label:\n",
    "                total_correct += 1\n",
    "\n",
    "    return total_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657950d",
   "metadata": {},
   "source": [
    "# GA_Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f14faa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_Neural_train(population,\n",
    "                    pop_size,\n",
    "                    max_generations, \n",
    "                    Adam_epochs, GA_steps, \n",
    "                    offspring_size, elitist_level, rho,\n",
    "                    learning_rate,\n",
    "                   weight_decay,\n",
    "                   batch_size,\n",
    "                   num_cells,num_genes,graph,train_ids,test_ids,labels):\n",
    "    \n",
    "    print(f\"Starting with population of size: {pop_size}\")\n",
    "    \n",
    "    \n",
    "    for k in range(max_generations):\n",
    "        print(f\"Currently in generation {k+1}\")\n",
    "        \n",
    "        #SGD\n",
    "        print(f\"--- Starting Adam\")\n",
    "        \n",
    "        # Sequential version\n",
    "        #population = [SGD_training(population[i], SGD_steps, learning_rate, 0.9, train_loader) for i in range(pop_size)]\n",
    "        for i in range(pop_size):\n",
    "            train = Adam_Trainer(device_train = device_train,gnn_model = population[i],\n",
    "                                 lr = learning_rate,weight_decay = weight_decay,Adam_epochs = Adam_epochs,\n",
    "                                 batch_size = batch_size,num_cells = num_cells,\n",
    "                                                        num_genes = num_genes,\n",
    "                                                        num_labels = num_labels,\n",
    "                                                        graph = graph,\n",
    "                                                        train_ids = train_ids,\n",
    "                                                        test_ids = test_ids,\n",
    "                                                        labels = labels)\n",
    "            train.fit()\n",
    "        \n",
    "        print(f\"--- Finished Adam\")\n",
    "         \n",
    "        # GA\n",
    "        print(f\"--- Starting GA\")\n",
    "        GA_start = time.time()\n",
    "        sorted_fitness = []          # store the sorted fitness values to maybe use in data collection\n",
    "        for i in range(0, GA_steps):\n",
    "            \n",
    "            sigma = 0.01 / (k+1)\n",
    "            population, sorted_fitness = GA_training(population, pop_size, offspring_size, elitist_level, rho, sigma, train_ids,\n",
    "                                                    test_ids,\n",
    "                                                    graph,\n",
    "                                                    batch_size,\n",
    "                                                    num_cells,\n",
    "                                                    num_genes,\n",
    "                                                    labels)\n",
    "        \n",
    "        GA_end = time.time()\n",
    "        print(f\"--- Finished GA,Time:{(GA_end-GA_start)*1000}ms\")\n",
    "        \n",
    "        \n",
    "    print(f\"Finished training process\")\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab74ac",
   "metadata": {},
   "source": [
    "# Start training process\n",
    "We have now defined the whole training algorithm. The next step is to actually perform training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e61e033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "device_train = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "#device_train = torch.device('cpu')\n",
    "batch_size = 500\n",
    "pop_size = 15\n",
    "max_generations = 100\n",
    "Adam_epochs = 5\n",
    "GA_steps = 1\n",
    "offspring_size = 80\n",
    "elitist_level = 0.6\n",
    "rho = 4\n",
    "learning_rate = 1e-3\n",
    "in_feats = 400\n",
    "n_hidden = 200\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67dcc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population and start training process\n",
    "population = [GNN(in_feats=in_feats,\n",
    "                         n_hidden=n_hidden,\n",
    "                         n_classes=num_labels,\n",
    "                         n_layers=1,\n",
    "                         gene_num=num_genes,\n",
    "                         activation=F.relu,\n",
    "                         dropout=0.1).to(device_train) for i in range(pop_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbe831",
   "metadata": {},
   "source": [
    "# Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e0c8c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with population of size: 15\n",
      "Currently in generation 1\n",
      "--- Starting Adam\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-dc66c529c011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                \u001b[0mnum_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cells\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_genes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                      \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                      labels = labels)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mTrain_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"All Time:{(Train_start-Train_end)*1000}ms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-18769dddc60c>\u001b[0m in \u001b[0;36mGA_Neural_train\u001b[0;34m(population, pop_size, max_generations, Adam_epochs, GA_steps, offspring_size, elitist_level, rho, learning_rate, weight_decay, batch_size, num_cells, num_genes, graph, train_ids, test_ids, labels)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                         \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                         labels = labels)\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Finished Adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-97c4b4ac5ba7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmax_test_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mtrain_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_unsure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-97c4b4ac5ba7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                                    seed_nodes=self.train_ids.long())):\n\u001b[1;32m     79\u001b[0m             \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_from_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Copy node/edge features from the parent graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mbatch_nids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_parent_nid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_nids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-a3391dd1e03b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nf)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neigh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3.6/lib/python3.6/site-packages/dgl/nodeflow.py\u001b[0m in \u001b[0;36mblock_compute\u001b[0;34m(self, block_id, message_func, reduce_func, apply_node_func, v, inplace)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                                        \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                                        apply_func=apply_node_func)\n\u001b[0;32m--> 935\u001b[0;31m                 \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mdest_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3.6/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/python3.6/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0medge_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfdedge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mdst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfddst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mudf_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mudf_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3.6/lib/python3.6/site-packages/dgl/runtime/scheduler.py\u001b[0m in \u001b[0;36m_mfunc_wrapper\u001b[0;34m(src_data, edge_data, dst_data)\u001b[0m\n\u001b[1;32m    970\u001b[0m                            \u001b[0msrc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                            canonical_etype=canonical_etype)\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0m_mfunc_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mfunc_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEDGE_UDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mfunc_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdedge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfddst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-a3391dd1e03b>\u001b[0m in \u001b[0;36mmessage_func\u001b[0;34m(self, edges)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# return {'m': h}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!"
     ]
    }
   ],
   "source": [
    "Train_start = time.time()\n",
    "trained_population = GA_Neural_train(population=population,\n",
    "                                    pop_size = pop_size,\n",
    "                                    max_generations=max_generations,\n",
    "                                    Adam_epochs=Adam_epochs,GA_steps=GA_steps,\n",
    "                                    offspring_size=offspring_size,elitist_level=elitist_level,rho=rho,\n",
    "                                    learning_rate=learning_rate,\n",
    "                               weight_decay = weight_decay,\n",
    "                               batch_size = batch_size,\n",
    "                               num_cells = num_cells,num_genes = num_genes,graph = graph,\n",
    "                                     train_ids = train_ids,test_ids = test_ids,\n",
    "                                     labels = labels)\n",
    "Train_end = time.time()\n",
    "print(f\"All Time:{(Train_start-Train_end)*1000}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
